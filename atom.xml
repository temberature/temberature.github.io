<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>https://temberature.github.io</id>
    <title>第三大脑</title>
    <updated>2024-02-05T10:54:28.422Z</updated>
    <generator>https://github.com/jpmonette/feed</generator>
    <link rel="alternate" href="https://temberature.github.io"/>
    <link rel="self" href="https://temberature.github.io/atom.xml"/>
    <subtitle>智能共生——万物互联，裂隙有光。</subtitle>
    <logo>https://temberature.github.io/images/avatar.png</logo>
    <icon>https://temberature.github.io/favicon.ico</icon>
    <rights>All rights reserved 2024, 第三大脑</rights>
    <entry>
        <title type="html"><![CDATA[Finetuning Large Language Models ]]></title>
        <id>https://temberature.github.io/post/wef9Bd9Dl/</id>
        <link href="https://temberature.github.io/post/wef9Bd9Dl/">
        </link>
        <updated>2024-02-05T09:49:31.000Z</updated>
        <content type="html"><![CDATA[<p>DLAI - Learning Platform Beta<br>
https://learn.deeplearning.ai/finetuning-large-language-models/</p>
<p>Welcome to Fine-Tuning Large Language Models, taught<br>
by Sharon Zhou.<br>
Really glad to be here.<br>
When I visit with different groups, I often hear people ask,<br>
how can I use these large language models on my<br>
own data or on my own task?<br>
Whereas you might already know about how to<br>
prompt a large language model, this course goes<br>
over another important tool, fine-tuning them.<br>
Specifically, how to take, say, an open-source<br>
LLM and further train it on your own data.<br>
While writing a prompt can be pretty good<br>
at getting an LLM to follow directions to<br>
carry out the task, like extracting keywords<br>
or classifying text as positive or negative sentiment.<br>
If you fine tune, you can then get the LLM to even<br>
more consistently do what you want.<br>
And I found that prompting an LLM to<br>
speak in a certain style, like being more helpful or more polite,<br>
or to be succinct versus verbose to a specific certain extent,<br>
that can also be challenging.<br>
Fine-tuning turns out to also be a good way to adjust an LLM's tone.<br>
People are now aware of the amazing capabilities of<br>
ChatGPT and other popular LLMs to answer questions about a huge range<br>
of topics.<br>
But individuals and companies would like to have that<br>
same interface to their own private and proprietary data.<br>
One of the ways to do this is to train<br>
an LLM with your data.<br>
Of course, training a foundation LLM takes<br>
a massive amount of data, maybe hundreds of billions<br>
or even more than a trillion words of data,<br>
and massive GPU compute resources.<br>
But with fine-tuning, you can take an existing<br>
LLM and train it further on your own data.<br>
So, in this course, you'll learn what fine-tuning is, when it<br>
might be helpful for your applications, how fine-tuning<br>
fits into training, how it differs from prompt engineering<br>
or retrieval augmented generation alone, and<br>
how these techniques can be used<br>
alongside fine-tuning.<br>
You'll dive into a specific variant of fine-tuning that's<br>
made GPT-3 into chat GPT called instruction fine-tuning, which teaches an LLM<br>
to follow instructions.<br>
Finally, you'll go through the steps of fine-tuning your<br>
own LLM, preparing the data, training the<br>
model, and evaluating it, all in code.<br>
This course is designed to be accessible to<br>
someone familiar with Python.<br>
But to understand all the code, it will help to further have<br>
basic knowledge of deep learning, such as what the<br>
process of training a neural network is like, and what is,<br>
say, a trained test split.<br>
A lot of hard work has gone into this course.<br>
We'd like to acknowledge the whole Lam and I team, and<br>
Nina Wei in particular on design, as well as on the DEEPLEARNING.AI side,<br>
Tommy Nelson and Geoff Ludwig.<br>
In about an hour or so through this short course,<br>
you gain a deeper understanding of how you can build<br>
your own LLM through fine-tuning an existing LLM on your own data.</p>
<p>Let's get started.</p>
<h1 id="why-finetune">Why finetune</h1>
<p>In this lesson, you'll get to learn why you should fine-tune, what<br>
fine-tuning really even is, compare it to<br>
prompt engineering, and go through a lab where you get to<br>
compare a fine-tuned model to a non-fine-tuned model.</p>
<p>Cool, let's get started!<br>
Alright, so why should you fine-tune LLMs?<br>
Well before we jump into why, let's talk about what fine-tuning really<br>
is.<br>
So what fine-tuning is, is taking these general purpose<br>
models like GPT-3 and specializing them into something<br>
like ChatGPT,<br>
the specific chat use case to make it chat well, or using GPT-4<br>
and turning that into a specialized GitHub co-pilot use<br>
case to auto-complete code.<br>
An analogy I like to make is a PCP, a primary care physician,<br>
is like your general purpose model.<br>
You go to your PCP every year for a general checkup,<br>
but a fine-tune or specialized model is like a cardiologist or dermatologist,<br>
a doctor that has a specific specialty and can actually<br>
take care of your heart problems or skin problems in much more<br>
depth.<br>
So what fine tuning actually does for your<br>
model is that it makes it possible for<br>
you to give it a lot more data than what fits into<br>
the prompt so that your model can learn<br>
from that data rather than just get access to it,<br>
from that learning process is able to upgrade itself from that PCP<br>
into something more specialized like a dermatologist.<br>
So you can see in this figure you might have some symptoms<br>
that you input into the model like skin irritation,<br>
redness, itching, and the base model<br>
which is the general purpose model might just<br>
say this is probably acne.<br>
A model that is fine-tuned on dermatology data however<br>
might take in the same symptoms and be<br>
able to give you a much clearer, more specific diagnosis.<br>
In addition to learning new information, fine-tuning can also help<br>
steer the model to more consistent outputs or more<br>
consistent behavior.<br>
For example, you can see the base model here.<br>
When you ask it, what's your first name?<br>
It might respond with, what's your last name?<br>
Because it's seen so much survey data out there of different questions.</p>
<p>So it doesn't even know that it's supposed to answer that question.<br>
But a fine-tuned model by contrast, when you ask it, what's your<br>
first name?<br>
would be able to respond clearly.<br>
My first name is Sharon.<br>
This bot was probably trained on me.<br>
In addition to steering the model to more<br>
consistent outputs or behavior, fine tuning can help<br>
the model reduce hallucinations, which is a common problem<br>
where the model makes stuff up.<br>
Maybe it will say my first name is Bob when this was<br>
trained on my data and my name is definitely not Bob.<br>
Overall, fine tuning enables you to customize the model<br>
to a specific use case.<br>
In the fine-tuning process, which we'll go<br>
into far more detail later, it's actually very<br>
similar to the model's earlier training recipe.<br>
So now to compare it with something that you're<br>
probably a little bit more familiar with, which<br>
is prompt engineering.<br>
This is something that you've already been doing for a while<br>
with large language models, but maybe even for over the<br>
past decade with Google, which is just putting a query in, editing<br>
the query to change the results that you see.<br>
So there are a lot of pros to prompting.<br>
One is that you really don't need any data to get started.<br>
You can just start chatting with the model.<br>
There's a smaller upfront cost, so you don't really<br>
need to think about cost, since every single time you ping<br>
the model, it's not that expensive.<br>
And you don't really need technical knowledge to get started.<br>
You just need to know how to send a text message.<br>
What's cool is that there are now methods you can use, such<br>
as retrieval augmented generation, or RAG, to<br>
connect more of your data to it, to selectively choose what kind of data<br>
goes into the prompt.<br>
Now of course, if you have more than a little bit of data,<br>
then it might not fit into the prompt.<br>
So you can't use that much data.<br>
Oftentimes when you do try to fit in a ton of data,<br>
unfortunately it will forget a lot of that data.<br>
There are issues with hallucination, which is when the model<br>
does make stuff up and it's hard to correct that<br>
incorrect information that it's already learned. So while using retrieval augmented<br>
generation can be great to connect your data, it will<br>
also often miss the right data,get the incorrect data and cause the<br>
model, to output the wrong thing.<br>
Fine tuning is kind of the opposite of prompting.<br>
So you can actually fit in almost an<br>
unlimited amount of data, which is nice because<br>
the model gets to learn new information on that data.<br>
As a result, you can correct that incorrect information that it<br>
may have learned before, or even put in<br>
recent information that it hadn't learned about previously.<br>
There's less cost afterwards if you do fine-tune a<br>
smaller model and this is particularly relevant if<br>
you expect to hit the model a lot of times. So have<br>
a lot of either throughput or you expect<br>
it to just handle a larger load.<br>
And also retrieval augmented generation can<br>
be used here too. I think sometimes people think it's<br>
a separate thing but actually you can use<br>
it for both cases.<br>
So you can actually connect it with far more data<br>
as well even after it's learned all this information.<br>
There are cons, however.<br>
You need more data, and that data has to<br>
be higher quality to get started.<br>
There is an upfront compute cost as well, so it's<br>
not free necessarily.<br>
It's not just a couple dollars just to get started.<br>
Of course, there are now free tools out there to get started,<br>
but there is compute involved in making this happen,<br>
far more than just prompting.<br>
And oftentimes you need some technical<br>
knowledge to get the data in the right place, and that's<br>
especially, you know, surrounding this data piece.<br>
And, you know, there are more and more tools now that's<br>
making this far easier, but you still need some<br>
understanding of that data.<br>
And you don't have to be just anyone who can send<br>
a text message necessarily.<br>
So finally, what that means is for prompting,<br>
you know, that's great for generic use cases.<br>
It's great for different side projects and prototypes.<br>
It's great to just get started really, really<br>
fast.<br>
Meanwhile, fine tuning is great for more enterprise or domain-specific<br>
use cases, and for production usage.<br>
And we'll also talk about how it's useful for privacy in this<br>
next section, which is the benefits of fine-tuning your own<br>
LLM. So if you have your own LLM that<br>
you fine-tuned, one benefit you get is around performance.</p>
<p>So this can stop the LLM from making stuff up,<br>
especially around your domain.<br>
It can have far more expertise in that domain.<br>
It can be far more consistent.<br>
So sometimes these models will just produce, you know,<br>
something really great today, but then tomorrow you hit it and it<br>
isn't consistent anymore.<br>
It's not giving you that great output anymore.<br>
And so this is one way to actually make it<br>
far more consistent and reliable.<br>
And you can also have it be better at moderating. If you've<br>
played a lot with ChatGPT, you might have seen ChatGPT say, I'm sorry,<br>
I can't respond to that.<br>
And you can actually get it to say the same<br>
thing or something different that's related to your company or<br>
use case to help the person chatting with it, stay<br>
on track.<br>
And again, so now I want to touch on privacy.<br>
When you fine tune your own LLM, this can happen in your VPC or on<br>
premise.<br>
This prevents data leakage and data breaches that<br>
might happen on off the shelf, third party solutions.<br>
And so this is one way to keep that data safe that you've<br>
been collecting for a while that might be the last few days,<br>
it might be the last couple decades as well.<br>
Another reason you might want to fine tune your own LLM is<br>
around cost, so one is just cost transparency.<br>
You maybe you have a lot of people using your model and<br>
you actually want to lower the cost per request.<br>
Then fine tuning a smaller LLM can actually<br>
help you do that.<br>
And overall, you have greater control<br>
over costs and a couple other factors as well.<br>
That includes uptime and also latency.<br>
You can greatly reduce the latency for certain applications<br>
like autocomplete.<br>
You might need latency that is sub 200<br>
milliseconds so that it is not perceivable by<br>
the person doing autocomplete.<br>
You probably don't want autocomplete to happen<br>
across 30 seconds, which is currently the case with<br>
running GPD 4 sometimes.<br>
And finally, in moderation, we talked about that<br>
a little bit here already.<br>
But basically, if you want the model to say, I'm<br>
sorry to certain things, or to say, I don't know<br>
to certain things, or even to have a custom response, This is<br>
one way to actually provide those guardrails to<br>
the model.<br>
And what's really cool is you're actually get to see an example of<br>
that in the notebooks.<br>
All right.<br>
So across all of these different labs, you'll be using a lot of<br>
different technologies to fine tune.<br>
So there are three Python libraries.<br>
One is PyTorch developed by Meta.<br>
This is the lowest level interface that you'll see.<br>
And then there's a great library by HuggingFace on top of PyTorch and<br>
a of the great work that's been done and it's much higher<br>
level.<br>
You can import datasets and train models very easily.<br>
And then finally, you'll see the Llamanai library, which<br>
I've been developing with my team.<br>
And we call it the llama library for<br>
all the great llamas out there.<br>
And this is an even higher level interface<br>
where you can train models with just three<br>
lines of code.<br>
All right.<br>
So let's hop over to the notebooks and see some fine-tuned models<br>
in action.<br>
Okay, so we're going to compare a fine-tuned model<br>
with a non-fine-tuned model.<br>
So first we're importing from the LLAMA library, again<br>
this is from LAMANI, the basic model runner.<br>
And all this class does is it helps us run open-source<br>
models.<br>
So these are hosted open-source models on GPUs to<br>
run them really efficiently.<br>
And the first model you can run here is the LLAMA2 model,<br>
which is very popular right now.<br>
And this one is not fine-tuned.<br>
So we're gonna just instantiate it based on this is its hugging<br>
face name and we're gonna say.<br>
Tell me how to train my dog to sit.<br>
So it's just you know, really really simple here into<br>
the non fine-tuned model we're gonna get the output out and. Let's print non<br>
tuned.<br>
Output and see oof.<br>
Okay.<br>
So we asked it.<br>
Tell me how to train my dog to sit.<br>
It said period, and then tell me how to train my dog to say,<br>
tell me how to teach my dog to come, tell me how to get my dog to heel.<br>
So clearly this is very similar to the what's<br>
your first name, what's your last name answer.<br>
This model has not been told or trained<br>
to actually respond to that command.<br>
So maybe a bit of a disaster, but let's keep looking.<br>
So maybe we can ask it, what do you think of Mars?<br>
So now, you know, at least it's responding to the question, but<br>
it's not great responses.<br>
I think it's a great planet.<br>
I think it's a good planet.<br>
I think it'll be a great planet.<br>
So it keeps going.<br>
Very philosophical, potentially even existential,<br>
if you keep reading.<br>
All right.<br>
What about something like a Google search query,<br>
like Taylor Swift's best friend?<br>
Let's see what that actually says.<br>
All right.<br>
Well, it doesn't quite get Taylor Swift's best<br>
friend, but it did say that it's a huge<br>
Taylor Swift fan.<br>
All right, let's keep exploring maybe something that's a<br>
conversation to see if it can do turns in a<br>
conversation like chat GPT.<br>
So this is an agent for an Amazon delivery order.<br>
Okay, so at least it's doing the different customer<br>
agent turns here, but it isn't quite<br>
getting anything out of it. This is not something usable for<br>
any kind of like fake turns or help<br>
with making an auto agent.<br>
All right, so you've seen enough of that.<br>
Let's actually compare this to Llama 2 that has been fine-tuned to<br>
actually chat.<br>
So I'm gonna instantiate the fine-tune model.<br>
Notice that this name, all that's different is this chat here.<br>
And then I'm gonna let this fine-tune model do the same thing.<br>
So tell me how to train my dog to sit.<br>
I'm gonna print that.<br>
Okay, very interesting.<br>
So you can immediately tell a difference.<br>
So tell me how to train my dog to sit. It's still trying to auto-complete that.</p>
<p>So tell me how to train my dog to sit on command.<br>
But then it actually goes through almost a step-by-step guide<br>
of what to do to train my dog to sit.<br>
Cool, so that's much, much better.<br>
And the way to actually, quote unquote,<br>
get rid of this extra auto-complete thing is actually to<br>
inform the model that you want instructions.<br>
So I'm actually putting these instruction tags here.<br>
This was used for LLAMA2.<br>
You can use something different when you fine-tune<br>
your own model, but this helps with telling the model, hey,<br>
these are my instructions and these are the boundaries.<br>
I'm done with giving this instruction.<br>
Stop continuing to give me an instruction.<br>
So here you can see that it doesn't auto-complete that on-command thing.</p>
<p>And just to compare, just to be fair,<br>
we can see what the non-fine-tuned model actually says.<br>
Great, it just repeats the same thing or something very similar.<br>
Not quite right.<br>
Cool, let's keep going down. So what do you think of Mars, this<br>
model?<br>
Oh, it's a fascinating planet.<br>
It's captured the imagination of humans for centuries.<br>
Okay, cool.<br>
So something that's much better output here.<br>
What about Taylor Swift's best friend?<br>
Let's see how this does.<br>
Okay, this one's pretty cute.<br>
It has a few candidates for who Taylor Swift's<br>
best friend actually is.<br>
Let's take a look at these turns from the Amazon delivery agent.<br>
Okay.<br>
It says, I see. Can you provide me with your order number?<br>
This is much, much better.<br>
It's interesting because down here, it also summarizes what's going on,<br>
which may or may not be something that you would want,<br>
and that would be something you can fine tune away.<br>
And now I'm curious what chat GPT would say for, tell<br>
me how to train my dog to sit.<br>
Okay.<br>
So it gives different steps as well.<br>
Great.<br>
Alright, feel free to use ChatGPT or any other<br>
model to see what else they can each<br>
do and compare the results. But it's pretty clear, I think, that<br>
the ones that have been fine-tuned, including ChatGPT and this Lama2Chat<br>
LLM, they're clearly better than the one that was<br>
not fine-tuned.<br>
Now in the next lesson, we're going to see where fine-tuning fits<br>
in in the whole training process.<br>
So you'll get to see the first step and how to even<br>
get here with this fine-tuned model.</p>
<h1 id="where-finetuning-fits-in">Where finetuning fits in</h1>
<p>In this lesson, you'll learn about where fine-tuning really<br>
fits into the training process.<br>
It comes after a step called pre-training, which you'll go<br>
into a little bit of detail on, and then you'll get to learn about all the<br>
different tasks you get to apply fine-tuning to.</p>
<p>Alright, let's continue.<br>
Alright, let's see where fine-tuning fits in.<br>
First, let's take a look at pre-training.<br>
This is the first step before fine-tuning even happens, and<br>
it actually takes a model at the start that's completely<br>
random.<br>
It has no knowledge about the world at all.<br>
So all its weights, if you're familiar with weights, are<br>
completely random.<br>
It cannot form English words at all.<br>
It doesn't have language skills yet.<br>
And the learning objective it has is next token prediction,<br>
or really, in a simplified sense, it's<br>
just the next word prediction here. So you see the word wants, and<br>
so we want it to now predict the word upon, But<br>
then you see the LLM just producing &quot;sd!!!@&quot;.<br>
So just really far from the word upon, so that's where it's starting.<br>
But it's taking in and reading from a giant corpus of data, often<br>
scraped from the entire web.<br>
We often call this unlabeled because it's not something that we've structured<br>
together. We've just scraped it from the web.<br>
I will say it has gone through many, many cleaning processes,<br>
So there is still a lot of manual work to<br>
getting this data set to be effective for model pre-training.<br>
And this is often called self-supervised learning because the<br>
model is essentially supervising itself with<br>
next token prediction.<br>
All it has to do is predict the next word.<br>
There aren't really labels otherwise.<br>
Now, after training, here you see that the model is now<br>
able to predict the word upon, or the token upon.<br>
And it's learned language.<br>
It's learned a bunch of knowledge from the internet. So<br>
this is fantastic that this process actually works<br>
in this way and it's amazing because all it is is<br>
just trying to predict the next token and it's reading the<br>
entire Internet's worth of data to do so.<br>
Now okay maybe there's an asterisk on entire<br>
Internet data and data scraped from the entire<br>
Internet.<br>
The actual understanding and knowledge behind this is<br>
often not very public.<br>
People don't really know exactly what that data set looks like for a lot<br>
of the closed source models from large companies. But<br>
there's been an amazing open source effort by EleutherAI to<br>
create a dataset called The Pile, which you'll get to<br>
explore in this lab.<br>
And what it is, is that it's a set of 22<br>
diverse datasets scraped from the entire internet.<br>
Here you can see in this figure, you know, there's<br>
a four score and seven years. So that's a Lincoln's Gettysburg address.</p>
<p>There's also Lincoln's carrot cake recipe.<br>
And of course, also scraped from PubMed, there's<br>
information about different medical texts.<br>
And finally, there's also code in here from GitHub.<br>
So it's a set of pretty intellectual datasets that's curated<br>
together to actually infuse these models<br>
with knowledge.<br>
Now this pre-training step is pretty expensive and time-consuming, it's actually<br>
expensive because it's so time-consuming to have the model<br>
go through all of this data, go from absolutely randomness to<br>
understanding some of these texts, you<br>
know, putting together a carrot cake recipe while also<br>
writing code while also knowing about medicine in the<br>
Gettysburg Address.<br>
Okay, so these pre-trained base models are great<br>
and there are actually a lot of them<br>
that are open source out there, but you know,<br>
it's been trained on these data sets from the web and it might<br>
have this geography homework you might see here<br>
on the left where it asks what's the.<br>
What's the capital of Kenya?<br>
What's the capital of France?<br>
And it all, you know, in a line without seeing the answers.<br>
So when you then input, what's the capital of Mexico, the<br>
L line might just say, what's the capital of Hungary?<br>
As you can see that it's not really useful from the<br>
sense of a chatbot interface.<br>
So how do you get it to that chatbot interface?<br>
Well, fine tuning is one of those ways to get you there.<br>
And it should be really a tool in your toolbox.<br>
So pre-training is really that first step that gets you<br>
that base model.<br>
And when you add more data in, not actually as much data,<br>
you can use fine-tuning to get a fine-tuned model.<br>
And actually, even a fine-tuned model, you<br>
can continue adding fine-tuning steps afterwards.<br>
So fine-tuning really is a step afterwards.<br>
You can use the same type of data. You can actually<br>
probably scrape data from different sources<br>
and curate it together, which you'll take a look at in a little bit.<br>
So that can be this quote unquote unlabeled data,<br>
But you can also curate data yourself to<br>
make it much more structured for the model<br>
to learn about.<br>
And I think one thing that's key that differentiates fine-tuning from<br>
pre-training is that there's much less data<br>
needed.<br>
You're building off of this base model that has<br>
already learned so much knowledge and basic language<br>
skills that you're really just taking it to<br>
the next level.<br>
You don't need as much data.<br>
So this really is a tool in your toolbox.<br>
And if you're coming from other machine learning areas, you<br>
know, that's fine tuning for discriminative tasks, maybe you're<br>
working with images and you've been fine-tuning on<br>
ImageNet, you'll find that the definition for<br>
fine-tuning here is a little bit more loose and it's not as<br>
well defined for generative tasks because we are actually updating the<br>
weights of the entire model, not<br>
just part of it, which is often the case for fine-tuning those<br>
other types of models.</p>
<p>So we have the same training objective as pre-training<br>
here for fine-tuning next token production.<br>
And all we're doing is changing up the data so that it's more<br>
structured in a way, and the model can be more consistent in<br>
outputting and mimicking that structure.<br>
And also there are more advanced ways to<br>
reduce how much you want to update this model, and we'll<br>
discuss this a bit later.<br>
So exactly what is fine-tuning doing for you?<br>
So you're getting a sense of what it is right now, but<br>
what are the different tasks you you can<br>
actually do with it?<br>
Well, one giant category I like to think about<br>
is just behavior change. You're changing the behavior of the model.<br>
You're telling it exactly, you know, in this chat interface, we're in<br>
a chat setting right now. We're not looking at a survey.<br>
So this results in the model being able<br>
to respond much more consistently.<br>
It means the model can focus better.<br>
Maybe that could be better for moderation, for example.<br>
And it's also generally just teasing out its capabilities.<br>
So here it's better at conversation so that it can now talk about a wide<br>
variety of things versus<br>
before we would have to do a lot of prompt engineering in<br>
order to tease that information out.<br>
Fine tuning can also help the model gain<br>
new knowledge and so this might be around<br>
specific topics that are not in that base pre-trained model.<br>
This might mean correcting old incorrect<br>
information so maybe there's you know more updated<br>
recent information that you want the model to<br>
actually be infused with.<br>
And of course more commonly you're doing both with these models, so<br>
oftentimes you're changing the behavior and you<br>
want it to gain new knowledge.<br>
So taking it a notch down, so tasks for fine-tuning, it's really<br>
just text in, text out for LLMs. And I<br>
like to think about it in two different categories, so<br>
you can think about it one as extracting text, so you<br>
put text in and you get less text out. So a<br>
lot of the work is in reading, and this could be extracting keywords, topics, it<br>
might be routing, based on all the data that you<br>
see coming in. You route the chat, for example, to some<br>
API or otherwise.<br>
Different agents are here, like different agent capabilities.<br>
And then that's in contrast to expansion.<br>
So that's where you put text in, and you get more text out.<br>
So I like to think of that as writing.<br>
And so that could be chatting, writing emails, writing code,<br>
and really understanding your task exactly,<br>
the difference between these two different tasks,<br>
or maybe you have multiple tasks that you want to fine-tune<br>
on is what I've found to be the clearest indicator of success.<br>
So if you want to succeed at fine-tuning the model, it's getting<br>
clearer on what task you want to do.<br>
And clarity really means knowing what<br>
good output looks like, what bad output looks like,<br>
but also what better output looks like.<br>
So when you know that something is doing<br>
better at writing code or doing better at routing a task,<br>
that actually does help you actually fine-tune<br>
this model to do really well.<br>
Alright, so if this is your first time fine-tuning,<br>
I recommend a few different steps.<br>
So first, identify a task by just prompt engineering a<br>
large LLM and that could be chat GPT, for example,<br>
and so you're just playing with chat GPT<br>
like you normally do.<br>
And you find some, you know, tasks that it's doing okay at, so<br>
not not great, but like not horrible either, so<br>
you know that it's possible within the realm of possibility, but<br>
it's not it's not the best and you want it to much better<br>
for your task.<br>
So pick that one task and just pick one.<br>
And then number four, get some inputs and<br>
outputs for that task. So you put in some text<br>
and you got some text out, get inputs where you<br>
put in text and get text out and outputs,<br>
pairs of those for this task.<br>
And one of the golden numbers I like to use<br>
is 1000 because I found that that is a good<br>
starting point for the amount of data that you need.<br>
And make sure that these inputs and outputs<br>
are better than the okay result from that LLM before.<br>
You can't just generate these outputs necessarily all the time.<br>
And so make sure you have those pairs of data and you'll<br>
explore this in the lab too, this whole pipeline here.<br>
Start out with that and then what you do is<br>
you can then fine tune a small LLM on this<br>
data just to get a sense of that performance bump.<br>
And then so this is only if you're a first time, this<br>
is what I recommend.<br>
So now let's jump into the lab where you<br>
get to explore the data set that was used for pre-training versus<br>
for fine-tuning, so you understand exactly what these<br>
input- output pairs look like.<br>
Okay, so we're going to get started by importing a few different<br>
libraries, so we're just going to run that.<br>
And the first library that we're going to use is<br>
the datasets library from. HuggingFace, and they have this great<br>
function called loadDataset where you can just pull<br>
a dataset from on their hub and be able to run it.<br>
So here I'm going to pull the pre-training dataset called the pile that<br>
you just saw a little bit more about and here I'm just grabbing<br>
the split which is train versus test and<br>
very specifically I'm actually grabbing streaming equals true because<br>
this data set is massive we can't download it<br>
without breaking this new book so I'm<br>
actually going to stream it in one at a<br>
time so that we can explore the different pieces of data in<br>
there.<br>
So just loading that up and now I'm going to just look at<br>
the first five so this.<br>
It's just using iter tools.<br>
Great.<br>
Ok, so you can see here, in the pre-trained data set, there's a<br>
lot of data here that looks kind of scraped.<br>
So this text says, it is done and submitted.<br>
You can play Survival of the Tastiest on Android.<br>
And so that's one example.<br>
And let's see if we can find another one here.<br>
Here is another one.<br>
So this is just code that was scraped, XML code that was scraped. So that's<br>
another data point.<br>
You'll see article content, you'll see this topic about Amazon<br>
announcing a new service on AWS, and then here's about Grand<br>
Slam Fishing Charter, which is a family business.<br>
So this is just a hodgepodge of different data sets scraped from<br>
essentially the internet.<br>
And I kind of want to contrast that with fine-tuning<br>
data set that you'll be using across the different labs.<br>
We're grabbing a company data set of question-answer pairs, you know,<br>
scraped from an FAQ and also put together about internal engineering<br>
documentation.<br>
And it's called Lamini Docs, it's about the company Lamini.<br>
And so we're just going to read that JSON file and take a look at<br>
what's in there.<br>
Okay, so this is much more structured data,<br>
right? So there are question-answer pairs here, and it's very<br>
specific about this company.<br>
So the simplest way to use this data<br>
set is to concatenate actually these questions and<br>
answers together and serve that up into the model.<br>
So that's what I'm going to do here. I'm going to turn that into a dict<br>
and then I'm going to see what actually concatenating one<br>
of these looks like.<br>
So, you know, just concatenating the question and directly<br>
just giving the answer after it right here.<br>
And of course you can prepare your data in any way possible.<br>
I just want to call out a few different common ways of<br>
formatting your data and structuring it.<br>
So question answer pairs, but then also<br>
instruction and response pairs, input output pairs,<br>
just being very generic here.<br>
And also, you can actually just have it,<br>
since we're concatenating it anyways, it's just<br>
text that you saw above with the pile.<br>
All right, so concatenating it, that's very simple, but<br>
sometimes that is enough to see results, sometimes<br>
it isn't.<br>
So you'll still find that the model might need just more structure<br>
to help with it, and this is very similar<br>
to prompt engineering, actually.<br>
So taking things a bit further, you can also process your data<br>
with an instruction following, in this case, question-answering<br>
prompt template.<br>
And here's a common template.<br>
Note that there's a pound-pound-pound before the question type of marker<br>
so that that can be easily used as structure to tell the<br>
model to expect what's next.<br>
It expects a question after it sees that for the question.<br>
And it also can help you post-process the model's outputs<br>
even after it's been fine-tuned.<br>
So we have that there.<br>
So let's take a look at this prompt template in<br>
action and see how that differs from the<br>
concatenated question and answer.<br>
So here you can see how that's how the prompt template<br>
is with the question and answer neatly done<br>
there.<br>
And often it helps to keep the input<br>
and output separate so I'm actually going to take<br>
out that answer here and keep them separated<br>
out because this helps us just using the<br>
data set easily for evaluation and for you<br>
know when you split the data set into<br>
train and test.<br>
So now what I'm gonna do is put all of this, apply<br>
all of this template to the entire data set.<br>
So just running a for loop over it and just hydrating the prompt.<br>
So that is just adding that question and<br>
answer into this with F string or dot<br>
format stuff here with Python.<br>
All right, so let's take a look at the difference between that text-only thing<br>
and the question-answer format.<br>
Cool.<br>
So it's just text-only, it's all concatenated here that you're putting in, and<br>
here is just question-answer, much more structured.</p>
<p>And you can use either one, but of course I<br>
do recommend structuring it to help with evaluation.<br>
That is basically it.<br>
The most common way of storing this data<br>
is usually in JSON lines files, so &quot;jsonl files.jsonl.&quot;<br>
It's basically just, you know, each line is a JSON object and that's it,<br>
and so just writing that to file there.<br>
You can also upload this data set onto HuggingFace,<br>
shown here, because you'll get to use this later<br>
as well and you'll get to pull it from the<br>
cloud like that.<br>
Next, you'll dive into a specific variant of fine-tuning called<br>
instruction fine-tuning.</p>
<h1 id="instruction-finetuning">Instruction finetuning</h1>
<p>In this lesson you'll learn about instruction fine-tuning, a<br>
variant of fine-tuning that enabled GPT-3 to turn into<br>
chat GPT and give it its chatting powers.<br>
Okay, let's start giving chatting powers to all our models.<br>
Okay, so let's dive into what instruction fine-tuning is.</p>
<p>Instruction fine-tuning is a type of fine-tuning. There are<br>
all sorts of other tasks that you can do like reasoning, routing,<br>
copilot, which is writing code, chat, different agents,<br>
but specifically instruction fine tuning, which you<br>
also may have heard as instruction tune or instruction<br>
following LLMs, teaches the model to follow instructions<br>
and behave more like a chatbot.<br>
And this is a better user interface to<br>
interact with the model as we've seen with chat GPT.<br>
This is the method that turned. GPT-3 into chat GPT, which<br>
dramatically increased AI adoption from just a few researchers<br>
like myself to millions and millions of people.<br>
So for the data set for instruction following,<br>
you can use a lot that already exists<br>
readily available either online or specific to your company,<br>
and that might be FAQs, customer support conversations,<br>
or Slack messages.<br>
So it's really this dialogue dataset or just<br>
instruction response datasets.<br>
Of course, if you don't have data, no problem.<br>
You can also convert your data into something that's<br>
more of a question-answer format or instruction following<br>
format by using a prompt template. So here<br>
you can see, you know, a README might be able to come be converted into<br>
a question-answer pair.<br>
You can also use another LLM to do this for you.<br>
There's a technique called Alpaca from Stanford that uses<br>
chat GPT to do this.<br>
And of course, you can use a pipeline<br>
of different open source models to do this as well.<br>
Cool.<br>
So one of the coolest things about fine tuning,<br>
I think, is that it teaches this new behavior to the model.<br>
And while, you know, you might have fine<br>
tuning data on what's the capital of France, Paris, because<br>
these are easy question answer pairs that you can<br>
get.<br>
You can also generalize this idea of question<br>
answering to data you might not have given<br>
the model for your fine-tuning data set, but<br>
that the model had already learned in its pre-existing pre-training<br>
step. And so that might be code.<br>
And this is actually findings from the chat GPT paper where the<br>
model can now answer questions about<br>
code even though they didn't have question answer pairs about that<br>
for their instruction fine-tuning.<br>
And that's because it's really expensive to get programmers<br>
to go, you know, label data sets where they ask questions<br>
about code and write the code for it.<br>
So an overview of the different steps of fine-tuning<br>
are data prep, training, and evaluation.<br>
Of course, after you evaluate the model,<br>
you need to prep the data again to improve it.<br>
It's a very iterative process to improve the model.<br>
And specifically for instruction fine-tuning and other different types of fine-tuning,<br>
data prep is really where you have differences.<br>
This is really where you change your data,<br>
you tailor your data to the specific type of fine tuning,<br>
the specific task of fine tuning that you're doing.<br>
And training and evaluation is very similar.<br>
So now let's dive into the lab where you'll get<br>
a peek at the alpaca dataset for instruction tuning.</p>
<p>You'll also get to compare models again that have been<br>
instruction tuned versus haven't been instruction tuned, and you'll get to<br>
see models of varying sizes here.<br>
So first importing a few libraries, the first one that<br>
is important is again this load data set<br>
function from the data sets library and let's load up this instruction<br>
tune data set and this is specifying the<br>
alpaca data set and again we're streaming this because it's actually a<br>
hefty fine-tuning data set not as big as the pile<br>
of course.<br>
I'm going to load that up and just like before with the pile, you're<br>
going to take a look at a few examples.<br>
All right, so unlike the pile, it's not just text and that's it.<br>
Here it's a little bit more structured, but<br>
it's not as, you know, clear-cut as just question-answer pairs.<br>
And what's really, really cool about, you know, this<br>
is that the authors of the alpaca paper, they<br>
actually had two prompt templates because<br>
they wanted the model to be able to work with two different<br>
types of prompts and two different types of tasks<br>
essentially and so one is you know an instruction<br>
following one where there is an extra set of<br>
inputs for example it the instruction might be add<br>
two numbers and the inputs might be first number is three the<br>
second number is four and then there's prompt templates without input<br>
which you can see in these examples sometimes it's not relevant<br>
to have an input so it doesn't have that so these are the prompt<br>
templates that are being used and so again<br>
very similar to before you'll just hydrate those prompts<br>
and run them across the whole data set.</p>
<p>And let's just print out one pair to see what that looks like.<br>
Cool, so that's input output here and you know how it's hydrated<br>
into the prompt.<br>
So it ends with response and then it<br>
outputs this response here.<br>
Cool, and just like before, you can write it to a JSON lines file.</p>
<p>You can upload it to HuggingFace hub if you want.<br>
We've actually loaded it up at Lamini slash Alpaca so that it's stable,<br>
you can go look at it there and you can go use it.<br>
Okay, great.<br>
So now that you have seen what that instruction following data set<br>
looks like, I think the next thing to do is<br>
just remind you again on this tell me how to train my<br>
dog to sit prompt on different models.<br>
So the first one is going to be this llama 2 model<br>
that is again not instruction tuned.<br>
We're gonna run that.<br>
Tell me how to train my dog to sit.<br>
Okay, it starts with that period again and just<br>
says this so remember that before and then now we're<br>
gonna compare this to again the instruction tuned<br>
model right here okay so much better it's actually<br>
producing different steps and then finally I just<br>
want to share chatGPT again just so you<br>
can have this comparison right here great okay<br>
so that.<br>
That is a much larger set of models, ChatGPT is quite large<br>
compared to the Llama2 models.<br>
Those are actually 7 billion parameter models,<br>
ChatGPT is rumored to be around 70 billion,<br>
so very large models.<br>
You're also going to explore some smaller models.<br>
So one is that 70 million parameter model.<br>
And here I'm loading up these models.<br>
This is not super important yet, you'll<br>
explore this a bit more later, but I'm going to load up two<br>
different things to process the data and then<br>
run the model.<br>
And you can see here, the tag that we have here is a<br>
&quot;EleutherAI/Pythia/70m&quot;.<br>
This is a 70 million parameter model that<br>
has not been instruction tuned.<br>
I'm going to paste some code here. It's a function to run inference, or basically<br>
run the model on text.<br>
We will go through these different sections of<br>
what exactly is going on in this function<br>
throughout the next few labs.<br>
Cool.<br>
So this model hasn't been fine-tuned. It doesn't know anything specific about a<br>
company, but we can load up this, company dataset again<br>
from before.<br>
So we're going to give this model a question from this dataset, probably<br>
just, you know, the first sample from the test set, for<br>
example.<br>
And so we can run this here. The question is, can Lamini<br>
generate technical documentation or user manuals for software projects?<br>
And the actual answer is yes, Lamini can generate technical<br>
documentation and user manuals for software projects.<br>
And it keeps going.<br>
But the model's answer is, I have a question about the following.<br>
How do I get the correct documentation to work?<br>
A, I think you need to use the following code,<br>
et cetera.<br>
So it's quite off.<br>
Of course, it's learned English, and it got the word<br>
documentation in there.<br>
So it kind of understands maybe that we're in a question-answer setting, because it<br>
has.<br>
A there for answer.<br>
But it's clearly quite off.<br>
And so it doesn't quite understand this data set<br>
in terms of the knowledge, and also doesn't understand<br>
the behavior that we're expecting from it. So it doesn't understand that it's<br>
supposed to answer this question.<br>
Ok, so now compare this to a model that we've<br>
now fine-tuned for you, but that you're actually about<br>
to fine-tune for instruction following.<br>
And so that's loading up this model.<br>
And then we can run the same question through this<br>
model and see how it does.<br>
And it says, yes, lamani can generate technical documentation or<br>
user manuals for software projects, et cetera, and so this is<br>
just far more accurate than the one before and it's<br>
following that right behavior that we would expect.<br>
Okay great so now that you've seen what an instruction<br>
following model does exactly the next step is<br>
to go through what you saw a peak of which is that<br>
tokenizer how to prep our data so that<br>
it is available to the model for training.</p>
<h1 id="data-preparation">Data preparation</h1>
<p>Now after exploring the data that you'll be using, in this lesson you'll learn<br>
about how to prepare that data for training.<br>
All right, let's jump into it.<br>
So next on what kind of data you need to prep,<br>
well there are a few good best practices.<br>
So one is you want higher quality data and actually<br>
that is the number one thing you need for fine-tuning<br>
rather than lower quality data.<br>
What I mean by that is if you give it garbage inputs, it'll<br>
try to parrot them and give you garbage outputs.<br>
So giving really high quality data is important.<br>
Next is diversity.<br>
So having diverse data that covers a lot of aspects<br>
of your use case is helpful.<br>
If all your inputs and outputs are the same,<br>
then the model can start to memorize them and if that's<br>
not exactly what you want, then the model will start<br>
to just only spout the same thing over<br>
and over again. And so having diversity in<br>
your data is, is really important.<br>
Next is real or generated.<br>
I know there are a lot of ways to create generated data,<br>
and you've already seen one way of doing that using an LLM, but<br>
actually having real data is very, very effective and helpful most<br>
of the time, especially for those writing tasks.</p>
<p>And that's because generated data already has<br>
certain patterns to it. You might've heard of some services that<br>
are trying to detect whether something is generated<br>
or not. And that's actually because there are patterns<br>
in generated data that they're trying to detect.</p>
<p>And as a result, if you train on more of the same patterns, it's<br>
not going to learn necessarily new patterns or<br>
new ways of framing things.<br>
And finally, I put this last because actually<br>
in most machine learning applications,<br>
having way more data is important than less data.<br>
But as you actually just seen before, pre-training<br>
handles a lot of this problem.<br>
Pre-training has learned from a lot of data, all<br>
from the internet.<br>
And so it already has a good base understanding. It's<br>
not starting from zero.<br>
And so having more data is helpful for the model, but not as<br>
important as the top three and definitely not as<br>
important as quality.<br>
So first, let's go through some of the steps of collecting your data.<br>
So you've already seen some of those instruction response pairs.<br>
So the first step is collect them.<br>
The next one is concatenate those pairs or<br>
add a prompt template. You've already seen that as well.<br>
The next step is tokenizing the data, um,<br>
adding padding or truncating the data.<br>
So it's the right size going into the model and you'll see<br>
how to tokenize that in the lab.<br>
So the steps to prepping your data is one<br>
collecting those instruction response pairs.<br>
Maybe that's question answer pairs, and then it's concatenating<br>
those pairs together, adding some prompt template, like you<br>
did before.<br>
The third step is tokenizing that data.<br>
And the last step is splitting that data<br>
into training and testing.<br>
Now in tokenizing, what, what does that really mean?<br>
Well, tokenizing your data is taking your text data and<br>
actually turning that into numbers that represent each of<br>
those pieces of text.<br>
It's not actually necessarily by word.<br>
It's based on the frequency of, you know, common<br>
character occurrences.<br>
And so in this case, one of my favorites is the ING token,<br>
which is very common in tokenizers.<br>
And that's because that happens in every single gerund.<br>
So in here, you can see finetuning, ING.<br>
So every single, you know, verb in the gerund, you know, fine-tuning<br>
or tokenizing all has ING and that maps<br>
onto the token 278 here.<br>
And when you decode it with the same tokenizer,<br>
it turns back into the same text.<br>
Now there are a lot of different tokenizers and<br>
a tokenizer is really associated with<br>
a specific model for each model as it was trained on it.<br>
And if you give the wrong tokenizer to your model, it'll<br>
be very confused because it will expect different numbers<br>
to represent different sets of letters<br>
and different words.<br>
So make sure you use the right tokenizer and you'll<br>
see how to do that easily in the lab.<br>
Cool, so let's head over to the notebook.<br>
Okay, so first we'll import a few different libraries and<br>
actually the most important one to see here is the AutoTokenizer class<br>
from the Transformers library by HuggingFace.<br>
And what it does is amazing.<br>
It automatically finds the right tokenizer or for your<br>
model when you just specify what the model is. So all you have to do<br>
is put the model and name in, and this is the same<br>
model name that you saw before, which is a 70<br>
million Pythium base model.<br>
Okay, so maybe you have some text that says,<br>
you know, hi, how are you?<br>
So now let's tokenize that text.<br>
So put that in, boom.<br>
So let's see what encoded text is.<br>
All right, so that's different numbers representing<br>
text here.<br>
Tokenizer outputs a dictionary with input<br>
IDs that represent the token, so I'm just printing that here.<br>
And then let's actually decode that back into the text and see if it actually<br>
turns back into hi, how are you?<br>
Cool, awesome, it turns back into hi, how are you, so that's great.<br>
All right, so when tokenizing, you probably are putting<br>
in batches of inputs, so let's just take a look at<br>
a few different inputs together, so there's hi, how are you, I'm good, and<br>
yes.<br>
So putting that list of text through, you can just put it<br>
in a batch like that.<br>
Into the tokenizer, you get a few different things here.<br>
So here's hi, how are you again.<br>
I'm good, it's smaller.<br>
And yes, it's just one token.<br>
So as you can see, these are varying in length.<br>
Actually, something that's really important for models is<br>
that everything in a batch is the same length, because<br>
you're operating with fixed size tensors.<br>
And so the text needs to be the same.<br>
So one thing that we do do is something called padding.<br>
Padding is a strategy to handle these variable length encoded texts.<br>
Um, and for our padding token, you have to specify, you know,<br>
what you want to, what number you want to represent for,<br>
for padding. And specifically we're using a zero, which<br>
is actually the end of sentence token as well.<br>
So when we run, padding equals true through the tokenizer,<br>
you can see the yes string has a lot of<br>
zeros padded there on the right, just to match the length of this hi,<br>
how are you string.<br>
Your model will also have a max length that it can handle<br>
and take in so it can't just fit everything in and you've played<br>
with prompts before and you've noticed probably that there is a<br>
limit to the prompt length and so this is the same thing<br>
and truncation is a strategy to handle making<br>
those encoded text much shorter and that fit<br>
actually into the model so this is one way to make it<br>
shorter so as you can see here I'm just artificially changing<br>
the max length to three, setting truncation to true,<br>
and then seeing how it's,much shorter now, for hi, how<br>
are you?<br>
It's truncating from the right, so it's just getting rid of everything here<br>
on the right.<br>
Now, realistically, actually one thing that's<br>
very common is, you know, you're writing a prompt, maybe you have your instruction<br>
somewhere,and you have a lot of the important things maybe on<br>
the other side,on the right and that's getting truncated out.</p>
<p>So, you know, specifying truncation side to<br>
the left actually can truncate it the other way.<br>
So this really depends on your task.<br>
And realistically for padding and truncation,<br>
you want to use both. So let's just actually set both in there. So<br>
truncation's true and padding's true here.<br>
I'm just printing that out so you can see the zeros here, but<br>
also getting truncated down to three.<br>
Great, so that was really a toy example.<br>
I'm going to now paste some code that you did in<br>
the previous lab on prompts.<br>
So here it's loading up the data set file with the<br>
questions and answers, putting it into the prompt, hydrating<br>
those prompts all in one go.<br>
So now you can see one data point here of question and answer.<br>
So now you can run this tokenizer on<br>
just one of those data points.<br>
So first concatenating that question with that answer and<br>
then running it through the tokenizer. I'm<br>
just returning the tensors as a NumPy array<br>
here just to be simple and running it<br>
with just padding and that's because I don't know how long these tokens actually<br>
will be, and so what's important is that<br>
I then figure out, you know, the minimum between the max length and<br>
the tokenized inputs.<br>
Of course, you can always just pad to the longest.<br>
You can always pad to the max length and so that's<br>
what that is here.<br>
And then I'm tokenizing again with truncation up<br>
to that max length.<br>
So let me just print that out.<br>
And just specify that in the dictionary, and cool.<br>
So that's what the tokens look like.<br>
All right, so let's actually wrap this into a full-fledged function<br>
so you can run it through your entire<br>
data set.<br>
So this is, again, the same things happening here<br>
that you already looked at, grabbing the max length,<br>
setting the truncation side.<br>
So that's a function for tokenizing your data set.<br>
And now what you can do is you can load up that dataset.<br>
There's a great map function here. So you can map the tokenize<br>
function onto that dataset.<br>
And you'll see here I'm doing something really simple.<br>
So I'm setting batch size to one, it's very simple.<br>
It is gonna be batched and dropping last batch true. That's<br>
often what we do to help with mixed size inputs.<br>
And so the last batch might be a different size.<br>
Cool.<br>
Great, and then so the next step is to split the data set.<br>
So first I have to add in this labels columns<br>
as for hugging face to handle it, and then I'm going to run this<br>
train test split function, and I'm going<br>
to specify the test size as 10% of the data.<br>
So of course you can change this depending on how<br>
big your data set is.<br>
Shuffle's true, so I'm randomizing the order of this<br>
data set.<br>
I'm just going to print that out here.<br>
So now you can see that the data set has been split<br>
across training and test set, 140 for a test set there.<br>
And of course this is already loaded up<br>
in Hugging Face like you had seen before,<br>
so you can go there and download it and see<br>
that it is the same.<br>
So while that's a professional data set, it's about<br>
a company, maybe this is related to your<br>
company for example, you could adapt it to your company.<br>
We thought that might be a bit boring, it doesn't have to be, so<br>
we included a few more interesting datasets that you<br>
can also work with and feel free to customize and train your<br>
models for these instead.<br>
One is for Taylor Swift, one's for the popular band BTS, and<br>
one is on actually open source large language models<br>
that you can play with.<br>
And just looking at, you know, one data point from the TayTay dataset,<br>
let's take a look.<br>
All right, what's the most popular.<br>
Taylor Swift song among millennials?<br>
How does this song relate to the millennial generation?<br>
Okay, okay.<br>
So, you can take a look at this yourself and yeah,<br>
these data sets are available via HuggingFace.<br>
And now in the next lab, now that you've<br>
prepped all this data, tokenized it, you're ready<br>
to train the model.</p>
<h1 id="training-process">Training process</h1>
<p>In this lesson, you'll step through the entire training process, and<br>
at the end see the model improve on your task, specifically<br>
for you to be able to chat with it.<br>
Alright, let's jump into it.<br>
Alright, training in LLM, what does this look like?<br>
So, the training process is actually quite similar to other<br>
neural networks.<br>
So, as you can see here, you know, the same setup that we<br>
had seen the LLM predict &quot;sd!!@&quot;.<br>
What's going on?<br>
Well, first you add that training data up at the top.<br>
Then you calculate the loss, so it predicts something<br>
totally off in the beginning, predict the loss compared<br>
to the actual response it was supposed to give, that's<br>
a pawn.<br>
And then you update the weights, you back prop through<br>
the model to update the model to improve it,<br>
such that in the end it does learn to then<br>
output something like a pawn.<br>
There are a lot of different hyperparameters that<br>
go into training LLMs.<br>
We won't go through them very specifically, but<br>
across a few that you might want to play with is learning<br>
rate, learning scheduler, and various optimizer hyperparameters<br>
as well.<br>
All right, so now diving a level deeper into the code.<br>
So these are just general chunks of training<br>
process code in PyTorch.<br>
So first you want to go over the number of epochs,<br>
an epoch is a pass over your entire data set.<br>
So you might go over your entire data set multiple times.<br>
And then you want to load it up in batches.<br>
So that is those different batches that you saw when you're<br>
tokenizing data.<br>
So that's sets of data together.<br>
And then you put the batch through your<br>
model to get outputs.<br>
You compute the loss from your model and<br>
you take a backwards step and you update your optimizer.<br>
Okay. So now that you've gone through every step<br>
of this low level code in PyTorch, we're actually<br>
going to go one level higher into HuggingFace and<br>
also another level higher into the Llama library by<br>
Llama and I, just to see how the training<br>
process works in practice in the lab.<br>
So let's take a look at that.<br>
Okay.<br>
So first up is seeing how the training<br>
process has been simplified over time, quite a bit with<br>
higher and higher level interfaces, that PyTorch code you saw.<br>
Man, I remember running that during my PhD.<br>
Now there are so many great libraries out<br>
there to make this very easy.<br>
One of them is the Lamini Llama library, and it's just training your model in<br>
three lines of code that's hosted on an external GPU, and it<br>
can run any open source model, and you can get the model back.<br>
And as you can see here, it's just requesting that 410<br>
million parameter model.<br>
You can load that data from that same JSON lines file,<br>
and then you just hit &quot;model.train&quot;.<br>
And that returns a dashboard, a playground interface,<br>
and a model ID that you can then call and continue training<br>
or run with for inference.<br>
All right, so for the rest of this lab, we're<br>
actually going to focus on using the Pythia<br>
70 million model.<br>
You might be wondering why we've been playing with that really small, tiny<br>
model, and the reason is that it can run on CPU nicely<br>
here for this lab, so that you can actually see<br>
the whole training process go.<br>
But realistically, for your actual use cases,<br>
I recommend starting with something a bit larger,<br>
maybe something around a billion parameters,<br>
or maybe even this 400 million one if your task<br>
is on the easier side.<br>
Cool.<br>
So first up, I'm going to load up all of these libraries, And<br>
one of them is a utilities file with a bunch of different<br>
functions in there.<br>
Some of them that we've already written together on the tokenizer,<br>
and others you should take a look at for just logging and showing<br>
outputs.<br>
So first let's start with the different configuration parameters<br>
for training.<br>
So there are two ways to actually, you know, import data. You've<br>
already seen those two ways. So one is just not<br>
using HuggingFace necessarily, you just specify a certain dataset path.</p>
<p>Another one, you could specify a HuggingFace path,<br>
and here I'm using a boolean value, use HuggingFace, to<br>
specify whether that's true.<br>
We include both for you here so you can easily use it.<br>
Again, we're going to use a smaller model so that it runs on CPU, so<br>
this is just 70 million parameters here.<br>
And then finally, I'm going to put all of<br>
this into a training config, which will be then passed<br>
onto the model, just to understand, you know, what<br>
the model name is and the data is.<br>
Great.<br>
So the next step is the tokenizer.<br>
You've already done this in the past lab, but<br>
here again, you are loading that tokenizer and then<br>
splitting your data.<br>
So here's just the training and test set, and<br>
this is loading it up from HuggingFace.<br>
Next just loading up the model, you already specified<br>
the model name above.<br>
So that's 70 million parameter Pythia model.<br>
I'm just going to specify that as the base model, which hasn't been<br>
trained yet.<br>
Next an important piece of code.<br>
If you're using a GPU, this is PyTorch code that<br>
will be able to count how many CUDA devices, basically<br>
how many GPUs you have.<br>
And depending on that, if you have more than zero of them,<br>
that means you have a GPU.<br>
So you can actually put the model on GPU.<br>
Otherwise it'll be CPU.<br>
In this case, we're going to be using CPU.<br>
You can see select CPU device.<br>
All right. So just to put the model on that GPU or CPU,<br>
you just have to do the model to device.<br>
So very simple.<br>
So now this is printing out the, you know,<br>
what the model looks like here, but it's putting it on that device.<br>
All right.<br>
So putting together steps from the previous lab,<br>
but also adding in some new steps is inference.<br>
So you've already seen this function before, but<br>
now stepping through exactly what's going on.<br>
So first you're tokenizing that text coming in.<br>
You're also passing in your models.<br>
So that's the model here, and you want the model to<br>
generate based on those tokens.<br>
Now the tokens have to be put onto the same device so that,<br>
you know, if the model is on GPU, for example, you need to put the<br>
tokens on GPU as well. So the model can actually see it.<br>
And then next there's an important, you know, max input tokens and max<br>
output tokens here as parameters for specifying, you<br>
know, how many tokens can actually be put into the<br>
model as input. And then how many do you expect out?<br>
We're setting this to a hundred here as a default, but<br>
feel free to play with this make it longer so it generates<br>
more.<br>
Note that it does take time to generate<br>
more so expect a difference in the time<br>
it takes to generate.<br>
Next the model does generate some tokens out<br>
and so all you have to do is decode it with that<br>
tokenizer just like you saw before and here<br>
after you decode it you just have to<br>
strip out the prompt initially because it's<br>
just outputting both the prompt with your generated<br>
output and so I'm just having that return that<br>
generated text answer.<br>
So great this function you're going to be using a lot.<br>
So first up is taking a look at that first<br>
test set question and putting it through the model and<br>
try not to be too harsh and I know you've<br>
already kind of seen this before so again<br>
the model is answering this really weird way<br>
that you've seen before.<br>
It's not really answering the question which<br>
is here and the correct answer is here.<br>
Okay so this is what training is for.<br>
So next you're going to look at the training arguments.<br>
So there are a lot of different arguments.<br>
First, key in on a few.<br>
So the first one is the max number of steps<br>
that you can run on the model.<br>
So this is just max number of training steps.<br>
We're gonna set that to three just to make it very simple, just<br>
to walk through three different steps.<br>
What is a step exactly?<br>
A step is a batch of training data.<br>
And so if your batch size is one, it's just one data point. If<br>
your batch size is 2,000, it's 2,000 data points.<br>
Next is the trained model name. So what do you want to call it?<br>
So here I'm calling it the name of a dataset, plus,<br>
you know, the max steps here so that we can differentiate<br>
it if you want to play with different<br>
max steps and the word steps.<br>
Something I also think is the best practice that's<br>
not necessarily shown here is also to put<br>
the timestamp on the trained model because you<br>
might be experimenting with a lot of them.<br>
Okay, cool.<br>
So I'm now going to show you a big list of different training arguments.</p>
<p>There are a lot of good defaults here.<br>
And I think the ones to focus on is max steps.<br>
This is probably going to stop the model from running past those<br>
three steps that you specified up there.<br>
And then also the learning rate.<br>
There are a bunch of different arguments here.<br>
I recommend that you can dive deeper into this if you're<br>
curious and be able to play with a lot of these arguments.<br>
But here we're largely setting these as<br>
good defaults for you.<br>
Next, we've included a function that calculates the<br>
number of floating point operations for<br>
the model.<br>
And so that's just flops and understanding the memory footprint of<br>
this base model.<br>
So here, it's just going to print that out here.<br>
This is just for your knowledge, just to understand what's going on.<br>
And we'll be printing that throughout training.<br>
And I know we said that this was a tiny, tiny model, but even here,<br>
look how big this model is here with 300 megabytes.<br>
So you can imagine a really large model to take up a<br>
ton of memory and this is why we need really high performing<br>
large memory GPUs to be able to run those larger models.<br>
Next you load this up in the trainer class.<br>
This is a class we wrapped around HuggingFaces<br>
main trainer class basically doing the same thing<br>
just printing out things for you as you train and as you<br>
can see you put a few things in. The main things are the base model,<br>
you put in you know max steps, the training arguments,<br>
and of course, your data sets you want to put in there.<br>
And the moment you've been waiting for.<br>
It is training the models.<br>
You just do &quot;trainer.train&quot;.<br>
And let's see it go.<br>
Okay.<br>
Okay. So as you can see, it printed out a lot<br>
of different things in the logs, namely the loss.<br>
If you run this for more steps, even just 10 steps, you'll<br>
see the loss start to go down.<br>
All right.<br>
So now you've trained this model.<br>
Let's save it locally.<br>
So you can have a save directory, maybe specifying the output<br>
deer and the final as a final checkpoint.<br>
And then all you have to do is &quot;trainer.savemodel&quot;.<br>
And let's see if it saved right here.<br>
So awesome, great work.<br>
Now that you've saved this model, you can actually load it up by just saying,<br>
you know,<br>
this auto model again from pre-trained and the save directory and you<br>
just have to specify local files equals true.<br>
So it doesn't pull from the HuggingFace hub in the cloud.<br>
I'm going to call this slightly fine-tuned model,<br>
or fine-tuned slightly model.<br>
And then I'm going to put this on the right device again.<br>
This is only important if you have a GPU, really,<br>
but here for CPU, just for good measure.<br>
And then let's run it. Let's see how it does.<br>
So let's see how it does on the test set again, or<br>
test data point again, and then just run inference.<br>
Again, this is the same inference function that you've<br>
run before.<br>
Cool.<br>
So is it any better? Not really.<br>
And is it supposed to be? Not really. It's<br>
only gone through a few steps.<br>
So what should it have been?<br>
Let's just take a look at that exact answer.<br>
So it's saying, yes, LAMNI can generate technical<br>
documentation user manuals.<br>
So it's it's very far from it. It's actually very similar still to that<br>
base model.<br>
Ok, but if you're patient, what could it look like?<br>
So we also fine tuned a model for far longer than that.<br>
So this model was only trained on three<br>
steps and actually in this case, three data points out of 1,260<br>
data points in the training data set.<br>
So instead we actually fine-tuned it on the entire data<br>
set twice for this &quot;lamini_docs_finetunemodel&quot; that we uploaded to HuggingFace that you<br>
can now download and actually use.<br>
And if you were to try this on your own computer,<br>
it might take half an hour or an hour, depending on your processor.<br>
Of course, if you have a GPU, it could just take a couple minutes.<br>
Great. So let's run this.<br>
Okay, this is a much better answer, and it's comparable to the<br>
actual target answer.<br>
But as you can see here at the end, it still starts to<br>
repeat itself additionally and laminize. So it's not perfect, but<br>
this is a much smaller model, and you could train it<br>
for even longer too.<br>
And now just to give you a sense of what<br>
a bigger model might do, This one was trained to be maybe a<br>
little bit less robust and repetitive.<br>
This is what a bigger 2.8 billion fine-tuned model would be.<br>
And this is running the LLAMA library with the same basic model<br>
runner as before.<br>
So here you can see, yes, LLAMA and I can generate technical<br>
documentation or user manuals.<br>
Ok, great.<br>
So one other thing that's kind of interesting in this dataset<br>
that we use to fine-tune that you can also do for your<br>
datasets is doing something called moderation,<br>
and encouraging the model to<br>
actually not get too off track.<br>
And if you look closely at the examples in this data set,<br>
which we're about to do, you'll see that there are examples that say, let's keep<br>
the discussion relevant to llamini.<br>
I'm going to loop through the data set here<br>
to find all the data points that say that, so<br>
that you can go see that yourself.<br>
So this is how you might prepare your own data set.<br>
And as a reminder, this is very similar to chat GPT.<br>
Sorry, i'm an AI and I can't answer that. So they're using a<br>
very similar thing here.<br>
So points it to the documentation to take a look<br>
at the fact that there isn't anything about Mars.<br>
All right, so now that you've run all of training here, you<br>
can actually do all of that in just three lines<br>
of code using Llamani's Llama library.<br>
And all you have to do is load up the model,<br>
load up your data and train it.<br>
And specifically here, we're running a slightly larger model.<br>
So the Pythia 410 million model, It's the biggest model that's available<br>
for a free tier.<br>
And then Llamani docs, you can load that up through a JSON<br>
lines file just like you did before and all you have to<br>
do is run &quot;model.train&quot;. I'm running is public is true. So this<br>
is a public model that anyone can then<br>
run afterwards.<br>
Put that through instead of the Pythia 410<br>
in the basic model runner to then run it.<br>
You can also click on this link here to sign up,<br>
make an account.<br>
Basically you can see the results.<br>
You can run a chatbot there, kind of interface there to<br>
be able to see everything, but since is public is true,<br>
we can actually just look at the model<br>
results here on the command line, So &quot;model.evaluate&quot;, run that. And<br>
here you can see, again, the same job ID. For this job ID, you<br>
can see all the evaluation results that were<br>
data points that were not trained on.<br>
And so just to pretty print this a little bit into a data frame, I'm<br>
gonna plop some code in here to reformat that.<br>
So this is just code that is reformatting that into a nice<br>
data frame from that list of dictionaries.<br>
Cool.<br>
And here you can see a lot of different, you know, questions and then answer<br>
from the train model versus the base model.<br>
So this is an easy way to compare those results.<br>
So here's a question. Does Lamini have the ability to understand<br>
and generate code for audio processing tasks?<br>
And you can see that the train model<br>
actually gave an answer. Yes, Lamini has the ability to understand,<br>
and generic codes not quite there yet. This is really a baby<br>
model and a very limited data, but it is much<br>
better than this base model that answers a colon.<br>
all nice a very good language for audio processing A<br>
colon. You know, yes, Lamini has the ability<br>
to understand and generate code. It's not quite there yet, so<br>
this is a really baby model with very limited data, but<br>
it. It is much better than this base model that<br>
answers with A colon, I think you are looking<br>
for a language that can be used to<br>
write audio code just very often, it keeps rambling.<br>
So a very big difference in performance.<br>
And now you can see a different question here,<br>
you know, is it possible to control the level of<br>
detail in the generated output?<br>
So as you can see, you can go through all these<br>
results and in the next lab, we'll actually explore how to evaluate<br>
all of these results.</p>
<h1 id="evaluation-and-iteration">Evaluation and iteration</h1>
<p>Now that you've finished training your model, the<br>
next step is to evaluate it, see how it's doing.<br>
This is a really important step because AI<br>
is all about iteration.<br>
This helps you improve your model over time.<br>
Okay, let's get to it.<br>
Evaluating generative models is notoriously very, very difficult.<br>
You don't have clear metrics and the performance of these<br>
models is just improving so much over time<br>
that metrics actually have trouble keeping up.<br>
So as a result, human evaluation is often the most reliable way of<br>
doing so, so that's actually having experts who<br>
understand the domain actually assess the outputs.<br>
A good test data set is extremely important<br>
to making this actually a good use of that person's time, and<br>
that means it's a high quality data set, it's accurate, so<br>
you've gone through it to make sure that it<br>
is accurate.<br>
It's generalized so it actually covers a lot of<br>
the different test cases you want to make<br>
sure the model covers and of course it can't be<br>
seen in the training data.<br>
Another popular way that is emerging is ELO comparison<br>
so that's looking almost like a A-B test between multiple models or tournament across<br>
multiple models.<br>
ELO rankings are used in chess specifically and so this is one<br>
way of also being able to understand and which<br>
models are performing well or not.<br>
So one really common open LLM benchmark is a suite of different<br>
evaluation methods.<br>
So it's actually taking a bunch of different possible evaluation methods<br>
and averaging them all together to rank models.<br>
And this one is developed by EleutherAI, and it's a set of different<br>
benchmarks put together.<br>
So one is ARC. It's a set of grade school questions.<br>
HellaSwag is a test of common sense.<br>
MMLU covers a lot of elementary school subjects,<br>
and TruthfulQA measures the model's ability to reproduce<br>
falsehoods that you can commonly find online.<br>
And so these are a set of benchmarks<br>
that were developed by researchers over time and<br>
now have been used in this common evaluation suite.<br>
And you can see here this is the latest ranking as of this recording,<br>
but I'm sure this changes all the time.<br>
Llama 2 is doing well.<br>
This is actually not necessarily sorted by the average here.<br>
Llama 2 is doing well. There's recently a free willy<br>
model that was fine-tuned on top of the Llama 2<br>
model using what's known as the Orca method, which is why<br>
it's called free willy.<br>
Not going to go into that too much.<br>
There are a lot of animals going on right here,<br>
but feel free to go check it out yourself.<br>
Okay, so one other framework for analyzing<br>
and evaluating your model is called error analysis.<br>
And what this is is categorizing errors so that you understand the<br>
types of errors that are very common, and going after the<br>
very common errors and the very catastrophic errors first.</p>
<p>This is really cool because error analysis usually requires<br>
you to first train your model first beforehand.<br>
But of course, for fine-tuning, you already have a base model that's been<br>
pre-trained. So you can already perform error analysis before you<br>
even fine-tune the model.<br>
This helps you understand and characterize how the<br>
base model is doing, so that you know what<br>
kind of data will give it the biggest lift for fine-tuning.<br>
And so there are a lot of different categories.<br>
I'll go through a few common ones that you can take a look at.<br>
So one is just misspellings. This is very straightforward,<br>
very simple.<br>
So here it says, go get your liver or lover checked,<br>
and it's misspelled.<br>
And so just fixing that example in your<br>
data set is important to just spell it correctly.<br>
Length is a very common one that I hear about chat GPT<br>
or generative models in general.<br>
They really are very verbose.<br>
And so one example is just making sure your data set is<br>
less verbose to make it so that it actually is answering the<br>
question very succinctly. And you've already seen that in the<br>
training notebook where we're able to do a bit of that in the models, less<br>
verbose and less repetitive.<br>
And speaking of repetitive, these models do tend<br>
to be very repetitive.<br>
And so one way to do that is to fix it with either stop tokens<br>
more explicitly, those prompt templates you saw,<br>
but of course, also making sure your<br>
dataset includes examples that don't have as much repetition<br>
and do have diversity.<br>
Cool, so now on to a lab where you get to run the model across a test<br>
dataset and then be able to run a few different metrics,<br>
but largely inspect it manually and also run<br>
on one of those LLM benchmarks that you saw, Arc.<br>
Okay, so this actually can be done in just a line of code,<br>
which is running your model on your entire test data<br>
set in a batched way that's very efficient on GPUs. And<br>
so I just wanted to share that here, which is you can load<br>
up your model here and instantiate it and<br>
then have it just run on a list of your entire test data set. And<br>
then it's automatically batched on GPUs<br>
really quickly.<br>
Now we're really largely running on CPUs here.<br>
So for this lab, you'll get to actually just run<br>
it on a few of the test data points.<br>
And then of course you can do more on your own as well.<br>
Okay, great.<br>
So I think the first thing is to load up<br>
the test data set that we've been working with.<br>
And then let's take a look at what one of those data points looks like.<br>
So I'm just going to print question answer pair.<br>
All right, so this is one that we've been looking at.<br>
And then we want to load up the model to<br>
run it over this entire data set.<br>
So this is the same as before.<br>
I'm going to pull out the actual fine-tuned model<br>
from HuggingFace.<br>
Okay so now we've loaded up our model and I'm gonna<br>
load up one really basic evaluation metric just<br>
for you to get a sense of this generative task and it's gonna be<br>
whether it's an exact match between two strings of<br>
course stripping a little bit of white space<br>
but just getting a sense of whether it<br>
can be an exact match.<br>
This is really hard for those writing tasks because it's<br>
generating content there are actually a lot of different<br>
possible to write answers, so it's not<br>
a super valid evaluation metric.<br>
For reading, quote unquote, tasks, those reading tasks,<br>
you might be extracting topics out. You might be<br>
extracting some information out. So maybe in those cases where it's<br>
closer to classification, this might make more sense.<br>
But I just want to run this through.<br>
You can run different evaluation metrics through as well.<br>
An important thing when you're running a model in evaluation<br>
mode is to do &quot;model.eval&quot; to make sure things like dropout<br>
is disabled.<br>
And then just like in previous labs, you can run this<br>
inference function to be able to generate output.<br>
So let's run that first test question again.<br>
Again, you get that output and look at the actual answer,<br>
compare it to that, and it's similar, but it's not quite there.<br>
So of course, when you run exact match, it's<br>
not perfect.<br>
And that's not to say there aren't other ways of measuring these models.<br>
This is a very very simple way.<br>
Sometimes people also will take you know these<br>
outputs and put it into another LLM to<br>
ask it and grade it to see how well you know how<br>
close is it really.<br>
You can also use embedding so you can embed the actual answer<br>
and actually embed the generated answer and see how<br>
close they are in distance.<br>
So there are a lot of different approaches<br>
that you can take.<br>
Cool so now to run this across your entire data set,<br>
this is what that might look like.<br>
So let's just actually run it over 10 since it takes quite<br>
a bit of time.<br>
You're going to iterate over that data set, pull<br>
out the question and answers.<br>
Here I'm also trying to take the predicted answer and<br>
actually append it with the other answers so<br>
that you can inspect it manually later, and<br>
then take a look at the number of exact matches, and<br>
it's just evaluating here.<br>
So the number of exact matches is zero, and that's not actually super surprising<br>
since this is a very generative task.<br>
And typically for these tasks, you know, there again are a lot of<br>
different ways of approaching evaluation,<br>
but at the end of the day, what's been found to be<br>
significantly more effective by a large margin is<br>
using manual inspection on a very curated test set.<br>
And so this is what that data frame looks like.<br>
So now you can go inspect it and see, okay, for every predicted answer,<br>
what was the target and how close was it really?<br>
Okay, cool. So that's only on a subset of the data.<br>
We also did evaluate it on all of the data here that you can go load<br>
from HuggingFace and be able to basically see<br>
and evaluate manually all the data.<br>
And last but not least, you'll get to see running Arc, which<br>
is a benchmark.<br>
So if you're curious about academic benchmarks, this<br>
was one that you just explored across that test suite of different<br>
LLM benchmarks. And this ARC benchmark, as<br>
a reminder, is one of those four that EleutherAI came up<br>
with and put together, and these are from academic papers.</p>
<p>And for this one, if you inspect the data set, you'll<br>
find science questions that may or may not be related to your<br>
task.<br>
And these evaluation metrics, especially here, are just very good<br>
for academic contests or understanding, you know,<br>
general model abilities sometimes around these,<br>
in this case, basic grade school questions.<br>
But I actually really recommend, you know, even even as<br>
you run these to not necessarily be too caught up on the<br>
performance on these benchmarks, even though this is how<br>
people are ranking models now, and that's because they don't correlate<br>
with your use case.<br>
They are not necessarily related to what your company cares about,<br>
what you actually care about for your end<br>
use case for that fine-tuned model.<br>
And as you can probably see, the fine-tuned models are able to<br>
basically get tailored to a ton of different<br>
tasks which require a ton of different ways<br>
of evaluating them.<br>
Okay, so the ARC benchmark just finished running and<br>
the score is right here, 0.31, and actually that is lower<br>
than the base model score in the paper, which<br>
is 0.36, which is crazy because you saw it improve<br>
so much on this.<br>
But it's because it improves so much on this company<br>
dataset related to this company, related<br>
to question answering for it, and not grade school science.<br>
So that's what ARC is really measuring.<br>
Of course, if you fine-tune a model on general tasks, so<br>
if you fine-tune it on alpaca, for example, you should see a little bit<br>
of a bump in that performance for this<br>
specific benchmark. And if you use a larger model you'll also see<br>
a likely bump as well because it's learned much more.</p>
<p>And that's basically it. So as you can see this.<br>
ARC benchmark probably only matters if you're<br>
looking at general models and comparing general models.<br>
Maybe that's finding a base model for you to use but not<br>
for your actual fine-tuning task. It's not very<br>
useful unless you're fine-tuning the model to do grade school science questions.</p>
<p>All right and that's a for the notebooks.<br>
In the last lesson you'll learn some practical tips for fine-tuning and<br>
then a sneak peek of more advanced methods.</p>
<h1 id="consideration-on-getting-started-now">Consideration on getting started now</h1>
<p>All right, you made it to our last lesson and<br>
these will be some considerations you should take<br>
on getting started now, some practical tips, and also a bit<br>
of a sneak preview on more advanced training methods.<br>
So first, some practical steps to fine-tuning.<br>
Just to summarize, first you want to figure out your task,<br>
you want to collect data that's related to your tasks<br>
inputs and outputs and structure it as such.<br>
If you don't have enough data, no problem, just generate some or use<br>
a prompt template to create some more.<br>
And first, you want to fine tune a small model.<br>
I recommend a 400 million to a billion<br>
parameter model just to get a sense of<br>
where the performance is at with this model.<br>
And you should vary the amount of data you actually give to<br>
the model to understand how much data actually influences<br>
where the model is going.<br>
And then you can evaluate your model to see what's<br>
going well or not.<br>
And finally, you want to collect more data to improve<br>
the model through your evaluation.<br>
Now, from there, you can now increase your task complexity,<br>
so you can make it much harder now.<br>
And then you can also increase the model<br>
size for performance on that more complex task.<br>
So for task-defined tune, you learned about, you know, reading<br>
tasks and writing tasks.<br>
Writing tasks are a lot harder.<br>
These are the more expansive tasks like chatting,<br>
writing emails, writing code, and that's because there are more<br>
tokens that are produced by the model.<br>
So this is a harder task in general for the model.<br>
And harder tasks tend to result in needing<br>
larger models to be able to handle them.<br>
Another way of having a harder task is<br>
just having a combination of tasks, asking the model to<br>
do a combination of things instead of just one task.<br>
And that could mean having an agent be<br>
flexible and do several things at once or in just in one<br>
step as opposed to multiple steps.<br>
So now that you have a sense of model sizes that you<br>
need for your task complexity, there's also a compute requirement<br>
basically around hardware of what you need to run your models.</p>
<p>For the labs that you ran, you saw those 70 million<br>
parameter models that ran on CPU.<br>
They weren't the best models out there.<br>
And I recommend starting with something a little<br>
bit more performant in general.<br>
So if you see here in this table, the first row,<br>
I want to call out of a &quot;1 V100&quot; GPU that's available, for example, on<br>
AWS, but also any other cloud platform and you see<br>
that it has 16 gigabytes of memory and<br>
that means it can run a 7 billion parameter model for inference<br>
but for training, training needs far more memory for to<br>
store the gradients and the optimizers so it only can actually fit<br>
a 1 billion parameter model and if you want to fit a<br>
larger model you can see some of the other options available here<br>
great so maybe you thought that that was not enough for you<br>
you want to work with much larger models?<br>
Well, there's something called PEFT or parameter efficient fine tuning, which<br>
is a set of different methods that help<br>
you do just that, be much more efficient in how you're using<br>
your parameters and training your models.<br>
And one that I really like is LoRa, which stands for low rank adaptation.</p>
<p>And what LoRa does is that it reduces<br>
the number of parameters you have to train<br>
weights that you have to train by a huge amount.<br>
For GPT-3, for example, they found that they could<br>
reduce it by 10,000x, which resulted in 3x less memory needed<br>
from the GPU.<br>
And while you do get slightly below accuracy to fine<br>
tuning, this is still a far more efficient way<br>
of getting there and you get the same<br>
inference latency at the end.<br>
So what is exactly happening with LoRa?<br>
Well, you're actually training new weights in<br>
some of the layers of the model and you're freezing<br>
the main pre-trained weights, which you see<br>
here in blue.<br>
So that's all frozen and you have these new orange weights.<br>
Those are the LoRa weights.<br>
And the new weights, and this gets a little bit mathy,<br>
are the rank decomposition matrices of<br>
the original weights change.<br>
But what's important is less so, you know, the math behind that here, it's<br>
that you can train these separately, alternatively to<br>
the pre-trained weights, but then at<br>
inference time be able to merge them back into the<br>
main pre-trained weights and get that fine-tuned model more efficiently.</p>
<p>What I'm really excited about to use LoRa for is adapting it to new<br>
tasks and so that means you could train<br>
a model with LoRa on one customer's data<br>
and then train another one on another customer's data and<br>
then be able to merge them each in at inference time when<br>
you need them.</p>
<h1 id="conclusion">Conclusion</h1>
<p>All right, you made it to our last lesson and<br>
these will be some considerations you should take<br>
on getting started now, some practical tips, and also a bit<br>
of a sneak preview on more advanced training methods.<br>
So first, some practical steps to fine-tuning.<br>
Just to summarize, first you want to figure out your task,<br>
you want to collect data that's related to your tasks<br>
inputs and outputs and structure it as such.<br>
If you don't have enough data, no problem, just generate some or use<br>
a prompt template to create some more.<br>
And first, you want to fine tune a small model.<br>
I recommend a 400 million to a billion<br>
parameter model just to get a sense of<br>
where the performance is at with this model.<br>
And you should vary the amount of data you actually give to<br>
the model to understand how much data actually influences<br>
where the model is going.<br>
And then you can evaluate your model to see what's<br>
going well or not.<br>
And finally, you want to collect more data to improve<br>
the model through your evaluation.<br>
Now, from there, you can now increase your task complexity,<br>
so you can make it much harder now.<br>
And then you can also increase the model<br>
size for performance on that more complex task.<br>
So for task-defined tune, you learned about, you know, reading<br>
tasks and writing tasks.<br>
Writing tasks are a lot harder.<br>
These are the more expansive tasks like chatting,<br>
writing emails, writing code, and that's because there are more<br>
tokens that are produced by the model.<br>
So this is a harder task in general for the model.<br>
And harder tasks tend to result in needing<br>
larger models to be able to handle them.<br>
Another way of having a harder task is<br>
just having a combination of tasks, asking the model to<br>
do a combination of things instead of just one task.<br>
And that could mean having an agent be<br>
flexible and do several things at once or in just in one<br>
step as opposed to multiple steps.<br>
So now that you have a sense of model sizes that you<br>
need for your task complexity, there's also a compute requirement<br>
basically around hardware of what you need to run your models.</p>
<p>For the labs that you ran, you saw those 70 million<br>
parameter models that ran on CPU.<br>
They weren't the best models out there.<br>
And I recommend starting with something a little<br>
bit more performant in general.<br>
So if you see here in this table, the first row,<br>
I want to call out of a &quot;1 V100&quot; GPU that's available, for example, on<br>
AWS, but also any other cloud platform and you see<br>
that it has 16 gigabytes of memory and<br>
that means it can run a 7 billion parameter model for inference<br>
but for training, training needs far more memory for to<br>
store the gradients and the optimizers so it only can actually fit<br>
a 1 billion parameter model and if you want to fit a<br>
larger model you can see some of the other options available here<br>
great so maybe you thought that that was not enough for you<br>
you want to work with much larger models?<br>
Well, there's something called PEFT or parameter efficient fine tuning, which<br>
is a set of different methods that help<br>
you do just that, be much more efficient in how you're using<br>
your parameters and training your models.<br>
And one that I really like is LoRa, which stands for low rank adaptation.</p>
<p>And what LoRa does is that it reduces<br>
the number of parameters you have to train<br>
weights that you have to train by a huge amount.<br>
For GPT-3, for example, they found that they could<br>
reduce it by 10,000x, which resulted in 3x less memory needed<br>
from the GPU.<br>
And while you do get slightly below accuracy to fine<br>
tuning, this is still a far more efficient way<br>
of getting there and you get the same<br>
inference latency at the end.<br>
So what is exactly happening with LoRa?<br>
Well, you're actually training new weights in<br>
some of the layers of the model and you're freezing<br>
the main pre-trained weights, which you see<br>
here in blue.<br>
So that's all frozen and you have these new orange weights.<br>
Those are the LoRa weights.<br>
And the new weights, and this gets a little bit mathy,<br>
are the rank decomposition matrices of<br>
the original weights change.<br>
But what's important is less so, you know, the math behind that here, it's<br>
that you can train these separately, alternatively to<br>
the pre-trained weights, but then at<br>
inference time be able to merge them back into the<br>
main pre-trained weights and get that fine-tuned model more efficiently.</p>
<p>What I'm really excited about to use LoRa for is adapting it to new<br>
tasks and so that means you could train<br>
a model with LoRa on one customer's data<br>
and then train another one on another customer's data and<br>
then be able to merge them each in at inference time when<br>
you need them.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[OpenAI CEO Sam Altman | AI for the Next Era - YouTube]]></title>
        <id>https://temberature.github.io/post/RQfND9th0/</id>
        <link href="https://temberature.github.io/post/RQfND9th0/">
        </link>
        <updated>2024-01-03T07:56:14.000Z</updated>
        <content type="html"><![CDATA[<p>https://www.youtube.com/watch?v=WHoWGNQRXb0</p>
<p>Transcript:<br>
(00:10) all right let's start a little bit more pragmatic but then we'll Branch out so one of the things I think a lot of folks here are interested in is based off the apis that very large models will create what are the real business opportunities like what are the ways to look forward and then how given the the apis will be available to multiple players how do you create distinctive businesses on him yeah um so I I think so far we've been in the realm where it's you know you can do like an incredible copywriting business or you can do like a sort of like Education Service or whatever um but we I don't think we've yet seen<br>
(00:50) the kind of like people go after the like you know trillion dollar like take on Google's um and I think that's about to happen like maybe it'll be successful maybe Google will do it themselves but like I would guess that with the quality of of language models we'll see in the coming years um you know there will be like a serious challenge to Google for the first time for for a search product um and I think people are really starting to think about like how did the fundamental things change um and that's going to be really powerful uh I think that a like a human level chat bot interface that actually works<br>
(01:28) this time around like I I think like you know many of these trends that like we all made fun of were just too early like the chatbot thing was good it was just too early now it can work and I think you know having like new medical services that are done through that where you get great advice or new Education Services like this these are going to be very large companies I think we'll get multimodal models and not that much longer and that'll open up new things I think people are doing amazing work with sort of agents that can use computers to do things for you use programs and this idea of like a language interface<br>
(02:02) um where you know you say a natural language what you want in this kind of like dialogue back and forth you can iterate and refine it and the computer just does it for you you see some of this uh with like Dolly and co-pilot in very early ways but I think this is going to be a massive Trend and you know very large businesses will get built with this as the interface and more generally that like these very powerful models will will be one of the genuine new technological platforms which we haven't really had since mobile and there's always like an explosion of new companies right after so that'll be cool and and what do you<br>
(02:38) what do you things are given that the large language model we provided as an API service what are the things that you think that folks who are thinking about these kind of AI businesses should think about is how do you create an enduring differentiated business so you know they're they're I think there will be a small handful of like fundamental large models out there that other people build on but right now what happens is you know company makes large language model API other people build on top of it and I think there will be a middle layer that becomes really important where uh I'm like skeptical of all of the<br>
(03:15) startups that are trying to sort of train their own models I don't think that's going to keep going but what I think will happen is there'll be a whole new set of startups that take an existing very large model of the future and tune it uh which is not just fine-tuning like all the things you can do I think there will be a lot of access provided to create the model for medicine or using a computer or like the kind of like friend or whatever and then those those companies will create a lot of enduring value because they will have like a special version of they won't have to have created the base model but<br>
(03:47) they will have created something they can use just for themselves or share with others that has this unique data flywheel going that sort of improves over time and all of that so I think there will be a lot of value created in that middle layer and what do you think some of the most surprising ones will be it's a little bit like for example you know a surprise from a couple years ago and we talked a little bit to Kevin Scott about this this morning as we opened up which is train on the internet do code right so so what do you think some of the the surprises will be of you didn't realize it reached that far<br>
(04:22) I think the biggest like systemic mistake in thinking people are making right now is they're like all right you know maybe I was skeptical but this language model thing is really going to work and sure like images video too but but it's not going to be generating net new knowledge for Humanity it's just going to like do what other people have done and you know that's still great that's still like brings the marginal cost of intelligence very low but it's not it's not going to go like create fundamentally new it's not going to cure cancer it's not going to add to the sum total of human scientific knowledge and<br>
(04:51) that is what I think will turn out to be wrong that most surprises the current experts in the field yep so uh let's go to science then there's the next thing what are some of the things whether it's building on the apis you know uh use of apis by scientists where what are some of the places where science will get accelerated and how so I think there's two things happening now and then a bigger third one later um one is there are these science dedicated products whatever like Alpha fold and those are adding huge amounts of value and you're gonna see in this like like way more and way more I like I<br>
(05:26) think I if I were like you know had time to do something else I would be so excited to like go after a bio company right now like I think you can just do amazing things there um the anyway but there's like another thing that's happening which is like tools that just make us all much more productive uh that help us think of new research directions that sort of write a bunch of our code so you know we can be twice as productive and that impact on like the net output of one engineer a scientist I think will be the surprising way that AI contributes to science that is like outside of the obvious models but even just seeing now like what I<br>
(06:04) think these tools are capable of doing copilot is an example there's you know be much cooler stuff than that um that will be a significant like change to the way that technological development scientific development happens but then so those are the two that I think are like huge now and uh lead to like just an acceleration of progress but then the big thing um that I think people are starting to explore is um I hesitate to use this word because I think there's one one way it's used which is fine and one that is more scary but uh like AI that can start to be like an AI scientist and self-improve and so<br>
(06:44) when like can we automate like can we automate our own jobs as AI developers very first the very first thing we do can that help us like solve the really hard alignment problems that we don't know how to solve like that honestly I think is how it's going to happen um the the scary version of self-improvement like the one from the science fiction books is like you know editing your own code and changing your optimization algorithm and whatever else um but there's a less scary version of self-improvement which is like kind of what humans do which is if we try to go off and like discover new science uh you know that's<br>
(07:21) like we come up with explanations we test them we think like we whatever process we do uh that is like special to humans teaching AI to do that I'm very excited to see what that does for the total like I'm a big believer that the only real driver of human progress and economic growth over the long term is the the structure the societal structure that enables scientific progress and then scientific progress itself and uh like I think we're gonna make a lot more of that well especially science that's deployed in technology say a little bit about how what uh I think probably most people understand what the alignment problem is<br>
(08:01) but it's probably worth four sentences on the alignment problem yeah so the alignment problem is like we're going to make this incredibly powerful system and like be really bad if it doesn't do what we want or or if it sort of has you know goals that are uh either in conflict with ours um and many Sci-Fi movies about what happens there or goals where it just like doesn't care about us that much and so the alignment problem is how do we build AGI that that does what is in the best interest of humanity how do we make sure that Humanity gets to determine the you know the future of humanity and how do<br>
(08:37) we avoid both like accidental misuse um like where something goes wrong we didn't intend intentional misuse where like a bad person is like using an AGI for great harm even if that's what other person wants and then the kind of like you know inner alignment problems where like what if this thing just becomes a creature that views this as a threat um the the way that I think the self-improving systems help us is not necessarily by the nature of self-improving but like we have some ideas about how to solve the alignment problem at small scale um and we've you know been able to align open ai's biggest models better than we<br>
(09:10) thought we'd we would at this point so that's good um we have some ideas about what to do next um but we cannot honestly like look anyone in the eye and say we see at 100 years how we're going to solve this problem um but once the AI is good enough that we can ask it to like hey can you help us do alignment research um I think that's going to be a new tool in the toolbox yeah like for example one of the conversations you and I had is could we tell the uh the the agent don't be racist right as opposed to trying to figure out all the different things where the weird correlative data that exists on all the training settings<br>
(09:46) everything else may lead to racist outcomes it could actually in fact do a self-cleansing totally once the model gets smart enough that you can that it really understands what racism looks like and how complex that is you can say don't be racist yeah exactly um what do you think are the kind of Moon shots that in terms of evolution of the next couple years that people should be looking out for in terms of like evolution of where AI we'll go um I'll start with like the higher certainty things I I think language models are going to go just much much further than people think and we're like very excited to see what<br>
(10:34) happens there um I think it's like what a lot of people say about you know running out of compute running out of data like that's all true but I think there's so much algorithmic progress to come that that we're going to have like a very exciting time um another thing is I think we will get true multimodal models working and so you know not just text and images but every modality you'd like in one model able to easily like uh you know fluidly move between things um I think we will have models that continuously learn so like right now if you use GPT whatever it's sort of like stuck in time that it was trained and<br>
(11:12) the more you use it it doesn't get any better and all of that I think we'll get that changed so very excited about all of that and if you just think about like what that alone is going to unlock and the sort of applications people will be able to build with that um that that that that that would be like a huge victory for all of us and just like a like a massive step forward and a genuine technological Revolution if that were all that happened um but I think we're likely to keep making research progress into new paradigms as well um we've been like pleasantly surprised on the upside about what seems to be happening and I think<br>
(11:50) uh you know all these questions about like new knowledge generation how do we really Advance Humanity uh I think there will be systems that can help us with that so one thing I think would be useful to share because uh folks don't realize that you're actually making these strong predictions from a fairly critical point of view not just a you know we can take that Hill say a little bit about some of the areas that you think are current kind of illusionally talked about like for example Ai and fusion oh yeah so I like one of the unfortunate things that's happened is uh you know AI has become like the Mega<br>
(12:29) buzzword um which is usually a really bad sign I hope I hope it doesn't mean like the field is about to fall apart um but historically that's like a very bad sign for you know new startup creation or whatever if everybody is like I'm this with AI and that's definitely happening now um so like a lot of the you know we were talking about like are there all these people saying like I'm doing like these you know RL models for Fusion or whatever and as far as we can tell they're all like much worse than what like you know smart physicists to figure it out um I think it is just an area where people are going to say uh everything is<br>
(13:02) now this plus AI many things will be true I do think this will be like the biggest technological platform of the Generation Um but I think it's like we like to make predictions where we can be on the frontier understand predictably what the scaling laws look like or already have done the research where we can say all right this new thing is going to work and make predictions out from that way and that's sort of like how we try to run open AI um which is you know do the next thing in front of us when we have high confidence and Kate take 10 of the company to just totally go off and explore which has led to huge wins and there<br>
(13:38) will be wait like oh I feel bad to say this like I I doubt we'll still be using the Transformers in five years I hope we're not I hope we find something way better but the transform has obviously been remarkable so I think it's important to always look for like you know where am I going to find the next the sort of the next totally new paradigm um and but but I I think like that's the way to make predictions don't don't pay attention to the like AI for everything like you know can I see something working and can I see how it predictably gets better and then of course leave room open for like the you can't plan<br>
(14:14) the greatness but sometimes it had the research breakthrough happens yep so I'm going to uh ask two more questions and then open it up because I want to make sure that people have a chance to do this uh the broader discussion although I'm trying to paint the broad picture so you can get the crazy aspirations as part of this what do you think uh what do you think is going to happen vis-a-vis the application of AI to like these very important systems like for example financial markets um you know because the very natural thing would be is saying well let's let's do a high frequency Quant trading<br>
(14:50) system on top of this and other kinds of things what what is it is it just kind of being a neutral arms race is it is it what how do how what's your thought in like it's almost like the life 3.0 yeah omega's point of view yeah um I mean I think it is going to just seep in everywhere my basic model of the next decade is that uh the cost of intelligence the marginal cost of intelligence and the marginal cost of energy are going to Trend rapidly towards zero like surprisingly far and and those I think are two of the major inputs into the cost of everything else except the cost of things we want to be expensive the<br>
(15:28) status Goods whatever and and I think you have to assume that's going to touch almost everything um because these like seismic shifts that happen when like the whole cost structure of society change which happened many times before um like the Temptation is always to underestimate those uh so I wouldn't like make a high confidence prediction about anything that doesn't change a lot or that where that doesn't get to be applied um but one of the things that is important is it's not like the thing Trends either Trends all the way to zero they just Trend towards there and so it's like someone will still be willing to spend a<br>
(16:06) huge amount of money on compute and energy they will just get like unimaginable amount of intelligence energy they'll just get unimaginable amounts about that and so like who's going to do that and where is it going to get the weirdest not because the cost comes way down but the amount spent actually goes way up yes the intersection of the two curves yeah you know the thing got 10 or 100 thing got 100 times cheaper in the cost of energy you know 100 million times cheaper in the cost of intelligence and I was still willing to spend a thousand times more in today's dollars like what happens then yep<br>
(16:36) and then uh last of the buzzword Bingo part of the the future questions metaverse and AI what do you what do you see coming in this you know I think they're like both independently cool things it's not like totally clear to me yeah other than like how AI will impact all Computing yeah well obviously Computing simulation environments Asians possibly possibly entertainment certainly education right um you know like an AI tutor and so forth those those would be Baseline but the question is is there anything that's occurred to you that's I I would bet that the metaverse turns out in the upside case then which I think has a reasonable<br>
(17:20) chance of happening the upside case the metaverse turns out to be more like something on the order of the iPhone like a new a new container for software and you know a new way a new computer interaction thing and AI turns out to be something on the order of like a legitimate technological Revolution um and so I think it's more like how the metaverse is going to fit into this like new world of AI then AI fit into the metaverse but low confidence the TBD all right questions hey there how do you see uh Technologies uh foundational Technologies like tpg3 affecting um the pace of life science research specifically you can group in medical<br>
(18:08) research there and and sort of just quickening the iteration cycles and then what do you see as the rate limiter in life science research and sort of where we won't be able to get past because they're just like laws of nature yeah something like that um so I think the currently available models are kind of not good enough to have like made a big impact on the field at least that's what like most like life sciences researchers have told me they've all looked at it and they're like it's a little helpful in some cases um there's been some promising work in genomics but like stuff on a bench top<br>
(18:41) hasn't really impacted it I think that's going to change and I think uh this is one of these areas where there will be these like you know new 100 billion to trillion dollar companies started those those areas are rare but like when you can really change the way that if you can really make like a you know future Pharma company that is just hundreds of times better than what's out there today that's going to be really different um as you mentioned there still will be like the rate limit of like bio has to run at its own thing and human Trials take however long they take and that's so I think an interesting cut of this is<br>
(19:13) like where can you avoid that like where are the the synthetic bio companies that I've seen that have been most interesting are the ones that find a way to like make the cycle time super fast um and that that benefits like an AI That's giving you a lot of good ideas but you've still got to test them which is where things are right now um I'm a huge believer for startups that like the thing you want is low costs and fast cycle times and if you have those you can then compete as a startup against the big incumbents uh and so like I wouldn't go pick like cardiac disease is my first thing to go after<br>
(19:43) right now with like this kind of new kind of company um but you know using bio to manufacture something that sounds great uh I think the other thing is the simulators are still so bad and if I were an a if I were a bio means AI startup I would certainly try to work on that somehow when do you think the AI Tech will help create itself oh it's almost like a self-improvement will help make the simulators significantly better um people are working on that now uh I I don't know quite how it's going but you know there's very smart people are very optimistic about that yeah other questions and I can keep going on questions I just<br>
(20:25) want to make sure you guys had a chance this uh here yes great Mike is coming awesome thank you um I was curious what what aspects of Life do you think won't be changed by AI um sort of did all of the deep biological things like I think we will still really care about interaction with other people like we'll still have fun and like the reward you know systems of our brain are still going to work the same way like we're still going to have the same like drives to kind of create new things and you know compete for silly status and like you know form families and whatever um so I think the the stuff that people cared about<br>
(21:13) 50 000 years ago is more likely to be the stuff that people care about you know 100 years from now than 100 years ago as an amplifier on that before we get to the next whatever the next question is what do you think are the best utopian science fiction universes so far good question um Star Trek is pretty good honestly uh like I do like all of the ones that are sort of like you know we turn our Focus to like exploring and understanding the universe as much as we can um it's not this is not a utopian one well maybe I think the last question is like an incredible short story uh-huh yeah that was what that came to mind yep uh I<br>
(22:02) was expecting you to say Ian Banks on the culture those are great uh I think science fiction is like there's not like one there's not like one sci-fi universe that I could point to and say I think all of this is great but like the collective optimistic corner of sci-fi which is like a smallish Corner um I'm excited about actually uh I took a few days off to write a Sci-Fi story and I had so much fun doing it just about sort of like the optimistic case of AGI um that it made me want to go like read a bunch more so I'm looking for recommendations of more to read now um like the sort of less known stuff if<br>
(22:43) you have anything I will I will get you some great some recommendations so in a similar vein one of my favorite sci-fi books is called childhood's End by Arthur Clark from like the 60s I think and the I guess the one sentence summary is aliens come to the Earth try to save us and they just take our kids and leave everything else so you know there's a slightly more optimistic than that but yes I mean there's Ascension into the over mind is is is meant to be more utopian but yes okay uh you may not read it that way but yes well also in our current Universe yes our current situation um you know a lot of people think about<br>
(23:28) family building and fertility and like some of us have different people have different ways of approaching this but from where you stand what do you see as like the most promising Solutions it might not be a technological solution but I'm curious what you think other than everyone having 10 kids you know like how do we of everyone having 10 kids yeah how do you populate how do you like how do you see family building coexisting with you know AGI high tech it's this is like a question that comes up at open AI a lot like how do I think about you know how should one think about having kids there's I think<br>
(24:06) no consensus answer to this um there are people who say yeah I'm not I was gonna I thought I always thought I was gonna have kids and now I'm not going to because of AGI like there's just for all the obvious reasons and I think some less obvious ones there's people who say like well it's going to be the only thing for me to do in you know 15 20 years so of course I'm going to have a big family like that's what I'm going to spend my time doing you know I'll just like raise great kids and then I think that's what'll bring me fulfillment I think like as always it is a a personal decision I get very<br>
(24:34) depressed when people are like I'm not having kids because of AGI uh the EA Community is like I'm not doing that because they're all going to die they're kind of like a techno optimists are like well it's just like you know I want to like merge into the AGI and go off exploring the universe and it's going to be so wonderful and you know just I want total freedom but I think like all of those I find quite depressing um I think having a lot of kids is great I you know want to do that now more than I did even more than I did when I was younger and I I'm excited for it what do you think will be the way that<br>
(25:09) most users interact with Foundation models in five years do you think there'll be a number of verticalized AI startups that essentially have adapted and fine-tuned Foundation models to an industry or do you think prompt engineering will be something many organizations have as an in-house function I don't think we'll still be doing prompt Engineering in five years I think it'll just be like you and this will be integrated everywhere but you will just like you know either with text or voice depending on the context you you will just like interface in language and get the computer to do whatever you<br>
(25:39) want and uh that will you know apply to like generate an image where maybe we still do a little bit of prompt engineering but you know it's kind of just going to get it to like go off and do this research for me and do this complicated thing or just like you know be my therapist and help me figure out how to make my life better or like you know go use my computer for me and do this thing or or any number of other things but I think the fundamental interface will be natural language let me actually push on that a little bit before we get to the next question which is I mean to some degree just like we have<br>
(26:11) a wide range of human talents right now uh and taking a look for example a dolly when you have like a a great visual thinker they can get a lot more out of Dolly because they know how to think more they know how to iterate the loop through the the test don't you think that will be a general truth about most of these things so it isn't that why would be natural language is the way you're doing it it will be there will be like almost an evolving set of human talents about about going that extra mile 100 I just hope it's not like figuring out to like hack the prompt by adding one magic word to the end that<br>
(26:45) like changes everything else I I like what will matter is like the quality of ideas and the understanding of what you want so the artist will still do the best with image generation but not because they figured out to like add this one magic word at the end of it because they were just able to like articulate it with a creative eye that you know I don't have certainly what they have is a vision and kind of how their visual thinking and iterating through it yeah yeah well obviously it'll be that word or prompt now but it'll iterate to to better all right uh at least we have a question here hey thanks so much um<br>
(27:22) uh I think the term AGI is used uh thrown around a lot and um sometimes I've noticed my own discussions like the sources of confusion has just come from people having different definitions of AGI and so it can kind of be the magic box where everyone just kind of projects their their ideas onto it and I just want to get a sense from you what like how do you think you know how would you define AGI and how do you think you'll know yeah it's a great point I think there's like a lot of valid definitions to this but uh for me um AGI is basically the equivalent of a median human that you could like you<br>
(27:59) know hire as a co-worker um so and then they could like say do anything that you'd be happy with a remote co-worker doing like just behind a computer which includes like you know learning how to go be a doctor learn how to go be a very competent coder like there's a lot of stuff that a media human is capable of getting good at and I think one of the skills of an AGI is not any particular Milestone but the The Meta skill of learning to figure things out and that it can go decide to get good at whatever you need um so for me like that's that's kind of like AGI and then Super intelligence is when it's like smarter than all of<br>
(28:35) humanity put together thanks um just uh what would you say or in the next 20 30 years are some of the main societal issues that will arise as AI continues to grow and what can we do today to mitigate those issues obviously the economic impacts are huge and I think it's just like if it if it is as Divergent as I think it could be for like some people doing incredibly well and others not I think Society just won't tolerate at this time and so figuring out when we're gonna like disrupt so much of economic activity and even if it's not all disrupted by 20 or 30 years from now I think it'll be clear<br>
(29:17) that it's all going to be um what like what is the new social contract like how do my guess is that the things that we'll have to figure out are how we think about fairly Distributing wealth um access to AGI systems which will be like kind of the commodity of the realm and governance like how we collectively decide what they can do what they don't do things like that um and I think figuring out the answer to those questions is is gonna just be huge I I'm optimistic that people will figure out how to spend their time and be very fulfilled I think people worry about that in a little bit of a silly way I'm<br>
(29:56) sure what people do will be very different but we always solve this problem um but I do think like the concept of wealth and access and governance those are all going to change and how how we address those will will be huge actually one thing I don't know what level of devs you can share that but one of the things I love about what openai and you guys are doing is when you they think about these questions a lot themselves and they initiate some research so you've initiated some research on this stuff yeah so we run the largest uh Ubi experiment in the world I don't think that is uh we have a year and a half a<br>
(30:36) year and a quarter left in a five-year project I don't think that's like the only solution but I think it's a great thing to to be doing um and you know I think like we should have like 10 more things like that that we try um we also try with different ways to get sort of input from a lot of the groups that we think will be most affected and see how we can do that early in the cycle um we've explored more recently like how this technology can be used used for reskilling people that are going to be impacted early um we'll try to do a lot more stuff like that too yeah so they are the the organization is actually in fact<br>
(31:11) uh these are great questions addressing them and actually doing a bunch of interesting research on it so next question hi so um creativity came up today in several of the panels you know and um it seems to me that the way it's being used like you you have tools for human creators to go and expand human creativity so where do you think the line is between these tools to to allow a Creator to be more productive in artificial creativity itself so um I I think and I think we're seeing this now that tools for creatives that that is going to be like the great application of AI in the short term um people love it it's really helpful uh<br>
(31:51) and I think it is at least in what we're seeing so far um not replacing it is mostly enhancing it's replacing in some cases uh but for the majority of like the kind of work that people in these fields want to be doing it's enhancing and I think we'll see that Trend continue for a long time um eventually yeah it probably is just like you know we look at 100 years okay it can do the whole creative job um I think it's interesting that if you asked people 10 years ago uh about Holly I was going to have an impact with a lot of confidence from almost most people you would have heard you know first it's<br>
(32:26) going to come for the blue collar jobs working in the factories truck drivers whatever then it will come for the kind of like the low skill White Collar jobs then the very high skill like really high IQ uh white-collar jobs like a programmer or whatever and then very last of all and maybe never it's gonna take the creative jobs and it's really gone exactly and it's going exactly the other direction and I think this like isn't there's an interesting reminder in here generally about how hard predictions are but more specifically about you know we're not always very aware maybe even ourselves of like what skills<br>
(33:00) are hard and easy like what uses most of our brain and what doesn't or how like difficult bodies are to control or make or whatever we have one more question over here hey thanks for being here so you mentioned that um you will be skeptical of any startup trying to train their own language model and it would love to understand more so what I have heard and which might be wrong is that large language models depend on data and compute and any startup can access to the same amount of data because it's just like internet data and compute like different companies might have different compute but I guess I see a big players<br>
(33:33) can sell more compute so how good a large language model startup differentiate from another how would the startup differentiate from another how would one large language model startup differentiate I think it'll be this middle layer um I think in some sense the startups will train their own models just not from the beginning uh they will take like you know base models that are are like hugely trained with a gigantic amount of compute and data and then they will train on top of those to create you know the model for each vertical and and that those startups so in some sense they are training their own models<br>
(34:10) just not not from scratch but they're doing the one percent of training that really matters for for whatever this use case is going to be those startups I think they will be hugely successful and very differentiated startups there but that'll be about the kind of like data flywheel that the startup is able to do the kind of like all of the pieces on top of and Below uh like this could include prompt engineering for a while or whatever the sort of the kind of like core base model I think that's just going to get too too complex and too expensive and the world also just doesn't make enough chips<br>
(34:44) so Sam has a work thing he needs to get to so and as you probably can tell with a very far far ranging thing Sam always expands my uh boundaries and a little bit unlike the that when you're feeling depressed whether it's kids in a house you're the person I always turn to probably I appreciate that yes so anyway I think I think like no one knows like we're sitting on this like precipice of AI and like people like it's either gonna be like really great or really terrible um you may as well like you gotta you gotta like plan for the worst you certainly like it's not a strategy to say it's all<br>
(35:21) going to be okay but you may as well like emotionally feel like we're going to get to the Great future and we'll play as hard as you can to get there and play for it yes rather than like act from this place of like fear and despair all the time because if we acted from a place of fear and paranoia we would not be where we are today so let's thank Sam for spending dinner with us thank you</p>
<p>Generate with Glarity.</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ANTINET 书籍总结（GPT3.5 中英对照）]]></title>
        <id>https://temberature.github.io/post/piENcmSEc/</id>
        <link href="https://temberature.github.io/post/piENcmSEc/">
        </link>
        <updated>2023-11-20T03:02:23.000Z</updated>
        <content type="html"><![CDATA[<p>以下是文档关键点的高级摘要：</p>
<p>这本书是关于一个名为“Antinet”的模拟笔记系统，灵感来自尼克拉斯·卢曼的Zettelkasten。</p>
<p>Antinet有4个关键原则：</p>
<ul>
<li>
<p>模拟（纸上手写笔记，非数字）</p>
</li>
<li>
<p>数字-字母地址（每个注释的唯一ID）</p>
</li>
<li>
<p>树形结构（注释形成一个不断发展、有机的思想树）</p>
</li>
<li>
<p>索引（关键词提供进入注释的入口点）</p>
</li>
</ul>
<p>这些原则共同促进了深度思考、概念链接、创造力和知识在几十年中的演变。 Antinet成为你可以与之交流的&quot;第二大脑&quot;。</p>
<p>该书涵盖了尼克拉斯·卢曼及其观点背景。它旨在澄清网上对Zettelkasten 的误解，并提供从零开始建立Antinet 的实用指南。</p>
<p>知识发展主要分为四个阶段：</p>
<ul>
<li>
<p>选择 (选择来源和想法)</p>
</li>
<li>
<p>提取 (阅读时抽出想法)</p>
</li>
<li>
<p>创作 (制作不同类型的笔记)</p>
</li>
<li>
<p>安装 (将笔记归档到系统中)</p>
</li>
</ul>
<p>突出显示包括以下几项重要好处：</p>
<ul>
<li>
<p>发展天才级别工作</p>
</li>
<li>
<p>实现跨越数十年的长期项目</p>
</li>
<li>
<p>通过链接想法创造出惊喜和洞察力</p>
</li>
<li>
<p>加强记忆并减轻认知偏差</p>
</li>
</ul>
<p>该书主张，对于深度思考和创新性，模拟Antinet远胜于数字笔记。但是，要实现这些好处需要长期努力和一致性。</p>
<p>Here is a high-level summary of the key points from the document:</p>
<p>The book is about an analog note-taking system called the &quot;Antinet&quot; which is inspired by Niklas Luhmann's Zettelkasten.</p>
<p>The Antinet has 4 key principles:</p>
<ul>
<li>Analog (handwritten notes on paper, not digital)</li>
<li>Numeric-Alpha addresses (unique IDs for each note)</li>
<li>Tree structure (notes form an evolving, organic tree of ideas)</li>
<li>Index (keyterms provide entry points into the notes)</li>
</ul>
<p>Together these principles enable deep thinking, linking of concepts, creativity, and evolution of knowledge over decades. The Antinet becomes a &quot;second mind&quot; that you communicate with.</p>
<p>The book covers the background of Niklas Luhmann and his views. It aims to clear up misconceptions about the Zettelkasten online. It provides practical guidance on building an Antinet from scratch.</p>
<p>There are 4 main phases of knowledge development:</p>
<ul>
<li>Selection (choosing sources and ideas)</li>
<li>Extraction (pulling out ideas while reading)</li>
<li>Creation (making different types of notes)</li>
<li>Installation (filing notes in the system)</li>
</ul>
<p>Key benefits highlighted include:</p>
<ul>
<li>Developing genius-level work</li>
<li>Enabling long-term projects spanning decades</li>
<li>Creating surprises and insights from linking ideas</li>
<li>Strengthening memory and mitigating cognitive biases</li>
</ul>
<p>The book argues the analog Antinet is far superior to digital notes for deep thinking and creativity. But it requires long-term effort and consistency to realize the benefits.</p>
<h1 id="authors-note-作者注">AUTHOR’S NOTE 作者注</h1>
<h1 id="preface-do-not-skip">PREFACE (DO NOT SKIP)</h1>
<p>前言（请勿跳过）</p>
<p>Here is a summary of the key points from the document:<br>
这是文件中的关键要点摘要</p>
<p>The Antinet is a knowledge development system created using notecards. It was evolved over time by many great thinkers, but is often attributed to Niklas Luhmann.<br>
Antinet是一个使用记事卡创建的知识发展系统。它经过许多伟大思想家的演化，但通常归功于尼克拉斯·卢曼。</p>
<p>The Antinet has several meanings:<br>
Antinet有几个意思：</p>
<ul>
<li>
<p>It's a tongue-in-cheek reference to the over-reliance on digital tools for thinking and knowledge development. The author believes analog tools are better for deep, deliberate thinking.<br>
这是对过度依赖数字工具进行思考和知识发展的一种戏谑引用。作者认为模拟工具更适合深入、有意识的思考。</p>
</li>
<li>
<p>It's an acronym that refers to the 4 principles of the system, which were used by Luhmann.<br>
这是一个缩写词，指的是系统的四个原则，这些原则是由卢曼使用的。</p>
</li>
<li>
<p>It's a reference to Antonin Sertillanges, a Catholic intellectual who used a similar system.<br>
这是对安东尼·塞蒂朗日的参考，他是一位天主教知识分子，使用了类似的系统。</p>
</li>
</ul>
<p>The book aims to uncover the &quot;true magic&quot; of the analog Antinet/Zettelkasten system. It focuses on how it can turn you into a prolific researcher, reader and writer.<br>
这本书旨在揭示模拟Antinet/Zettelkasten系统的“真正魔力”。它专注于如何使您成为一个多产的研究者、读者和作家。</p>
<p>The book touches on the theoretical and practical aspects of the system, its history, and provides actionable techniques. It may need to be re-read at different stages as you build your own Antinet.<br>
这本书涉及到系统的理论和实践方面，它的历史，并提供可行的技术。在构建自己的Antinet过程中，可能需要在不同阶段重新阅读。</p>
<p>Key advice includes: 关键建议包括：</p>
<ul>
<li>Read Ch. 11 first to build a starter Antinet<br>
先阅读第11章以建立一个起始的Antinet。</li>
<li>Use the 2-step Luhmannian bibcard method to take notes while reading<br>
使用2步鲁曼式的参考卡方法在阅读时做笔记</li>
<li>Don't get bogged down by footnotes on a first read<br>
第一次阅读时不要被脚注所困扰</li>
<li>Be prepared to actively apply the techniques<br>
做好准备积极运用技巧</li>
</ul>
<p>The book aims to help committed learners create genius-level work using an analog system of pen, paper and notecards.<br>
这本书旨在帮助有决心的学习者使用笔、纸和卡片的模拟系统创造出天才级的作品。</p>
<h1 id="part-i-the-story-behind-the-story">PART I: THE STORY BEHIND THE STORY</h1>
<p>第一部分：故事背后的故事</p>
<h2 id="chapter-one-第一章">CHAPTER ONE 第一章</h2>
<h2 id="the-journey-that-led-me-to-publish-a-book-on-the-antinet">THE JOURNEY THAT LED ME TO PUBLISH A BOOK ON THE ANTINET</h2>
<p>带领我出版一本关于Antinet的书的旅程</p>
<p>Here is a summary of the key points from Chapter 1:<br>
以下是第一章的要点摘要：</p>
<ul>
<li>
<p>The author had previously co-founded a successful cryptocurrency company but left due to disillusionment and burnout.<br>
作者曾经共同创办了一家成功的加密货币公司，但因为幻灭和精疲力尽而离开。</p>
</li>
<li>
<p>He spent time trying to figure out his next steps, reading books on his patio and taking notes ineffectively with a commonplace book.<br>
他花时间努力思考接下来的步骤，在阳台上阅读书籍，并用一本普通的笔记本无效地做笔记。</p>
</li>
<li>
<p>He discovered the digital note-taking apps Foam and Obsidian and became enthused by their note-linking capabilities. However, this resulted in a messy over-linked network of digital notes.<br>
他发现了数字笔记应用Foam和Obsidian，并对它们的笔记链接功能感到兴奋。然而，这导致了一个混乱的过度链接的数字笔记网络。</p>
</li>
<li>
<p>He learned about the Zettelkasten system in the book &quot;How to Take Smart Notes&quot; by Sönke Ahrens. This described an analog paper-based note system used by Niklas Luhmann.<br>
他在Sönke Ahrens的书《如何做智能笔记》中了解到了Zettelkasten系统。这本书描述了尼克拉斯·卢曼使用的一种模拟纸质笔记系统。</p>
</li>
<li>
<p>Intrigued, the author tried using a real analog Zettelkasten and found it transformed his note-taking and writing. His thoughts flowed much better compared to digital apps.<br>
作者感到好奇，尝试使用真正的模拟式Zettelkasten，发现它改变了他的笔记和写作方式。与数字应用相比，他的思绪更加流畅。</p>
</li>
<li>
<p>By studying Luhmann's archived Zettelkasten online, the author pieced together how the analog system worked in practice. He coined his version the &quot;Antinet&quot;.<br>
通过在线研究卢曼的存档Zettelkasten，作者拼凑出了这个模拟系统在实践中的运作方式。他将自己的版本称为&quot;Antinet&quot;。</p>
</li>
<li>
<p>The Antinet helped the author make progress on a project about marketing and cryptocurrency. However, he felt compelled to write this book to share the power of the analog system with others.<br>
Antinet帮助作者在关于市场营销和加密货币的项目上取得了进展。然而，他觉得有必要写这本书与他人分享模拟系统的力量。</p>
</li>
<li>
<p>The author wants to help committed people create long-lasting work, even though focusing on the antiquated analog Zettelkasten seems absurd. He chose this path to genuinely help people rather than chase money.<br>
作者希望帮助有决心的人创造持久的工作，尽管专注于过时的模拟式Zettelkasten似乎荒谬。他选择这条道路是为了真正帮助人们，而不是追逐金钱。</p>
</li>
</ul>
<h2 id="chapter-two-第二章">CHAPTER TWO 第二章</h2>
<h2 id="the-who-and-why-of-the-antinet">THE WHO AND WHY OF THE ANTINET</h2>
<p>反对网的是谁和为什么</p>
<p>Here is a summary of the key points from Chapter 2:<br>
以下是第二章的要点摘要</p>
<ul>
<li>
<p>The author clarifies who should and should not bother reading this book about the Antinet system.<br>
作者明确指出谁应该和谁不应该读这本关于Antinet系统的书。</p>
</li>
<li>
<p>It is best suited for serious writers, researchers, academics, and lifelong learners who wish to develop deep knowledge and creative insights.<br>
它最适合于认真的作家、研究人员、学者和终身学习者，他们希望发展深入的知识和创造性的洞察力。</p>
</li>
<li>
<p>However, it requires a long-term time commitment of decades to fully realize the benefits. It is not for those with tight deadlines or limited time.<br>
然而，要充分实现其好处需要数十年的长期时间承诺。这并不适合那些时间紧迫或时间有限的人。</p>
</li>
<li>
<p>The Antinet excels at developing unconventional interactions between ideas that lead to creative insights and genius-level work. This emerges from its analog tree structure.<br>
Antinet在发展非传统的思想交互方面表现出色，这导致了创造性的洞察和天才级的工作。这源于它的模拟树结构。</p>
</li>
<li>
<p>It shines for long-term multi-year projects and enabling knowledge to compound over decades. This cannot occur in siloed, categorized systems.<br>
它适用于长期多年的项目，并使知识在几十年间得以累积。这在孤立、分类的系统中是不可能发生的。</p>
</li>
<li>
<p>The Antinet reveals structured accidents - surprising connections that emerge through browsing nearby tree branches. This cannot be replicated digitally.<br>
Antinet揭示了结构化的意外 - 通过浏览附近的树枝而出现的令人惊讶的联系。这无法在数字化中复制。</p>
</li>
<li>
<p>Niklas Luhmann created the Zettelkasten for a 30-year theory of everything project. However, his books were often poorly written and impenetrable due to his trollish nature.<br>
尼克拉斯·卢曼为一个持续30年的万物理论项目创建了Zettelkasten。然而，由于他的恶作剧性格，他的书籍常常写得很糟糕且难以理解。</p>
</li>
<li>
<p>The Antinet should not be expected to magically produce perfect writings without hard work. But it develops deeper ideas than other systems.<br>
Antinet不应该期望能够在没有努力的情况下神奇地产生完美的作品。但它能够发展出比其他系统更深入的思想。</p>
</li>
<li>
<p>In summary, the Antinet is best for serious thinkers aiming to produce unconventional, creative and long-lasting work over decades, not those seeking easy solutions.<br>
总之，Antinet最适合那些志在创造非传统、富有创意且持久的作品的认真思考者，而不是那些寻求简单解决方案的人。</p>
</li>
</ul>
<h2 id="chapter-three-第三章">CHAPTER THREE 第三章</h2>
<h2 id="the-current-zettelkasten-landscape">THE CURRENT ZETTELKASTEN LANDSCAPE</h2>
<p>当前的Zettelkasten景观</p>
<p>Here is a summary of the key points from Chapter 3:<br>
以下是第三章的要点摘要</p>
<ul>
<li>
<p>The current landscape of information on Zettelkasten online and in books is riddled with inaccuracies.<br>
关于Zettelkasten的在线和书籍信息目前充斥着不准确之处。</p>
</li>
<li>
<p>Popular sources like Wikipedia and zettelkasten.de get important aspects wrong, like describing it as hierarchical or advocating for digital notes.<br>
流行的来源，如维基百科和zettelkasten.de，对重要方面的描述存在错误，比如将其描述为分层或主张数字笔记。</p>
</li>
<li>
<p>Sönke Ahrens' book introduced concepts like fleeting notes and literature notes that are not part of Luhmann's original Zettelkasten.<br>
Sönke Ahrens的书介绍了像瞬时笔记和文献笔记这样的概念，它们并不是Luhmann原始的Zettelkasten的一部分。</p>
</li>
<li>
<p>A new wave of &quot;Ahrensians&quot; have created more layers of complexity and contradictions trying to adapt the system to digital tools.<br>
一股新的“阿伦斯派”浪潮正在尝试将系统适应数字工具，创造出更多的复杂性和矛盾。</p>
</li>
<li>
<p>For example, some advocates undermine Luhmann's numeric-alpha note IDs or promote digital search over analog serendipity.<br>
例如，一些倡导者质疑卢曼的数字-字母笔记ID，或者提倡数字搜索而非模糊的偶然发现。</p>
</li>
<li>
<p>The analog system's essence is lost in digital knockoffs. Luhmann saw it as a thinking tool and communication partner.<br>
模拟系统的本质在数字仿制品中丧失了。卢曼将其视为一种思维工具和沟通伙伴。</p>
</li>
<li>
<p>The author wants to share insights from studying Luhmann's archive to help committed learners avoid wasting time on inaccurate methods.<br>
作者希望通过研究卢曼的档案，分享一些见解，帮助有心学习者避免浪费时间在不准确的方法上。</p>
</li>
<li>
<p>He cares about this niche group and wants to serve them, unlike his past work in cryptocurrency catering to speculators.<br>
他关心这个利基群体，并希望为他们服务，不同于他过去在加密货币领域为投机者服务的工作。</p>
</li>
<li>
<p>In summary, the current landscape spreads misconceptions about Zettelkasten, but the author aims to uncover its true analog nature.<br>
总之，当前的情况对于Zettelkasten存在误解，但作者的目标是揭示它真正的模拟本质。</p>
</li>
</ul>
<h2 id="chapter-four-第四章">CHAPTER FOUR 第四章</h2>
<h2 id="niklas-luhmann-the-man">NIKLAS LUHMANN, THE MAN</h2>
<p>尼克拉斯·卢曼，这个人</p>
<p>Here is a summary of the key points about Niklas Luhmann from Chapter 4:<br>
以下是关于尼克拉斯·卢曼的关键要点的摘要，来自第四章：</p>
<ul>
<li>
<p>Understanding Luhmann's background, theories, views, and personality provides context for the nature of the Antinet system he created.<br>
了解卢曼的背景、理论、观点和个性，可以为他所创造的Antinet系统的性质提供背景。</p>
</li>
<li>
<p>Luhmann was born in 1927 in Germany. His passion was reading, thinking and writing. He created his Zettelkasten system to aid this.<br>
卢曼于1927年出生在德国。他热爱阅读、思考和写作。他创建了自己的Zettelkasten系统来辅助这些活动。</p>
</li>
<li>
<p>He was not interested in drinking or socializing. He prioritized expanding his mind over advancing his early career.<br>
他对喝酒和社交不感兴趣。他把拓宽思维放在比提升早期职业更重要的位置。</p>
</li>
<li>
<p>His political views trended libertarian. He aimed to remain detached and avoid moralizing issues.<br>
他的政治观点倾向自由主义。他的目标是保持超然和避免道德化问题。</p>
</li>
<li>
<p>Core concepts in Luhmann's work were communication, systems theory, complexity, and autopoiesis.<br>
卢曼的作品中的核心概念是沟通、系统理论、复杂性和自我生成。</p>
</li>
<li>
<p>He took an anti-humanist, anti-regionalist approach to sociology, applying biological concepts to social systems.<br>
他采取了一种反人道主义、反地域主义的社会学方法，将生物学概念应用于社会系统。</p>
</li>
<li>
<p>Luhmann had an ironic, absurdist, and carnivalesque attitude. He was a polite troll who provoked with his theories.<br>
卢曼具有讽刺、荒诞和狂欢的态度。他是一个有礼貌的喷子，通过他的理论引发争议。</p>
</li>
<li>
<p>He was dedicated to his intellectual pursuits, desiring more time for reading, writing and thinking.<br>
他专注于他的知识追求，渴望有更多的时间来阅读、写作和思考。</p>
</li>
<li>
<p>Luhmann produced an enormous volume of writing and books with the aid of his Zettelkasten system.<br>
卢曼利用他的Zettelkasten系统创作了大量的文字和书籍。</p>
</li>
<li>
<p>In summary, understanding Luhmann's unconventional mindset helps appreciate the nature of the Antinet system he devised.<br>
总之，理解卢曼的非传统思维方式有助于欣赏他设计的Antinet系统的本质。</p>
</li>
</ul>
<h1 id="part-2-the-antinet">PART 2: THE ANTINET</h1>
<p>第二部分：反网络</p>
<h2 id="chapter-five-第五章">CHAPTER FIVE 第五章</h2>
<h2 id="what-is-an-antinet">WHAT IS AN ANTINET?</h2>
<p>什么是Antinet？</p>
<p>Here is a summary of the key points from Chapter 5:<br>
以下是第五章的要点摘要：</p>
<ul>
<li>
<p>The term &quot;Antinet&quot; refers to the four principles of Niklas Luhmann's Zettelkasten system: Analog, Numeric-alpha addresses, Tree structure, and Index.<br>
“Antinet”一词指的是尼克拉斯·卢曼的Zettelkasten系统的四个原则：模拟、数字-字母地址、树状结构和索引。</p>
</li>
<li>
<p>Luhmann created his system to challenge simplistic views of good vs evil. A childhood experience of being abused by American soldiers showed him the world's complexity.<br>
卢曼创立了他的体系，挑战了对善恶的简单看法。一次童年时被美国士兵虐待的经历让他看到了世界的复杂性。</p>
</li>
<li>
<p>The Antinet functions like an adaptive optics system, transforming distorted thoughts into clear ideas. It exercises your neuro-associative recall ability.<br>
Antinet的功能类似于自适应光学系统，将扭曲的思维转化为清晰的观念。它锻炼你的神经联想记忆能力。</p>
</li>
<li>
<p>An Antinet is not just analog storage. It's a thinking and thought development system that becomes a second mind over time.<br>
一个Antinet不仅仅是模拟存储。它是一个思考和思维发展系统，随着时间的推移成为第二个思维。</p>
</li>
<li>
<p>The second mind emerges through neuroimprinting, internal dialogue, and communicating with your past self's handwriting. It has its own personality.<br>
第二个意识通过神经印记、内部对话和与过去自己的书写交流而出现。它有自己的个性。</p>
</li>
<li>
<p>The four principles transform the raw notecards into a whole greater than the parts. This cannot be replicated digitally.<br>
四个原则将原始的便签卡片转化为一个整体，超越了各个部分的价值。这是无法在数字化中复制的。</p>
</li>
<li>
<p>Antinets excel at developing unconventional insights, evolving ideas over decades, and revealing &quot;structured accidents.&quot;<br>
Antinets在开发非传统的洞察力、演化数十年的思想以及揭示“结构性事故”方面表现出色。</p>
</li>
<li>
<p>An Antinet is not a memory aid, but a thinking system. It strengthens memory faculties and mitigates cognitive biases.<br>
Antinet不是记忆辅助工具，而是一种思维系统。它增强记忆能力并减轻认知偏差。</p>
</li>
<li>
<p>Simply linking digital notes misses the essence of Luhmann's system. His analog principles imprint thoughts and create dialogue.<br>
简单地链接数字笔记会忽略卢曼系统的本质。他的模拟原则铭刻思想并创造对话。</p>
</li>
<li>
<p>In summary, &quot;Antinet&quot; refers to the unique analog system Luhmann devised to develop complex, deep knowledge over time.<br>
总之，“Antinet”是指卢曼设计的独特的模拟系统，用于随着时间的推移发展复杂而深入的知识。</p>
</li>
</ul>
<h2 id="chapter-six-第六章">CHAPTER SIX 第六章</h2>
<h2 id="analog-模拟">ANALOG 模拟</h2>
<p>Here is a summary of the key points from the chapter:<br>
这是本章的要点摘要</p>
<p>The Analog Pros and Cons<br>
模拟技术的优缺点</p>
<ul>
<li>Analog Pros: 模拟优势</li>
</ul>
<ol>
<li>Creates a better communication partner than digital<br>
比数字化更好的沟通伙伴</li>
<li>Captures one's consciousness and past self better<br>
更好地捕捉一个人的意识和过去的自我</li>
<li>Transforms the Zettelkasten into a thinking tool for short and long-term development<br>
将Zettelkasten转化为短期和长期发展的思维工具</li>
<li>Forces unlimited combinations of thought due to notecards' limited space<br>
由于便签的有限空间，强制进行无限的思维组合</li>
<li>Prevents hyper-selection of irrelevant material while reading<br>
阅读时防止过度选择无关材料</li>
<li>Enables better familiarity with knowledge through constant review<br>
通过不断的复习，使对知识更加熟悉</li>
<li>Exposes mistakes and self-deceptions effectively<br>
有效地揭示错误和自欺欺人</li>
</ol>
<ul>
<li>Analog Cons: 模拟缺点</li>
</ul>
<ol>
<li>Risk of destruction from fire, flood, etc.<br>
火灾、洪水等破坏的风险</li>
<li>Harder than digital in terms of effort required<br>
在所需的努力方面比数字更困难</li>
<li>Less mobile than digital<br>
比数字化更不灵活</li>
</ol>
<p>Comparison to Digital 与数字化的比较</p>
<ul>
<li>Digital can aid in productivity but lacks the communication component of analog<br>
数字技术可以提高生产力，但缺乏模拟技术的沟通组成部分</li>
<li>Digital is more distracting and leads to less happiness and poorer health outcomes<br>
数字化更容易分散注意力，导致更少的幸福感和较差的健康状况</li>
<li>Luhmann likely would have stuck with analog even if he had access to digital tools<br>
卢曼即使有数字工具的使用权限，也可能仍然坚持使用模拟工具</li>
</ul>
<p>The Power of Writing by Hand<br>
手写的力量</p>
<ul>
<li>Writing by hand disentangles thoughts, enhances memory and neuro-associative recall, improves learning, and leads to better mood<br>
手写能够解开思绪，增强记忆和神经联想回忆，提高学习能力，并带来更好的心情</li>
<li>Both scientific research and biblical verses support the power of writing by hand over typing<br>
科学研究和圣经经文都支持手写的力量胜过打字</li>
<li>Many great thinkers and writers use analog tools and write by hand<br>
许多伟大的思想家和作家使用模拟工具并手写</li>
</ul>
<p>Overall, the chapter covers the benefits and drawbacks of analog Zettelkasten systems compared to digital. It makes a strong case for the power of writing by hand and using physical note cards to develop deep thinking and creativity.<br>
总的来说，这一章节涵盖了与数字化相比，模拟式Zettelkasten系统的优点和缺点。它强调了手写和使用实体卡片进行深思熟虑和创造力发展的重要性。</p>
<h2 id="chapter-seven-第七章">CHAPTER SEVEN 第七章</h2>
<h2 id="numeric-alpha-数字-字母">NUMERIC-ALPHA 数字-字母</h2>
<p>Here is a summary of the key points from the chapter:<br>
这是本章的要点摘要</p>
<p>Numeric-Alpha Addresses 数字-字母地址</p>
<ul>
<li>
<p>Numeric-alpha addresses are a critical component of the Antinet system. They give each note a unique identifier and location.<br>
数字-字母地址是Antinet系统的关键组成部分。它们为每个笔记提供了独特的标识符和位置。</p>
</li>
<li>
<p>The addresses provide structure and order, allowing notes to be easily linked and retrieved.<br>
地址提供了结构和秩序，使得笔记可以轻松地进行链接和检索。</p>
</li>
<li>
<p>Numeric-alpha addresses have a long history, used in systems dating back to the 1700s. Luhmann likely adapted them from his work in the legal system.<br>
数字字母地址有着悠久的历史，可以追溯到18世纪的系统中使用。卢曼很可能是从他在法律系统中的工作中对其进行了改编。</p>
</li>
<li>
<p>The addresses make the Antinet self-referential, allowing it to function as a communication partner.<br>
地址使得Antinet具有自我参照性，使其能够作为通信伙伴发挥作用。</p>
</li>
<li>
<p>In memory science, numeric-alpha addresses resemble auto-associative networks in the brain.<br>
在记忆科学中，数字-字母地址类似于大脑中的自联想网络。</p>
</li>
</ul>
<p>Links 链接</p>
<ul>
<li>
<p>There are two main types of links: internal (within the Antinet) and external (to outside sources).<br>
有两种主要类型的链接：内部链接（在Antinet内部）和外部链接（指向外部来源）。</p>
</li>
<li>
<p>Internal links include stemlinks, branchlinks, remotelinks, and keyterm links. They connect related ideas.<br>
内部链接包括词干链接、分支链接、远程链接和关键词链接。它们连接相关的思想。</p>
</li>
<li>
<p>External links reference outside sources like books, articles, videos, etc.<br>
外部链接引用了外部来源，如书籍、文章、视频等。</p>
</li>
<li>
<p>Links enable associations, which are critical for learning and insight. The Antinet's structure mirrorsassociative networks in memory.<br>
链接使得关联成为可能，而关联对于学习和洞察力至关重要。Antinet的结构反映了记忆中的关联网络。</p>
</li>
<li>
<p>Digital tools don't optimize associations like the Antinet does through numeric-alpha addresses.<br>
数字-字母地址的Antinet不像数字工具那样优化关联。</p>
</li>
</ul>
<p>In summary, this chapter covered the importance of the Antinet's numeric-alpha address structure and linking system. Together they enable enhanced learning, creativity, and communication compared to digital notes.<br>
总之，本章介绍了Antinet的数字-字母地址结构和链接系统的重要性。它们共同促进了比数字笔记更强大的学习、创造力和沟通能力。</p>
<h2 id="chapter-eight-第八章">CHAPTER EIGHT 第八章</h2>
<h2 id="tree-树">TREE 树</h2>
<p>Here is a summary of the key points from the chapter:<br>
这是本章的要点摘要</p>
<p>Tree Structure of the Antinet<br>
Antinet的树状结构</p>
<ul>
<li>
<p>The structure of the Antinet is best represented as a tree, with branches, stems, leaves, and vines.<br>
Antinet的结构最好以树的形式来表示，包括树枝、树干、树叶和藤蔓。</p>
</li>
<li>
<p>This tree structure allows for internal branching and evolution of thoughts over time.<br>
这种树形结构允许思想在内部分支和演化。</p>
</li>
<li>
<p>It provides order while still embracing some chaos and roughness.<br>
它在保持一定混乱和粗糙的同时提供秩序。</p>
</li>
<li>
<p>Notes are positioned based on location, not rank. There is no hierarchy.<br>
依据位置而非等级来确定笔记的位置。没有等级制度。</p>
</li>
<li>
<p>The structure mirrors associative networks in human memory.<br>
结构反映了人类记忆中的联想网络。</p>
</li>
<li>
<p>It enables reverberation of linked concepts and surprising discoveries.<br>
它能够使相关概念回响并带来令人惊讶的发现。</p>
</li>
</ul>
<p>Classification Systems 分类系统</p>
<ul>
<li>
<p>Different classification systems can provide starting branches, like Luhmann's or academic disciplines.<br>
不同的分类系统可以提供起始分支，比如卢曼的或学术学科。</p>
</li>
<li>
<p>But fuzzy categories and internal growth are more important than rigid taxonomy.<br>
但是模糊的分类和内部增长比严格的分类更重要。</p>
</li>
<li>
<p>The index supplements classification limitations. The structure evolves based on use.<br>
指数补充分类限制。结构根据使用而演变。</p>
</li>
</ul>
<p>Metaphysics of Trees 树的形而上学</p>
<ul>
<li>
<p>Trees play a central role in myths, stories, and belief systems throughout history.<br>
树木在历史上的神话、故事和信仰体系中起着核心作用。</p>
</li>
<li>
<p>They represent life, knowledge, enlightenment, and the creative force.<br>
它们代表生命、知识、启迪和创造力。</p>
</li>
<li>
<p>Understanding the metaphysics reinforces the power of tree structures for knowledge.<br>
理解形而上学加强了树状结构在知识中的力量。</p>
</li>
</ul>
<p>In summary, this chapter covered the Antinet's rough tree structure, classification systems, and the metaphysical symbolism of trees. Together they provide a framework optimized for evolving thoughts and insights.<br>
总之，本章介绍了Antinet的粗糙树结构、分类系统以及树木的形而上学象征。它们共同构成了一个优化的框架，用于发展思想和洞察力。</p>
<h2 id="chapter-nine-第九章">CHAPTER NINE 第九章</h2>
<h2 id="index-索引">INDEX 索引</h2>
<p>Here is a summary of the key points from the chapter:<br>
这是本章的要点摘要</p>
<p>The Index 指数</p>
<ul>
<li>
<p>The index is a critical component for navigating the Antinet. It serves as a second map.<br>
索引是Antinet导航的关键组成部分，它充当第二张地图。</p>
</li>
<li>
<p>It contains keyterms that act as cues to access areas of knowledge.<br>
它包含作为访问知识领域的线索的关键术语。</p>
</li>
<li>
<p>Keyterms point to locations in the Antinet via numeric-alpha addresses.<br>
关键术语通过数字-字母地址指向Antinet中的位置。</p>
</li>
<li>
<p>There are two types of index cards: list cards and dedicated keyterm cards.<br>
有两种类型的索引卡：列表卡和专用关键词卡。</p>
</li>
<li>
<p>The index provides flexible access without rigid taxonomy limitations.<br>
该指标提供灵活的访问方式，没有严格的分类限制。</p>
</li>
<li>
<p>It enables cued recall and neuro-associative processing.<br>
它能够启用提示回忆和神经联想处理。</p>
</li>
</ul>
<p>Against Digital Search 反对数字搜索</p>
<ul>
<li>
<p>Search is actually a bug, not an inherently desirable feature.<br>
搜索实际上是一个错误，而不是一种本质上可取的功能。</p>
</li>
<li>
<p>Digital search yields too many low relevance results, creating noise.<br>
数字搜索产生了太多低相关性的结果，造成了噪音。</p>
</li>
<li>
<p>It eliminates the structured exploration of associations and serendipity.<br>
它消除了结构化的关联探索和偶然发现。</p>
</li>
<li>
<p>Search prevents maintenance rehearsal learning and evolving unique structures.<br>
搜索阻止了维持排练学习和演化独特结构。</p>
</li>
<li>
<p>It fails to improve mood and cognition like associative processing does.<br>
它无法像联想处理那样改善情绪和认知。</p>
</li>
</ul>
<p>In summary, the index transforms the Antinet into an explorable knowledge network. Avoiding digital search forces more valuable practices for developing insights.<br>
总之，该指数将Antinet转化为一个可探索的知识网络。避免数字搜索可以促进更有价值的洞察力发展实践。</p>
<h2 id="chapter-ten-第十章">CHAPTER TEN 第十章</h2>
<h2 id="network-网络">NETWORK 网络</h2>
<p>Here is a summary of the key points from the chapter:<br>
这是本章的要点摘要</p>
<p>The Antinet as a Cybernetic Network<br>
反网络作为一个控制网络</p>
<ul>
<li>
<p>The Antinet is a cybernetic system, aimed at communication and control through feedback.<br>
Antinet是一个以反馈为目标的网络系统，用于通信和控制。</p>
</li>
<li>
<p>Cybernetics involves achieving a goal by steering in the right direction.<br>
控制论涉及通过朝正确的方向引导来实现目标。</p>
</li>
<li>
<p>The Antinet's network structure resembles associationism and neural networks.<br>
Antinet的网络结构类似于联想主义和神经网络。</p>
</li>
<li>
<p>Associations are built on contiguity (continuous flow of thought) and similarity.<br>
协会建立在接触（思维的连续流）和相似性的基础上。</p>
</li>
<li>
<p>Numeric-alpha addresses create a self-referential, closed loop system.<br>
数字-字母地址创建了一个自我引用的闭环系统。</p>
</li>
<li>
<p>This closure enables feedback signals when searching for ideas.<br>
这种关闭功能在寻找创意时可以提供反馈信号。</p>
</li>
<li>
<p>Feedback prompts course-correction and new insights along the way.<br>
反馈促使调整课程和获得新的见解。</p>
</li>
<li>
<p>Digital notes lack the rich feedback loops of the Antinet's cybernetic network.<br>
数字笔记缺乏反馈回路，这是Antinet的控制网络所不具备的。</p>
</li>
</ul>
<p>In summary, this chapter explains how the Antinet functions as a cybernetic system optimized for communication between past and present thoughts. The network structure reinforced by numeric addresses generates valuable feedback and insights. This cybernetic nature is a key advantage over digital notes.<br>
总之，本章解释了Antinet如何作为一个针对过去和现在思维之间通信进行优化的控制系统。由数字地址加强的网络结构产生了有价值的反馈和洞察力。这种控制系统的特性是与数字笔记相比的一个关键优势。</p>
<h2 id="chapter-eleven-第十一章">CHAPTER ELEVEN 第十一章</h2>
<h2 id="the-hitchhikers-guide-to-the-antinet">THE HITCHHIKER’S GUIDE TO THE ANTINET</h2>
<p>《反互联网搭车者指南》</p>
<p>Here is a summary of the key points from the chapter:<br>
这是本章的要点摘要</p>
<p>Obstacles and Mindset 障碍和心态</p>
<ul>
<li>
<p>Avoid perfectionism - the system evolves over time. Mistakes and imperfections have value.<br>
避免完美主义 - 系统随着时间的推移而发展。错误和不完美具有价值。</p>
</li>
<li>
<p>Have faith in the power of analog tools for thinking. Don't get distracted by digital myths.<br>
相信模拟工具在思考中的力量。不要被数字神话所分散注意力。</p>
</li>
<li>
<p>Adopt a growth vs contribution mindset. Strive to create work to teach others.<br>
采用成长与贡献的心态。努力创造工作来教导他人。</p>
</li>
<li>
<p>Have some goal or focus area in mind before starting.<br>
开始之前，请先确定一些目标或关注领域。</p>
</li>
</ul>
<p>Building the Antinet 构建反网络</p>
<ul>
<li>
<p>The core components are the main box, index box, and bib box.<br>
核心组件是主箱、索引箱和参考文献箱。</p>
</li>
<li>
<p>Main box stores developed thoughts, index provides entry points.<br>
主要的盒子存储了发展的思想，索引提供了入口点。</p>
</li>
<li>
<p>Academic disciplines provide a robust classification system.<br>
学术学科提供了一个强大的分类系统。</p>
</li>
<li>
<p>Numeric-alpha addresses identify note locations.<br>
数字-字母地址用于标识音符位置。</p>
</li>
<li>
<p>Index keyterms serve as cues to find ideas.<br>
索引关键词作为查找思想的提示。</p>
</li>
<li>
<p>Add sources to notes via ExRefs.<br>
通过ExRefs将来源添加到笔记中。</p>
</li>
<li>
<p>It's simple but requires deliberate effort over time.<br>
这很简单，但需要长时间的刻意努力。</p>
</li>
</ul>
<p>In summary, this chapter provided guidance on the mindset and practical steps for building an Antinet from scratch. With the foundation established, one can now begin developing knowledge through reading and note-taking.<br>
简而言之，本章提供了从零开始构建Antinet的心态和实际步骤的指导。有了奠定的基础，现在可以通过阅读和做笔记来开始积累知识。</p>
<h1 id="part-3-knowledge-development">PART 3: KNOWLEDGE DEVELOPMENT</h1>
<p>第三部分：知识发展</p>
<h2 id="chapter-twelve-第十二章">CHAPTER TWELVE 第十二章</h2>
<h2 id="knowledge-development-知识发展">KNOWLEDGE DEVELOPMENT 知识发展</h2>
<p>Here is a summary of the key points from the chapter:<br>
这是本章的要点摘要</p>
<ul>
<li>
<p>Knowledge development involves evolving thoughts and thinking over time.<br>
知识的发展涉及随着时间的推移而不断演变的思想和思维。</p>
</li>
<li>
<p>The DIKW pyramid defines data, information, knowledge, and wisdom.<br>
DIKW金字塔定义了数据、信息、知识和智慧。</p>
</li>
<li>
<p>Knowledge = meaningful, structured information that can be taught.<br>
知识 = 有意义的、有结构的可以被教授的信息。</p>
</li>
<li>
<p>Analog tools develop knowledge better than digital tools.<br>
模拟工具比数字工具更好地发展知识。</p>
</li>
<li>
<p>Knowledge development has 4 main phases:<br>
知识发展有4个主要阶段：</p>
</li>
</ul>
<ol>
<li>
<p>Selection - Choose irresistible information from sources.<br>
选择 - 从来源中选择不可抗拒的信息。</p>
</li>
<li>
<p>Extraction - Write down selections from reading/listening.<br>
提取 - 将阅读/听力中的选择写下来。</p>
</li>
<li>
<p>Creation - Make notes: excerpts, reformulations, reflections.<br>
创作 - 做笔记：摘录，改写，反思。</p>
</li>
<li>
<p>Installation - File notes and index key ideas.<br>
安装-文件注释和索引关键思想。</p>
</li>
</ol>
<ul>
<li>
<p>Knowledge development simplifies complexity (sources), extracts meaning, and builds new complexity (in notes).<br>
知识的发展简化复杂性（来源），提取意义，并构建新的复杂性（在笔记中）。</p>
</li>
<li>
<p>The goal is creating shareable knowledge, not just collecting information.<br>
目标是创造可共享的知识，而不仅仅是收集信息。</p>
</li>
</ul>
<p>In summary, this chapter explains the nature of knowledge and how the Antinet develops it through deliberate reading, note-taking, and evolution of ideas over time. This process transforms information into meaningful, structured knowledge.<br>
总之，本章解释了知识的本质以及Antinet如何通过有意识的阅读、记笔记和思想的演化来发展知识。这个过程将信息转化为有意义、有结构的知识。</p>
<h2 id="chapter-thirteen-第十三章">CHAPTER THIRTEEN 第十三章</h2>
<h2 id="selection-选择">SELECTION 选择</h2>
<p>Here is a summary of the key points from the chapter:<br>
这是本章的要点摘要</p>
<ul>
<li>
<p>Selection is critical when working with an Antinet. It involves selecting what sources to read, what ideas to extract, and where to link ideas in your Antinet.<br>
在与Antinet一起工作时，选择是至关重要的。它涉及选择要阅读的来源，提取哪些想法，以及在你的Antinet中链接想法的位置。</p>
</li>
<li>
<p>Selection underlies communication. Luhmann viewed communication as founded on three selections: selection of information, selection of message, and selective interpretation.<br>
选择是沟通的基础。卢曼将沟通视为基于三个选择：信息选择、信息传递选择和选择性解释。</p>
</li>
<li>
<p>Knowledge selection is like natural selection. You select &quot;mate&quot; sources and extract &quot;genetic&quot; ideas from them to create new knowledge. The knowledge best adapted to your environment (audience) will spread.<br>
知识选择就像自然选择。你选择“配偶”来源，并从中提取“基因”思想来创造新的知识。最适应你的环境（受众）的知识将会传播。</p>
</li>
<li>
<p>There are three levels of selection: source selection, link selection, and material selection. Be selective in what you read, what you link cards to, and what ideas you extract.<br>
有三个层次的选择：源选择、链接选择和材料选择。在阅读、链接卡片和提取思想时要有选择性。</p>
</li>
<li>
<p>Avoid overselection. Digital tools make it too easy to capture too much. Analog forces you to be selective. Hard links are superior to hyperlinks.<br>
避免过度选择。数字工具使得捕捉过多变得太容易。模拟力量迫使你进行选择。硬链接优于超链接。</p>
</li>
<li>
<p>For material selection, focus only on irresistible ideas - the most important and applicable ideas to you. Ignore bad, good, even excellent ideas.<br>
对于材料选择，只关注那些不可抗拒的想法 - 对你来说最重要和适用的想法。忽略不好的、好的，甚至是优秀的想法。</p>
</li>
<li>
<p>Priming before reading involves previewing the source and setting a reading goal. This focuses your selection.<br>
阅读前的预热包括预览来源并设定阅读目标。这样可以集中你的选择。</p>
</li>
<li>
<p>Developing good selection skills requires practice and feedback. Publishing your work provides feedback on your selection abilities.<br>
发展良好的选拔技能需要实践和反馈。发布你的作品可以提供对你的选拔能力的反馈。</p>
</li>
</ul>
<h2 id="chapter-fourteen-第十四章">CHAPTER FOURTEEN 第十四章</h2>
<h2 id="extraction-提取">EXTRACTION 提取</h2>
<p>Here is a summary of the key points about extraction from the chapter:<br>
这是有关提取的章节的关键要点摘要</p>
<ul>
<li>
<p>Extraction involves pulling out and marking material to make into notes. There are intentional vs exploratory strategies.<br>
提取涉及提取和标记材料以制作笔记。有意识的和探索性的策略。</p>
</li>
<li>
<p>Extraction methods include:<br>
提取方法包括：</p>
</li>
</ul>
<ol>
<li>
<p>1-Step Book-to-Maincard: Stop reading to make a note on a card. Good for unfamiliar/complex books.<br>
1步书籍到主卡：停下阅读，在卡片上做笔记。适用于不熟悉/复杂的书籍。</p>
</li>
<li>
<p>2-Step Marginalia: Mark passages in books, then extract later. Risks overselection.<br>
2步骤的旁注：在书中标记段落，然后稍后提取。风险是过度选择。</p>
</li>
<li>
<p>Other Methods: Highlighting, headings, summaries. Help comprehension.<br>
其他方法：突出显示、标题、摘要。帮助理解。</p>
</li>
</ol>
<ul>
<li>
<p>The 2-Step Luhmannian Bibcard Method is best:<br>
2步骤卢曼式Bibcard方法是最好的</p>
</li>
<li>
<p>Front of bibcard has source details, reading goal, overview.<br>
前面的bibcard上有来源细节、阅读目标和概述。</p>
</li>
<li>
<p>Back has bibnotes - brief notes/keyterms from reading.<br>
背面有读书时的简要笔记/关键术语。</p>
</li>
<li>
<p>Later convert bibnotes into maincards or ExRefs.<br>
后来将参考文献转换为主要卡片或外部引用。</p>
</li>
<li>
<p>Bibnotes link ideas to page numbers for selective reading. They prime neuro-associative recall.<br>
Bibnotes将想法与页码链接，以便选择性阅读。它们激活神经联想回忆。</p>
</li>
<li>
<p>Reading differently with an Antinet - faster, more selective. Still read slowly for foundational books.<br>
与反网络不同的阅读方式-更快，更有选择性。对于基础书籍仍然要慢慢阅读。</p>
</li>
<li>
<p>Syntopical reading: Reading multiple books on one topic together.<br>
综合阅读：同时阅读多本关于同一主题的书籍。</p>
</li>
<li>
<p>Good extraction focuses only on irresistible ideas aligned to your goals.<br>
良好的提取只关注与您的目标一致的不可抗拒的想法。</p>
</li>
</ul>
<h2 id="chapter-fifteen-第十五章">CHAPTER FIFTEEN 第十五章</h2>
<h2 id="creation-创造">CREATION 创造</h2>
<p>Here is a summary of the key points about note creation from the chapter:<br>
以下是关于笔记创建的关键要点的摘要：</p>
<ul>
<li>
<p>Notes are thought containers that capture ideas and develop thinking over time.<br>
笔记是思想的容器，能够随着时间的推移捕捉想法并发展思维。</p>
</li>
<li>
<p>The four main types of notes are:<br>
四种主要类型的笔记是：</p>
</li>
</ul>
<ol>
<li>
<p>Observation notes - brief notes made while reading sources<br>
观察记录 - 在阅读资料时所做的简要记录</p>
</li>
<li>
<p>Excerpt notes - direct quotes copied from sources<br>
摘录注释-直接引用自来源的文字</p>
</li>
<li>
<p>Reformulation notes - summarizing ideas in your own words<br>
改写笔记 - 用自己的话总结思想</p>
</li>
<li>
<p>Reflection notes - applying meaning and relating ideas to projects<br>
反思笔记 - 将意义应用于项目并将想法联系起来</p>
</li>
</ol>
<ul>
<li>
<p>Note creation is a means to an end, not the end goal itself. Focus on the process, not perfection.<br>
注意创造是达到目标的手段，而不是目标本身。专注于过程，而不是完美。</p>
</li>
<li>
<p>Review your Antinet before writing a note to avoid duplicates. Not every idea needs a main note.<br>
在写便签之前，请检查您的Antinet以避免重复。并非每个想法都需要一个主要便签。</p>
</li>
<li>
<p>When possible, write reflections as if teaching an audience to gain deeper understanding.<br>
尽可能地，将反思写作为了教导观众获得更深入的理解。</p>
</li>
<li>
<p>Reformulations aim for comprehension, reflections aim for understanding by relating ideas to experience.<br>
改述旨在理解，反思旨在通过将思想与经验联系起来来理解。</p>
</li>
<li>
<p>Other notes include collectives (links or references grouped by topic), hoplinks (brief cross-references), and keyterm indexcards.<br>
其他注意事项包括集体（按主题分组的链接或引用）、跳转链接（简短的交叉引用）和关键词索引卡。</p>
</li>
<li>
<p>Add your own flair and creativity. No one style is best. Focus on starting and building your notes over time.<br>
增加你自己的风格和创造力。没有一种风格是最好的。专注于逐渐开始并建立你的笔记。</p>
</li>
</ul>
<h2 id="chapter-sixteen-第十六章">CHAPTER SIXTEEN 第十六章</h2>
<h2 id="installation-安装">INSTALLATION 安装</h2>
<p>Here is a summary of the key points about installing notes from the chapter:<br>
以下是有关安装笔记的章节的关键要点摘要：</p>
<ul>
<li>
<p>Installation refers to determining where to place a new note in your Antinet system.<br>
安装是指确定在您的Antinet系统中放置新便签的位置。</p>
</li>
<li>
<p>Review your Antinet before writing a new note to find the best place to install it. This prevents duplicates and allows you to build on previous thinking.<br>
在撰写新的笔记之前，请先回顾您的Antinet，找到最佳安装位置。这样可以避免重复，并让您能够在之前的思考基础上进行建设。</p>
</li>
<li>
<p>Install notes under or behind the most similar existing note or branch. Use your index to find related keyterms and cardlinks.<br>
将笔记安装在最相似的现有笔记或分支下方或后方。使用索引查找相关关键词和卡片链接。</p>
</li>
<li>
<p>If a topic doesn't exist yet, create a new stem or branch for it. Add an index entry pointing to the new section.<br>
如果一个主题还不存在，就为它创建一个新的主干或分支。添加一个索引条目，指向新的部分。</p>
</li>
<li>
<p>Don't overdo indexing, especially early on. Only add keyterms when needed to find a note again. Index fatigue is real.<br>
不要过度索引，尤其是在早期阶段。只有在需要再次找到笔记时才添加关键词。索引疲劳是真实存在的。</p>
</li>
<li>
<p>The name of the game is similarity. Install notes among their most similar neighbors in your Antinet's tree structure.<br>
游戏的名字是相似性。在你的Antinet的树状结构中安装与它们最相似的邻居之间的注释。</p>
</li>
<li>
<p>Following the creation guidelines makes installation smooth. Determine placement first, then write the note to match that context.<br>
遵循创建指南可以使安装过程顺利进行。首先确定放置位置，然后编写相应的注释。</p>
</li>
<li>
<p>Keeping installation simple allows you to focus energy on writing great notes. Don't let organization become a burden.<br>
保持安装简单，让你能够将精力集中在写出优秀的笔记上。不要让组织变成负担。</p>
</li>
</ul>
<h1 id="part-4-the-nature-of-the-antinet">PART 4: THE NATURE OF THE ANTINET</h1>
<p>第四部分：反网的本质</p>
<h2 id="chapter-seventeen-第十七章">CHAPTER SEVENTEEN 第十七章</h2>
<h2 id="mindset-心态">MINDSET 心态</h2>
<p>Here is a summary of the key points about Antinet mindset and workflow from the chapter:<br>
以下是关于Antinet思维和工作流程的关键要点摘要：</p>
<ul>
<li>There are three main working states:<br>
有三种主要的工作状态：</li>
</ul>
<ol>
<li>
<p>Emergence - Exploratory research to discover new ideas<br>
新兴 - 探索性研究以发现新的想法</p>
</li>
<li>
<p>Evolutionary - Find supporting info for emerged ideas<br>
进化 - 寻找支持已出现的想法的信息</p>
</li>
<li>
<p>Producing - Creating output like writing using your notes<br>
生产 - 使用您的笔记创作输出，如写作</p>
</li>
</ol>
<ul>
<li>
<p>Work consistently each day, even if just 2 hours. Long-term consistency matters over intensity.<br>
每天都要保持持续工作，即使只有2个小时。长期的持续性比强度更重要。</p>
</li>
<li>
<p>Make your workspace analog to minimize digital distraction. Dedicate set time to deep focus.<br>
使你的工作空间模拟化，以最小化数字干扰。专注于深度工作的设定时间。</p>
</li>
<li>
<p>Luhmann worked long hours daily, but viewed it as fun vacation-like work. Make using your Antinet an enjoyable experience.<br>
卢曼每天工作很长时间，但他把它看作是一种有趣的像度假一样的工作。让使用你的Antinet成为一种愉快的体验。</p>
</li>
<li>
<p>Be willing to put in effort upfront in creating notes and indexing. It gets easier over time. Focus on the long game.<br>
愿意在创建笔记和索引方面付出努力。随着时间的推移，这将变得更容易。专注于长期目标。</p>
</li>
<li>
<p>Don't get bogged down importing old notes. Focus energy on developing new knowledge.<br>
不要陷入导入旧笔记的困境。将精力集中在开发新知识上。</p>
</li>
<li>
<p>Adopt a contribution mindset, using your notes to create works for your audience. This fuels motivation.<br>
采用贡献的心态，利用你的笔记为你的观众创作作品。这会激发动力。</p>
</li>
<li>
<p>Trust the process and give it time. The benefits compound and emerge in their own way down the road.<br>
相信这个过程，并给它时间。好处会逐渐累积，并在未来以自己的方式显现出来。</p>
</li>
</ul>
<h2 id="chapter-eighteen-第十八章">CHAPTER EIGHTEEN 第十八章</h2>
<h2 id="communication-with-your-second-mind">COMMUNICATION WITH YOUR SECOND MIND</h2>
<p>与你的第二思维进行沟通</p>
<p>Here is a summary of the key points about communication with the Antinet's second mind:<br>
以下是与Antinet的第二个思维进行沟通的关键要点摘要</p>
<ul>
<li>
<p>The Antinet becomes a second mind, not just a second brain. It is an active thinking partner.<br>
Antinet成为第二个思维，不仅仅是第二个大脑。它是一个积极的思考伙伴。</p>
</li>
<li>
<p>Communication emerges between you and your past self captured in the Antinet's notes. It's an intrapersonal dialogue.<br>
与你在Antinet的笔记中捕捉到的过去自己之间产生了沟通。这是一种内心对话。</p>
</li>
<li>
<p>Communication, especially being surprised, helps the Antinet generate insights. Selective relations enable this.<br>
沟通，尤其是被惊讶的时候，有助于Antinet产生洞察力。选择性的关系使其成为可能。</p>
</li>
<li>
<p>The Antinet develops its own unique personality through your handwriting, keywords, and structure.<br>
Antinet通过您的手写、关键词和结构来发展出自己独特的个性。</p>
</li>
<li>
<p>It takes time to reach a threshold and transition into a second mind. But then you can collaborate with this metaphysical entity.<br>
达到一个阈值并转变为第二个意识需要时间。但是之后你可以与这个形而上的实体合作。</p>
</li>
<li>
<p>The constraints of analog notes promote under-communication, triggering your mind's internal dialogue.<br>
模拟笔记的限制促进了沟通不足，触发了你的内心对话。</p>
</li>
<li>
<p>Viewing your thoughts makes the Antinet feel like a ghostly presence of your past self. It becomes an alter ego.<br>
查看你的思绪让Antinet感觉像是你过去自己的幽灵存在。它变成了一个分身。</p>
</li>
<li>
<p>Trust in the emergence of this hard-to-describe phenomenon. With practice, the second mind develops its own antifragile nature.<br>
相信这种难以描述的现象的出现。通过实践，第二个思维会发展出自己的抗脆弱性。</p>
</li>
<li>
<p>The second mind concept originated long before Luhmann, but his Antinet principles unlock its benefits.<br>
第二心灵概念在卢曼之前就已经产生，但他的反网络原则揭示了它的好处。</p>
</li>
<li>
<p>In the end, it's about communicating with an expression of your own consciousness to think better.<br>
最后，这是关于用自己的意识表达来更好地思考。</p>
</li>
</ul>
<h2 id="chapter-nineteen-第十九章">CHAPTER NINETEEN 第十九章</h2>
<h2 id="human-memory-and-the-antinet">HUMAN MEMORY AND THE ANTINET</h2>
<p>人类记忆与反网</p>
<p>Here is a summary of the key points about human memory and the Antinet from the chapter:<br>
这是关于人类记忆和Antinet的关键要点的摘要</p>
<ul>
<li>
<p>The Antinet's structure mirrors how human memory works, not digital storage. Luhmann modeled it after memory science.<br>
Antinet的结构反映了人类记忆的工作方式，而不是数字存储。卢曼是根据记忆科学对其进行建模的。</p>
</li>
<li>
<p>Notes are like neurons, cardlinks like neural connections. The Antinet forms a haptic neural network.<br>
笔记就像神经元，卡片链接就像神经连接。Antinet形成了一种触觉神经网络。</p>
</li>
<li>
<p>Context is critical - branches provide internal context for developing ideas. Context evolves based on content.<br>
上下文至关重要 - 分支为发展思想提供内部上下文。上下文根据内容而演变。</p>
</li>
<li>
<p>Physical notes capture internal and external context better than digital. This transports your mind back in time.<br>
纸质笔记比数字化的更能捕捉内外环境。这能让你的思绪回到过去。</p>
</li>
<li>
<p>Positional coding - knowing a note's placement relies on spatial memory. This mimics the method of loci.<br>
位置编码 - 知道音符的位置依赖于空间记忆。这模仿了记忆法的方法。</p>
</li>
<li>
<p>Cardlinks enable associations like those in memory - local (stemlinks) and remote (remotelinks).<br>
Cardlinks使得像内存中的关联一样的关联成为可能 - 本地的（stemlinks）和远程的（remotelinks）。</p>
</li>
<li>
<p>The Antinet relies on distributed representations, not discrete storage locations. Thoughts connect.<br>
Antinet依赖于分布式表示，而不是离散的存储位置。思维相互连接。</p>
</li>
<li>
<p>Noise and decay exist, just like in human memory. The system evolves organically over time.<br>
噪音和腐朽存在，就像人类记忆中一样。系统随着时间的推移有机地演变。</p>
</li>
<li>
<p>The explicit design mirrors memory science. This enables the Antinet to become a second mind, exceeding digital tools.<br>
明确的设计反映了记忆科学。这使得Antinet能够成为第二个思维，超越数字工具。</p>
</li>
<li>
<p>Understanding these principles lets you appreciate the system's genius. But empirical testing is still key for full comprehension.<br>
理解这些原则让你能够欣赏这个系统的天才之处。但是，经验测试对于完全理解仍然至关重要。</p>
</li>
</ul>
<h2 id="chapter-twenty-第二十章">CHAPTER TWENTY 第二十章</h2>
<h2 id="evolution-perception-perspective-and-ruminants">EVOLUTION, PERCEPTION, PERSPECTIVE AND RUMINANTS</h2>
<p>进化、感知、观点和反刍动物</p>
<p>Here is a summary of the key points about evolution, perception, perspective, and rumination from the chapter:<br>
这是关于进化、感知、观点和沉思的章节的关键要点摘要</p>
<ul>
<li>
<p>The Antinet's structure enables long-term evolution of ideas. You can see your mental history unfold over time.<br>
Antinet的结构使得思想的长期演化成为可能。您可以看到随着时间推移，您的思维历史逐渐展开。</p>
</li>
<li>
<p>Reviewing your Antinet helps avoid repeating what you already know. You also see your perspectives shift.<br>
审查您的Antinet有助于避免重复您已经知道的内容。您还会看到自己的观点发生变化。</p>
</li>
<li>
<p>Simple ideas compound over time into complex, interconnected pathways of knowledge. This takes effort but pays off.<br>
简单的想法随着时间的推移逐渐变成复杂而相互关联的知识路径。这需要努力，但会有回报。</p>
</li>
<li>
<p>Cards capture your perception (interpretation) and perspective (point of view) when created. This gets locked in time.<br>
卡片在创建时捕捉到了你的感知（解释）和观点（视角）。这被固定在时间中。</p>
</li>
<li>
<p>Reviewing old cards creates an internal dialogue between past and present perceptions and perspectives.<br>
回顾旧卡片之间产生了过去和现在的感知和观点之间的内部对话。</p>
</li>
<li>
<p>The Antinet is like a ruminant - it lets you slowly digest and ferment ideas over time before developing them.<br>
Antinet就像一只反刍动物-它让你在发展想法之前慢慢消化和发酵它们。</p>
</li>
<li>
<p>Reverberation of ideas leads to rumination when captured over the long term in an Antinet.<br>
思想的回响在长期被捕捉在反网络中时会导致沉思。</p>
</li>
<li>
<p>Read analytically, digesting books deeply. The Antinet stores these insights to compound and collide over time.<br>
阅读时要有分析能力，深入消化书籍。Antinet将这些洞察力储存起来，随着时间的推移不断积累和碰撞。</p>
</li>
<li>
<p>Trust in the organic, antifragile evolution of your ideas over the long haul. The results will surprise you.<br>
相信你的想法会在长期发展中有机地、抗压性地演变。结果会让你惊讶。</p>
</li>
</ul>
<h2 id="chapter-twenty-one-第二十一章">CHAPTER TWENTY-ONE 第二十一章</h2>
<h2 id="randomness-surprisesand-accidents">RANDOMNESS, SURPRISESAND ACCIDENTS</h2>
<p>随机性，惊喜和意外</p>
<p>Here is a summary of the key points about randomness, surprises, and accidents from the chapter:<br>
这是关于随机性、意外和事故的关键要点的摘要</p>
<ul>
<li>
<p>Randomness, surprises, and accidents are features, not bugs, of the Antinet's organic structure.<br>
随机性、惊喜和意外是Antinet有机结构的特点，而不是错误。</p>
</li>
<li>
<p>The tree structure and hard-to-create cardlinks generate useful surprises - insights you didn't intentionally design.<br>
树状结构和难以创建的卡片链接会产生有用的惊喜 - 这些洞见并非你有意设计的。</p>
</li>
<li>
<p>Heterogeneous relations between disparate ideas create bisociations and new understandings.<br>
异质的关系在不同的思想之间产生双重关联和新的理解。</p>
</li>
<li>
<p>Proximity of ideas in branches can create holistic entities greater than their parts.<br>
思想在分支中的接近可以创造出比它们各自更大的整体实体。</p>
</li>
<li>
<p>Accidents emerge from shuffling physical cards and prowling the stacks, not just focused searching.<br>
事故发生于洗牌实体卡和搜寻书堆，而不仅仅是专注搜索。</p>
</li>
<li>
<p>Movement creates more possibilities for useful accidents versus just meditation alone.<br>
运动创造了更多有益的偶然事件的可能性，而仅仅冥想是不够的。</p>
</li>
<li>
<p>Adopt a playful, curious spirit like John Venn instead of rigid overwork. This unlocks breakthroughs.<br>
像约翰·文恩一样采取一种好奇、玩乐的精神，而不是过度刻板的工作。这将带来突破。</p>
</li>
<li>
<p>Trust in the randomness. Don't fear the mess in your Antinet. Embrace odd structures along the way.<br>
相信随机性。不要害怕你的Antinet中的混乱。接受沿途的奇怪结构。</p>
</li>
<li>
<p>Surprises demonstrate the magic of communicating with your past self captured in the second mind.<br>
惊喜展示了与过去自己沟通的魔力，被捕捉在第二个心灵中。</p>
</li>
<li>
<p>The story about John Venn emerged as its own surprise thanks to the Antinet. Fittingly, it underscores the power of randomness.<br>
关于约翰·文恩的故事因Antinet而出人意料地浮现出来。恰如其分地，它强调了随机性的力量。</p>
</li>
</ul>
<h1 id="afterword-后记">AFTERWORD 后记</h1>
<h1 id="appendix-a-luhmannian-tree-structure-zettelkasten-i">APPENDIX A: LUHMANNIAN TREE STRUCTURE (ZETTELKASTEN I)</h1>
<p>附录A：卢曼树结构（ZETTELKASTEN I）</p>
<h1 id="appendix-b-luhmannian-tree-structure-zettelkasten-ii">APPENDIX B: LUHMANNIAN TREE STRUCTURE (ZETTELKASTEN II)</h1>
<p>附录B：卢曼树结构（ZETTELKASTEN II）</p>
<h1 id="appendix-c-digital-antinets">APPENDIX C: DIGITAL ANTINETS</h1>
<p>附录C：数字天线网络</p>
<h1 id="glossary-术语表">GLOSSARY 术语表</h1>
<h1 id="acknowledgments-致谢">ACKNOWLEDGMENTS 致谢</h1>
<h1 id="about-the-author-关于作者">ABOUT THE AUTHOR 关于作者</h1>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ANTINET 书籍总结（Deepl 中英对照）]]></title>
        <id>https://temberature.github.io/post/b1ZJUwopO/</id>
        <link href="https://temberature.github.io/post/b1ZJUwopO/">
        </link>
        <updated>2023-11-20T02:31:48.000Z</updated>
        <content type="html"><![CDATA[<p>以下是该文件要点的高度概括：</p>
<p>本书讲述的是一种名为 &quot;Antinet &quot;的模拟笔记系统，其灵感来自尼克拉斯-卢曼（Niklas Luhmann）的 Zettelkasten。</p>
<p>Antinet 有四个关键原则：</p>
<ul>
<li>
<p>模拟（在纸上手写笔记，而不是数字笔记）</p>
</li>
<li>
<p>数字-阿尔法地址（每个音符都有唯一的 ID）</p>
</li>
<li>
<p>树状结构（笔记形成一棵不断发展的有机思想树）</p>
</li>
<li>
<p>索引（关键术语提供了进入笔记的入口）</p>
</li>
</ul>
<p>这些原则结合在一起，可以实现深入思考、概念链接、创造力和几十年的知识进化。Antinet 成为与您交流的 &quot;第二大脑&quot;。</p>
<p>本书介绍了尼克拉斯-卢曼的背景及其观点。本书旨在澄清网上对 Zettelkasten 的误解。它提供了从零开始建造 Antinet 的实用指导。</p>
<p>知识发展分为 4 个主要阶段：</p>
<ul>
<li>
<p>选择（选择资料来源和想法）</p>
</li>
<li>
<p>提取（阅读时提取观点）</p>
</li>
<li>
<p>创作（做不同类型的笔记）</p>
</li>
<li>
<p>安装（将笔记归档到系统中）</p>
</li>
</ul>
<p>主要优势包括</p>
<ul>
<li>
<p>开发天才级工作</p>
</li>
<li>
<p>促成跨越数十年的长期项目</p>
</li>
<li>
<p>从相互联系的想法中创造惊喜和洞察力</p>
</li>
<li>
<p>加强记忆，减少认知偏差</p>
</li>
</ul>
<p>本书认为，在深入思考和创造力方面，模拟 Antinet 远远优于数字笔记。但是，要实现这些优势，需要长期的努力和坚持。</p>
<p>Here is a high-level summary of the key points from the document:</p>
<p>The book is about an analog note-taking system called the &quot;Antinet&quot; which is inspired by Niklas Luhmann's Zettelkasten.</p>
<p>The Antinet has 4 key principles:</p>
<ul>
<li>Analog (handwritten notes on paper, not digital)</li>
<li>Numeric-Alpha addresses (unique IDs for each note)</li>
<li>Tree structure (notes form an evolving, organic tree of ideas)</li>
<li>Index (keyterms provide entry points into the notes)</li>
</ul>
<p>Together these principles enable deep thinking, linking of concepts, creativity, and evolution of knowledge over decades. The Antinet becomes a &quot;second mind&quot; that you communicate with.</p>
<p>The book covers the background of Niklas Luhmann and his views. It aims to clear up misconceptions about the Zettelkasten online. It provides practical guidance on building an Antinet from scratch.</p>
<p>There are 4 main phases of knowledge development:</p>
<ul>
<li>Selection (choosing sources and ideas)</li>
<li>Extraction (pulling out ideas while reading)</li>
<li>Creation (making different types of notes)</li>
<li>Installation (filing notes in the system)</li>
</ul>
<p>Key benefits highlighted include:</p>
<ul>
<li>Developing genius-level work</li>
<li>Enabling long-term projects spanning decades</li>
<li>Creating surprises and insights from linking ideas</li>
<li>Strengthening memory and mitigating cognitive biases</li>
</ul>
<p>The book argues the analog Antinet is far superior to digital notes for deep thinking and creativity. But it requires long-term effort and consistency to realize the benefits.</p>
<h1 id="authors-note-作者注释">AUTHOR’S NOTE 作者注释</h1>
<h1 id="preface-do-not-skip">PREFACE (DO NOT SKIP)</h1>
<p>前言</p>
<p>Here is a summary of the key points from the document:<br>
以下是该文件的要点摘要：</p>
<p>The Antinet is a knowledge development system created using notecards. It was evolved over time by many great thinkers, but is often attributed to Niklas Luhmann.<br>
Antinet 是一种使用记事本创建的知识开发系统。它是由许多伟大的思想家逐渐发展而成的，但通常归功于尼克拉斯-卢曼（Niklas Luhmann）。</p>
<p>The Antinet has several meanings:<br>
Antinet 有多种含义：</p>
<ul>
<li>
<p>It's a tongue-in-cheek reference to the over-reliance on digital tools for thinking and knowledge development. The author believes analog tools are better for deep, deliberate thinking.<br>
这是对过度依赖数字工具进行思考和知识开发的一种调侃。作者认为，模拟工具更适合进行深思熟虑的思考。</p>
</li>
<li>
<p>It's an acronym that refers to the 4 principles of the system, which were used by Luhmann.<br>
这是一个首字母缩写词，指的是 Luhmann 使用的系统的 4 项原则。</p>
</li>
<li>
<p>It's a reference to Antonin Sertillanges, a Catholic intellectual who used a similar system.<br>
这指的是使用类似系统的天主教知识分子 Antonin Sertillanges。</p>
</li>
</ul>
<p>The book aims to uncover the &quot;true magic&quot; of the analog Antinet/Zettelkasten system. It focuses on how it can turn you into a prolific researcher, reader and writer.<br>
本书旨在揭示模拟 Antinet/Zettelkasten 系统的 &quot;真正魔力&quot;。它的重点是如何让您成为多产的研究者、读者和作家。</p>
<p>The book touches on the theoretical and practical aspects of the system, its history, and provides actionable techniques. It may need to be re-read at different stages as you build your own Antinet.<br>
本书涉及系统的理论和实践方面、系统的历史，并提供了可操作的技术。在您建立自己的 Antinet 的不同阶段，可能需要重新阅读本书。</p>
<p>Key advice includes: 主要建议包括</p>
<ul>
<li>Read Ch. 11 first to build a starter Antinet<br>
请先阅读第 11 章，以构建起步的 Antinet</li>
<li>Use the 2-step Luhmannian bibcard method to take notes while reading<br>
使用卢曼比卡两步法边读边记笔记</li>
<li>Don't get bogged down by footnotes on a first read<br>
初读时不要被脚注所困扰</li>
<li>Be prepared to actively apply the techniques<br>
准备好积极应用这些技术</li>
</ul>
<p>The book aims to help committed learners create genius-level work using an analog system of pen, paper and notecards.<br>
本书旨在帮助坚定的学习者使用笔、纸和记事本的模拟系统创作出天才级的作品。</p>
<h1 id="part-i-the-story-behind-the-story">PART I: THE STORY BEHIND THE STORY</h1>
<p>第 I 部分：故事背后的故事</p>
<h2 id="chapter-one-第一章">CHAPTER ONE 第一章</h2>
<h2 id="the-journey-that-led-me-to-publish-a-book-on-the-antinet">THE JOURNEY THAT LED ME TO PUBLISH A BOOK ON THE ANTINET</h2>
<p>我出版一本关于 antinet 的书的历程</p>
<p>Here is a summary of the key points from Chapter 1:<br>
以下是第 1 章的要点摘要：</p>
<ul>
<li>
<p>The author had previously co-founded a successful cryptocurrency company but left due to disillusionment and burnout.<br>
作者之前曾联合创办过一家成功的加密货币公司，但由于幻想破灭和倦怠而离开。</p>
</li>
<li>
<p>He spent time trying to figure out his next steps, reading books on his patio and taking notes ineffectively with a commonplace book.<br>
他在庭院里看书，用一本普通的书做笔记，但效果不佳。</p>
</li>
<li>
<p>He discovered the digital note-taking apps Foam and Obsidian and became enthused by their note-linking capabilities. However, this resulted in a messy over-linked network of digital notes.<br>
他发现了数字笔记应用程序 Foam 和 Obsidian，并为它们的笔记链接功能所吸引。然而，这样做的结果是，数字笔记的链接网络变得凌乱不堪。</p>
</li>
<li>
<p>He learned about the Zettelkasten system in the book &quot;How to Take Smart Notes&quot; by Sönke Ahrens. This described an analog paper-based note system used by Niklas Luhmann.<br>
他从 Sönke Ahrens 所著的《如何智能记笔记》一书中了解到 Zettelkasten 系统。这本书描述了尼克拉斯-卢曼使用的一种模拟纸质笔记系统。</p>
</li>
<li>
<p>Intrigued, the author tried using a real analog Zettelkasten and found it transformed his note-taking and writing. His thoughts flowed much better compared to digital apps.<br>
出于好奇，作者尝试使用真正的模拟 Zettelkasten，发现它改变了他的笔记和写作方式。与数字应用程序相比，他的思路更加流畅。</p>
</li>
<li>
<p>By studying Luhmann's archived Zettelkasten online, the author pieced together how the analog system worked in practice. He coined his version the &quot;Antinet&quot;.<br>
通过在线研究 Luhmann 的 Zettelkasten 档案，作者拼凑出了模拟系统的实际工作原理。他将自己的版本命名为 &quot;Antinet&quot;。</p>
</li>
<li>
<p>The Antinet helped the author make progress on a project about marketing and cryptocurrency. However, he felt compelled to write this book to share the power of the analog system with others.<br>
Antinet 帮助作者在一个关于市场营销和加密货币的项目上取得了进展。不过，他觉得自己有必要写这本书，与他人分享模拟系统的力量。</p>
</li>
<li>
<p>The author wants to help committed people create long-lasting work, even though focusing on the antiquated analog Zettelkasten seems absurd. He chose this path to genuinely help people rather than chase money.<br>
尽管专注于过时的模拟 Zettelkasten 似乎很荒谬，但作者希望帮助有决心的人创造出长久的作品。他选择这条道路是为了真正帮助人们，而不是追逐金钱。</p>
</li>
</ul>
<h2 id="chapter-two-第二章">CHAPTER TWO 第二章</h2>
<h2 id="the-who-and-why-of-the-antinet">THE WHO AND WHY OF THE ANTINET</h2>
<p>安提内特的来龙去脉</p>
<p>Here is a summary of the key points from Chapter 2:<br>
以下是第 2 章的要点摘要：</p>
<ul>
<li>
<p>The author clarifies who should and should not bother reading this book about the Antinet system.<br>
作者阐明了哪些人应该阅读这本关于 Antinet 系统的书，哪些人不应该阅读这本书。</p>
</li>
<li>
<p>It is best suited for serious writers, researchers, academics, and lifelong learners who wish to develop deep knowledge and creative insights.<br>
它最适合严肃的作家、研究人员、学者以及希望发展深厚知识和创造性见解的终身学习者。</p>
</li>
<li>
<p>However, it requires a long-term time commitment of decades to fully realize the benefits. It is not for those with tight deadlines or limited time.<br>
然而，它需要几十年的长期时间投入才能充分实现其效益。它不适合那些时间紧迫或时间有限的人。</p>
</li>
<li>
<p>The Antinet excels at developing unconventional interactions between ideas that lead to creative insights and genius-level work. This emerges from its analog tree structure.<br>
Antinet 擅长在各种想法之间建立非传统的互动关系，从而产生创造性的见解和天才级的作品。这源于它的模拟树形结构。</p>
</li>
<li>
<p>It shines for long-term multi-year projects and enabling knowledge to compound over decades. This cannot occur in siloed, categorized systems.<br>
它适用于长期的多年期项目，并能使知识在数十年间不断复合。这在各自为政的分类系统中是无法实现的。</p>
</li>
<li>
<p>The Antinet reveals structured accidents - surprising connections that emerge through browsing nearby tree branches. This cannot be replicated digitally.<br>
Antinet 揭示了结构性的意外--通过浏览附近的树枝而产生的惊人联系。这是无法用数字技术复制的。</p>
</li>
<li>
<p>Niklas Luhmann created the Zettelkasten for a 30-year theory of everything project. However, his books were often poorly written and impenetrable due to his trollish nature.<br>
尼克拉斯-卢曼（Niklas Luhmann）创建了 &quot;Zettelkasten&quot;，进行了长达 30 年的万物理论研究。然而，由于他的巨魔性格，他的书往往文笔拙劣，难以理解。</p>
</li>
<li>
<p>The Antinet should not be expected to magically produce perfect writings without hard work. But it develops deeper ideas than other systems.<br>
我们不能指望安提内特不经过艰苦努力就能神奇地写出完美的文章。但与其他体系相比，它能发展出更深刻的思想。</p>
</li>
<li>
<p>In summary, the Antinet is best for serious thinkers aiming to produce unconventional, creative and long-lasting work over decades, not those seeking easy solutions.<br>
总之，Antinet 最适合那些严肃的思想家，他们的目标是在数十年内创作出非传统的、有创造力的和持久的作品，而不是那些寻求简单解决方案的人。</p>
</li>
</ul>
<h2 id="chapter-three-第三章">CHAPTER THREE 第三章</h2>
<h2 id="the-current-zettelkasten-landscape">THE CURRENT ZETTELKASTEN LANDSCAPE</h2>
<p>当前的zettelkasten格局</p>
<p>Here is a summary of the key points from Chapter 3:<br>
以下是第 3 章的要点摘要：</p>
<ul>
<li>
<p>The current landscape of information on Zettelkasten online and in books is riddled with inaccuracies.<br>
目前网上和书本上关于 Zettelkasten 的信息充满了不准确之处。</p>
</li>
<li>
<p>Popular sources like Wikipedia and zettelkasten.de get important aspects wrong, like describing it as hierarchical or advocating for digital notes.<br>
维基百科和 zettelkasten.de 等流行资料在一些重要方面存在错误，例如将其描述为分级制度或主张使用数字笔记。</p>
</li>
<li>
<p>Sönke Ahrens' book introduced concepts like fleeting notes and literature notes that are not part of Luhmann's original Zettelkasten.<br>
Sönke Ahrens 在书中引入了转瞬即逝的笔记和文学笔记等概念，而这些概念并不属于 Luhmann 最初的 Zettelkasten。</p>
</li>
<li>
<p>A new wave of &quot;Ahrensians&quot; have created more layers of complexity and contradictions trying to adapt the system to digital tools.<br>
新一波的 &quot;阿伦派 &quot;试图使系统适应数字工具，从而制造了更多层次的复杂性和矛盾。</p>
</li>
<li>
<p>For example, some advocates undermine Luhmann's numeric-alpha note IDs or promote digital search over analog serendipity.<br>
例如，一些倡导者破坏了 Luhmann 的数字-字母注释 ID，或提倡数字搜索而非模拟偶然性。</p>
</li>
<li>
<p>The analog system's essence is lost in digital knockoffs. Luhmann saw it as a thinking tool and communication partner.<br>
模拟系统的精髓已被数字仿制品所掩盖。卢曼将其视为思考工具和交流伙伴。</p>
</li>
<li>
<p>The author wants to share insights from studying Luhmann's archive to help committed learners avoid wasting time on inaccurate methods.<br>
作者希望与大家分享研究 Luhmann 档案的心得，帮助坚定的学习者避免在不准确的方法上浪费时间。</p>
</li>
<li>
<p>He cares about this niche group and wants to serve them, unlike his past work in cryptocurrency catering to speculators.<br>
他关心这个小众群体，并希望为他们服务，这与他过去在加密货币领域迎合投机者的工作不同。</p>
</li>
<li>
<p>In summary, the current landscape spreads misconceptions about Zettelkasten, but the author aims to uncover its true analog nature.<br>
总之，当前的景观传播着对 Zettelkasten 的误解，但作者的目的是揭示其真实的模拟性质。</p>
</li>
</ul>
<h2 id="chapter-four-第四章">CHAPTER FOUR 第四章</h2>
<h2 id="niklas-luhmann-the-man">NIKLAS LUHMANN, THE MAN</h2>
<p>尼克拉斯-卢曼</p>
<p>Here is a summary of the key points about Niklas Luhmann from Chapter 4:<br>
以下是第 4 章中有关尼克拉斯-卢曼的要点摘要：</p>
<ul>
<li>
<p>Understanding Luhmann's background, theories, views, and personality provides context for the nature of the Antinet system he created.<br>
了解 Luhmann 的背景、理论、观点和个性，就能了解他所创建的 Antinet 系统的性质。</p>
</li>
<li>
<p>Luhmann was born in 1927 in Germany. His passion was reading, thinking and writing. He created his Zettelkasten system to aid this.<br>
卢曼 1927 年出生于德国。他热衷于阅读、思考和写作。他创造了 Zettelkasten 系统来辅助阅读、思考和写作。</p>
</li>
<li>
<p>He was not interested in drinking or socializing. He prioritized expanding his mind over advancing his early career.<br>
他不喜欢喝酒或社交。比起早期的职业生涯，他更注重拓展思维。</p>
</li>
<li>
<p>His political views trended libertarian. He aimed to remain detached and avoid moralizing issues.<br>
他的政治观点倾向于自由主义。他力求保持超脱，避免将问题道德化。</p>
</li>
<li>
<p>Core concepts in Luhmann's work were communication, systems theory, complexity, and autopoiesis.<br>
卢曼工作的核心概念是交流、系统理论、复杂性和自生。</p>
</li>
<li>
<p>He took an anti-humanist, anti-regionalist approach to sociology, applying biological concepts to social systems.<br>
他对社会学采取了一种反人文主义、反地域主义的方法，将生物学概念应用于社会系统。</p>
</li>
<li>
<p>Luhmann had an ironic, absurdist, and carnivalesque attitude. He was a polite troll who provoked with his theories.<br>
卢曼具有讽刺、荒诞和狂欢的态度。他是一个彬彬有礼的 &quot;巨怪&quot;，用他的理论进行挑衅。</p>
</li>
<li>
<p>He was dedicated to his intellectual pursuits, desiring more time for reading, writing and thinking.<br>
他一心追求知识，希望有更多的时间阅读、写作和思考。</p>
</li>
<li>
<p>Luhmann produced an enormous volume of writing and books with the aid of his Zettelkasten system.<br>
卢曼借助他的 Zettelkasten 系统创作了大量的文字和书籍。</p>
</li>
<li>
<p>In summary, understanding Luhmann's unconventional mindset helps appreciate the nature of the Antinet system he devised.<br>
总之，了解 Luhmann 的非传统思维方式有助于理解他所设计的 Antinet 系统的本质。</p>
</li>
</ul>
<h1 id="part-2-the-antinet">PART 2: THE ANTINET</h1>
<p>第 2 部分：天线</p>
<h2 id="chapter-five-第五章">CHAPTER FIVE 第五章</h2>
<h2 id="what-is-an-antinet">WHAT IS AN ANTINET?</h2>
<p>什么是天线罩？</p>
<p>Here is a summary of the key points from Chapter 5:<br>
以下是第 5 章的要点摘要：</p>
<ul>
<li>
<p>The term &quot;Antinet&quot; refers to the four principles of Niklas Luhmann's Zettelkasten system: Analog, Numeric-alpha addresses, Tree structure, and Index.<br>
Antinet &quot;一词指的是 Niklas Luhmann 的 Zettelkasten 系统的四个原则：模拟、数字-阿尔法地址、树形结构和索引。</p>
</li>
<li>
<p>Luhmann created his system to challenge simplistic views of good vs evil. A childhood experience of being abused by American soldiers showed him the world's complexity.<br>
卢曼创建他的系统是为了挑战简单的善恶观。童年被美国士兵虐待的经历让他看到了世界的复杂性。</p>
</li>
<li>
<p>The Antinet functions like an adaptive optics system, transforming distorted thoughts into clear ideas. It exercises your neuro-associative recall ability.<br>
Antinet 的功能就像一个自适应光学系统，能将扭曲的想法转化为清晰的思路。它能锻炼你的神经联想记忆能力。</p>
</li>
<li>
<p>An Antinet is not just analog storage. It's a thinking and thought development system that becomes a second mind over time.<br>
Antinet 不仅仅是模拟存储器。它是一个思维和思维发展系统，随着时间的推移，会成为第二个头脑。</p>
</li>
<li>
<p>The second mind emerges through neuroimprinting, internal dialogue, and communicating with your past self's handwriting. It has its own personality.<br>
通过神经印记、内心对话以及与过去的自己的笔迹交流，第二心灵就会出现。它有自己的个性。</p>
</li>
<li>
<p>The four principles transform the raw notecards into a whole greater than the parts. This cannot be replicated digitally.<br>
这四项原则将原始的记事本转化为一个大于部分的整体。这一点无法通过数字技术复制。</p>
</li>
<li>
<p>Antinets excel at developing unconventional insights, evolving ideas over decades, and revealing &quot;structured accidents.&quot;<br>
Antinets 善于提出非传统的见解，在数十年间不断发展思想，并揭示 &quot;结构性意外&quot;。</p>
</li>
<li>
<p>An Antinet is not a memory aid, but a thinking system. It strengthens memory faculties and mitigates cognitive biases.<br>
Antinet 不是一种记忆辅助工具，而是一种思维系统。它能增强记忆能力，减少认知偏差。</p>
</li>
<li>
<p>Simply linking digital notes misses the essence of Luhmann's system. His analog principles imprint thoughts and create dialogue.<br>
简单地将数字音符连接起来，忽略了 Luhmann 系统的精髓。他的模拟原理为思想打下了烙印，并创造了对话。</p>
</li>
<li>
<p>In summary, &quot;Antinet&quot; refers to the unique analog system Luhmann devised to develop complex, deep knowledge over time.<br>
总之，&quot;Antinet &quot;指的是 Luhmann 设计的独特的模拟系统，该系统可以随着时间的推移发展出复杂、深奥的知识。</p>
</li>
</ul>
<h2 id="chapter-six-第六章">CHAPTER SIX 第六章</h2>
<h2 id="analog-模拟">ANALOG 模拟</h2>
<p>Here is a summary of the key points from the chapter:<br>
以下是本章的要点摘要：</p>
<p>The Analog Pros and Cons<br>
模拟的优点和缺点</p>
<ul>
<li>Analog Pros: 模拟专业</li>
</ul>
<ol>
<li>Creates a better communication partner than digital<br>
打造比数字技术更好的交流伙伴</li>
<li>Captures one's consciousness and past self better<br>
更好地捕捉自己的意识和过去的自己</li>
<li>Transforms the Zettelkasten into a thinking tool for short and long-term development<br>
将 Zettelkasten 转化为短期和长期发展的思考工具</li>
<li>Forces unlimited combinations of thought due to notecards' limited space<br>
由于记事本的空间有限，因此可以进行无限的思维组合</li>
<li>Prevents hyper-selection of irrelevant material while reading<br>
防止阅读时过度选择无关材料</li>
<li>Enables better familiarity with knowledge through constant review<br>
通过不断审查，更好地熟悉知识</li>
<li>Exposes mistakes and self-deceptions effectively<br>
有效揭露错误和自我欺骗</li>
</ol>
<ul>
<li>Analog Cons: 模拟缺点</li>
</ul>
<ol>
<li>Risk of destruction from fire, flood, etc.<br>
火灾、洪水等破坏风险</li>
<li>Harder than digital in terms of effort required<br>
就所需付出的努力而言，比数字技术更难</li>
<li>Less mobile than digital<br>
移动性低于数字化</li>
</ol>
<p>Comparison to Digital 与数字技术的比较</p>
<ul>
<li>Digital can aid in productivity but lacks the communication component of analog<br>
数字技术有助于提高生产率，但缺乏模拟技术的通信功能</li>
<li>Digital is more distracting and leads to less happiness and poorer health outcomes<br>
数字技术更容易分散注意力，导致幸福感降低和健康状况恶化</li>
<li>Luhmann likely would have stuck with analog even if he had access to digital tools<br>
即使可以使用数字工具，卢曼也可能会坚持使用模拟工具</li>
</ul>
<p>The Power of Writing by Hand<br>
手写的力量</p>
<ul>
<li>Writing by hand disentangles thoughts, enhances memory and neuro-associative recall, improves learning, and leads to better mood<br>
手写能理清思路，增强记忆和神经联想，提高学习能力，改善情绪</li>
<li>Both scientific research and biblical verses support the power of writing by hand over typing<br>
科学研究和圣经经文都支持手写比打字更有力量</li>
<li>Many great thinkers and writers use analog tools and write by hand<br>
许多伟大的思想家和作家都使用模拟工具和手写工具</li>
</ul>
<p>Overall, the chapter covers the benefits and drawbacks of analog Zettelkasten systems compared to digital. It makes a strong case for the power of writing by hand and using physical note cards to develop deep thinking and creativity.<br>
总之，本章介绍了模拟 Zettelkasten 系统与数字 Zettelkasten 系统相比的优缺点。该章有力地证明了手写和使用实物便签卡对培养深度思维和创造力的作用。</p>
<h2 id="chapter-seven-第七章">CHAPTER SEVEN 第七章</h2>
<h2 id="numeric-alpha-数字-字母">NUMERIC-ALPHA 数字-字母</h2>
<p>Here is a summary of the key points from the chapter:<br>
以下是本章的要点摘要：</p>
<p>Numeric-Alpha Addresses 数字字母地址</p>
<ul>
<li>
<p>Numeric-alpha addresses are a critical component of the Antinet system. They give each note a unique identifier and location.<br>
数字-阿尔法地址是 Antinet 系统的重要组成部分。它们赋予每个音符唯一的标识符和位置。</p>
</li>
<li>
<p>The addresses provide structure and order, allowing notes to be easily linked and retrieved.<br>
地址提供了结构和顺序，使笔记易于链接和检索。</p>
</li>
<li>
<p>Numeric-alpha addresses have a long history, used in systems dating back to the 1700s. Luhmann likely adapted them from his work in the legal system.<br>
数字字母地址由来已久，可追溯到 17 世纪的系统中。Luhmann 很可能是根据他在法律系统中的工作对其进行了改编。</p>
</li>
<li>
<p>The addresses make the Antinet self-referential, allowing it to function as a communication partner.<br>
这些地址使 Antinet 具有自我参照性，使其能够作为通信伙伴发挥作用。</p>
</li>
<li>
<p>In memory science, numeric-alpha addresses resemble auto-associative networks in the brain.<br>
在记忆科学中，数字-阿尔法地址类似于大脑中的自动关联网络。</p>
</li>
</ul>
<p>Links 链接</p>
<ul>
<li>
<p>There are two main types of links: internal (within the Antinet) and external (to outside sources).<br>
链接主要有两种：内部链接（Antinet 内部）和外部链接（外部来源）。</p>
</li>
<li>
<p>Internal links include stemlinks, branchlinks, remotelinks, and keyterm links. They connect related ideas.<br>
内部链接包括主干链接、分支链接、remotelinks 和关键字链接。它们将相关的想法连接起来。</p>
</li>
<li>
<p>External links reference outside sources like books, articles, videos, etc.<br>
外部链接参考书籍、文章、视频等外部来源。</p>
</li>
<li>
<p>Links enable associations, which are critical for learning and insight. The Antinet's structure mirrorsassociative networks in memory.<br>
联想是学习和洞察力的关键。Antinet 的结构反映了记忆中的联想网络。</p>
</li>
<li>
<p>Digital tools don't optimize associations like the Antinet does through numeric-alpha addresses.<br>
数字工具无法像 Antinet 那样通过数字阿尔法地址优化关联。</p>
</li>
</ul>
<p>In summary, this chapter covered the importance of the Antinet's numeric-alpha address structure and linking system. Together they enable enhanced learning, creativity, and communication compared to digital notes.<br>
总之，本章介绍了 Antinet 的数字-字母地址结构和链接系统的重要性。与数字笔记相比，它们共同增强了学习能力、创造力和交流能力。</p>
<h2 id="chapter-eight-第八章">CHAPTER EIGHT 第八章</h2>
<h2 id="tree-树">TREE 树</h2>
<p>Here is a summary of the key points from the chapter:<br>
以下是本章的要点摘要：</p>
<p>Tree Structure of the Antinet<br>
Antinet 的树状结构</p>
<ul>
<li>
<p>The structure of the Antinet is best represented as a tree, with branches, stems, leaves, and vines.<br>
安提内特的结构最好表现为一棵树，有树枝、树干、树叶和藤蔓。</p>
</li>
<li>
<p>This tree structure allows for internal branching and evolution of thoughts over time.<br>
这种树形结构允许内部分支和思想随时间演变。</p>
</li>
<li>
<p>It provides order while still embracing some chaos and roughness.<br>
它在提供秩序的同时，也包容了一些混乱和粗糙。</p>
</li>
<li>
<p>Notes are positioned based on location, not rank. There is no hierarchy.<br>
笔记根据位置而不是等级来定位。没有等级之分。</p>
</li>
<li>
<p>The structure mirrors associative networks in human memory.<br>
人类记忆中联想网络的结构镜像</p>
</li>
<li>
<p>It enables reverberation of linked concepts and surprising discoveries.<br>
它使相关的概念和惊人的发现产生共鸣。</p>
</li>
</ul>
<p>Classification Systems 分类系统</p>
<ul>
<li>
<p>Different classification systems can provide starting branches, like Luhmann's or academic disciplines.<br>
不同的分类系统可以提供起始分支，如 Luhmann 或学科。</p>
</li>
<li>
<p>But fuzzy categories and internal growth are more important than rigid taxonomy.<br>
但是，模糊的分类和内部增长比僵化的分类更重要。</p>
</li>
<li>
<p>The index supplements classification limitations. The structure evolves based on use.<br>
索引补充了分类限制。该结构根据使用情况不断变化。</p>
</li>
</ul>
<p>Metaphysics of Trees 树木的形而上学</p>
<ul>
<li>
<p>Trees play a central role in myths, stories, and belief systems throughout history.<br>
树在历史的神话、故事和信仰体系中扮演着核心角色。</p>
</li>
<li>
<p>They represent life, knowledge, enlightenment, and the creative force.<br>
它们代表生命、知识、启迪和创造力。</p>
</li>
<li>
<p>Understanding the metaphysics reinforces the power of tree structures for knowledge.<br>
对形而上学的理解增强了树状结构的知识力量。</p>
</li>
</ul>
<p>In summary, this chapter covered the Antinet's rough tree structure, classification systems, and the metaphysical symbolism of trees. Together they provide a framework optimized for evolving thoughts and insights.<br>
总之，本章介绍了 Antinet 的粗略树形结构、分类系统以及树的形而上学象征意义。它们共同为思想和见解的发展提供了一个优化的框架。</p>
<h2 id="chapter-nine-第九章">CHAPTER NINE 第九章</h2>
<h2 id="index-索引">INDEX 索引</h2>
<p>Here is a summary of the key points from the chapter:<br>
以下是本章的要点摘要：</p>
<p>The Index 索引</p>
<ul>
<li>
<p>The index is a critical component for navigating the Antinet. It serves as a second map.<br>
索引是浏览 Antinet 的重要组成部分。它是第二张地图。</p>
</li>
<li>
<p>It contains keyterms that act as cues to access areas of knowledge.<br>
它包含的关键术语可作为进入知识领域的线索。</p>
</li>
<li>
<p>Keyterms point to locations in the Antinet via numeric-alpha addresses.<br>
关键字通过数字字母地址指向 Antinet 中的位置。</p>
</li>
<li>
<p>There are two types of index cards: list cards and dedicated keyterm cards.<br>
索引卡有两种类型：列表卡片和专用关键词卡片。</p>
</li>
<li>
<p>The index provides flexible access without rigid taxonomy limitations.<br>
该索引提供了灵活的访问方式，而没有严格的分类限制。</p>
</li>
<li>
<p>It enables cued recall and neuro-associative processing.<br>
它可以进行提示性回忆和神经联想处理。</p>
</li>
</ul>
<p>Against Digital Search 反对数字搜索</p>
<ul>
<li>
<p>Search is actually a bug, not an inherently desirable feature.<br>
搜索实际上是一个错误，而不是一个固有的理想功能。</p>
</li>
<li>
<p>Digital search yields too many low relevance results, creating noise.<br>
数字搜索产生了太多相关度低的结果，造成了噪音。</p>
</li>
<li>
<p>It eliminates the structured exploration of associations and serendipity.<br>
它消除了对联想和偶然性的结构化探索。</p>
</li>
<li>
<p>Search prevents maintenance rehearsal learning and evolving unique structures.<br>
搜索可以防止维护性排练学习和不断演化的独特结构。</p>
</li>
<li>
<p>It fails to improve mood and cognition like associative processing does.<br>
它无法像联想处理那样改善情绪和认知。</p>
</li>
</ul>
<p>In summary, the index transforms the Antinet into an explorable knowledge network. Avoiding digital search forces more valuable practices for developing insights.<br>
总之，索引将 Antinet 转化为一个可探索的知识网络。避免了数字搜索，从而为提出见解提供了更有价值的做法。</p>
<h2 id="chapter-ten-第十章">CHAPTER TEN 第十章</h2>
<h2 id="network-网络">NETWORK 网络</h2>
<p>Here is a summary of the key points from the chapter:<br>
以下是本章的要点摘要：</p>
<p>The Antinet as a Cybernetic Network<br>
作为控制论网络的 Antinet</p>
<ul>
<li>
<p>The Antinet is a cybernetic system, aimed at communication and control through feedback.<br>
Antinet 是一个控制论系统，旨在通过反馈进行交流和控制。</p>
</li>
<li>
<p>Cybernetics involves achieving a goal by steering in the right direction.<br>
控制论涉及通过正确的方向来实现目标。</p>
</li>
<li>
<p>The Antinet's network structure resembles associationism and neural networks.<br>
Antinet 的网络结构类似于联想主义和神经网络。</p>
</li>
<li>
<p>Associations are built on contiguity (continuous flow of thought) and similarity.<br>
联想建立在连续性（思维的持续流动）和相似性的基础上。</p>
</li>
<li>
<p>Numeric-alpha addresses create a self-referential, closed loop system.<br>
数字-阿尔法地址创建了一个自我参照的闭环系统。</p>
</li>
<li>
<p>This closure enables feedback signals when searching for ideas.<br>
这种闭合可以在搜索创意时发出反馈信号。</p>
</li>
<li>
<p>Feedback prompts course-correction and new insights along the way.<br>
通过反馈，可以纠正方向并获得新的见解。</p>
</li>
<li>
<p>Digital notes lack the rich feedback loops of the Antinet's cybernetic network.<br>
数字音符缺乏 Antinet 电子网络的丰富反馈回路。</p>
</li>
</ul>
<p>In summary, this chapter explains how the Antinet functions as a cybernetic system optimized for communication between past and present thoughts. The network structure reinforced by numeric addresses generates valuable feedback and insights. This cybernetic nature is a key advantage over digital notes.<br>
总之，本章介绍了 Antinet 如何作为一个控制论系统，在过去和现在的思想交流中发挥优化作用。通过数字地址强化的网络结构可以产生有价值的反馈和见解。与数字笔记相比，这种控制论性质是一个关键优势。</p>
<h2 id="chapter-eleven-第十七章">CHAPTER ELEVEN 第十七章</h2>
<h2 id="the-hitchhikers-guide-to-the-antinet">THE HITCHHIKER’S GUIDE TO THE ANTINET</h2>
<p>搭便车者的安提内特指南</p>
<p>Here is a summary of the key points from the chapter:<br>
以下是本章的要点摘要：</p>
<p>Obstacles and Mindset 障碍与心态</p>
<ul>
<li>
<p>Avoid perfectionism - the system evolves over time. Mistakes and imperfections have value.<br>
避免完美主义--系统会随着时间不断发展。错误和不完美都是有价值的。</p>
</li>
<li>
<p>Have faith in the power of analog tools for thinking. Don't get distracted by digital myths.<br>
相信模拟工具的思维力量。不要被数字神话所迷惑。</p>
</li>
<li>
<p>Adopt a growth vs contribution mindset. Strive to create work to teach others.<br>
采用成长与贡献的思维模式。努力创造能教给他人的作品。</p>
</li>
<li>
<p>Have some goal or focus area in mind before starting.<br>
在开始之前，心中要有一些目标或重点领域。</p>
</li>
</ul>
<p>Building the Antinet 建造 Antinet</p>
<ul>
<li>
<p>The core components are the main box, index box, and bib box.<br>
核心组件包括主框、索引框和围栏框。</p>
</li>
<li>
<p>Main box stores developed thoughts, index provides entry points.<br>
主力店开拓思路，指数提供切入点。</p>
</li>
<li>
<p>Academic disciplines provide a robust classification system.<br>
学科提供了一个强大的分类系统。</p>
</li>
<li>
<p>Numeric-alpha addresses identify note locations.<br>
数字字母地址标识注释位置。</p>
</li>
<li>
<p>Index keyterms serve as cues to find ideas.<br>
索引关键词可作为查找创意的线索。</p>
</li>
<li>
<p>Add sources to notes via ExRefs.<br>
通过 ExRefs 为注释添加资料来源。</p>
</li>
<li>
<p>It's simple but requires deliberate effort over time.<br>
这很简单，但需要长期的刻意努力。</p>
</li>
</ul>
<p>In summary, this chapter provided guidance on the mindset and practical steps for building an Antinet from scratch. With the foundation established, one can now begin developing knowledge through reading and note-taking.<br>
总之，本章为从零开始学习 Antinet 提供了思维方式和实际步骤方面的指导。有了基础，现在就可以开始通过阅读和记笔记来积累知识。</p>
<h1 id="part-3-knowledge-development">PART 3: KNOWLEDGE DEVELOPMENT</h1>
<p>第 3 部分：知识发展</p>
<h2 id="chapter-twelve-第十二章">CHAPTER TWELVE 第十二章</h2>
<h2 id="knowledge-development-知识发展">KNOWLEDGE DEVELOPMENT 知识发展</h2>
<p>Here is a summary of the key points from the chapter:<br>
以下是本章的要点摘要：</p>
<ul>
<li>
<p>Knowledge development involves evolving thoughts and thinking over time.<br>
知识的发展涉及思想和思维的长期演变。</p>
</li>
<li>
<p>The DIKW pyramid defines data, information, knowledge, and wisdom.<br>
DIKW 金字塔定义了数据、信息、知识和智慧。</p>
</li>
<li>
<p>Knowledge = meaningful, structured information that can be taught.<br>
知识 = 可以传授的有意义、有条理的信息。</p>
</li>
<li>
<p>Analog tools develop knowledge better than digital tools.<br>
模拟工具比数字工具更能开发知识。</p>
</li>
<li>
<p>Knowledge development has 4 main phases:<br>
知识发展分为 4 个主要阶段：</p>
</li>
</ul>
<ol>
<li>
<p>Selection - Choose irresistible information from sources.<br>
选择--从信息源中选择无法抗拒的信息。</p>
</li>
<li>
<p>Extraction - Write down selections from reading/listening.<br>
摘录--写下阅读/听力中的选段。</p>
</li>
<li>
<p>Creation - Make notes: excerpts, reformulations, reflections.<br>
创作 - 做笔记：摘录、改写、思考。</p>
</li>
<li>
<p>Installation - File notes and index key ideas.<br>
安装 - 文件注释和关键概念索引。</p>
</li>
</ol>
<ul>
<li>
<p>Knowledge development simplifies complexity (sources), extracts meaning, and builds new complexity (in notes).<br>
知识发展简化复杂性（来源）、提取意义并构建新的复杂性（注释）。</p>
</li>
<li>
<p>The goal is creating shareable knowledge, not just collecting information.<br>
目标是创造可共享的知识，而不仅仅是收集信息。</p>
</li>
</ul>
<p>In summary, this chapter explains the nature of knowledge and how the Antinet develops it through deliberate reading, note-taking, and evolution of ideas over time. This process transforms information into meaningful, structured knowledge.<br>
总之，本章解释了知识的本质，以及安提奈特人如何通过有意识的阅读、笔记和思想演变来发展知识。这一过程将信息转化为有意义、有条理的知识。</p>
<h2 id="chapter-thirteen-第十三章">CHAPTER THIRTEEN 第十三章</h2>
<h2 id="selection-选择">SELECTION 选择</h2>
<p>Here is a summary of the key points from the chapter:<br>
以下是本章的要点摘要：</p>
<ul>
<li>
<p>Selection is critical when working with an Antinet. It involves selecting what sources to read, what ideas to extract, and where to link ideas in your Antinet.<br>
在使用 Antinet 时，选择至关重要。这包括选择阅读哪些资料、提取哪些观点以及在 Antinet 中将观点链接到何处。</p>
</li>
<li>
<p>Selection underlies communication. Luhmann viewed communication as founded on three selections: selection of information, selection of message, and selective interpretation.<br>
选择是传播的基础。卢曼认为，传播建立在三种选择之上：信息选择、信息选择和选择性阐释。</p>
</li>
<li>
<p>Knowledge selection is like natural selection. You select &quot;mate&quot; sources and extract &quot;genetic&quot; ideas from them to create new knowledge. The knowledge best adapted to your environment (audience) will spread.</p>
</li>
<li>
<p>There are three levels of selection: source selection, link selection, and material selection. Be selective in what you read, what you link cards to, and what ideas you extract.</p>
</li>
<li>
<p>Avoid overselection. Digital tools make it too easy to capture too much. Analog forces you to be selective. Hard links are superior to hyperlinks.</p>
</li>
<li>
<p>For material selection, focus only on irresistible ideas - the most important and applicable ideas to you. Ignore bad, good, even excellent ideas.</p>
</li>
<li>
<p>Priming before reading involves previewing the source and setting a reading goal. This focuses your selection.</p>
</li>
<li>
<p>Developing good selection skills requires practice and feedback. Publishing your work provides feedback on your selection abilities.</p>
</li>
</ul>
<h2 id="chapter-fourteen">CHAPTER FOURTEEN</h2>
<h2 id="extraction">EXTRACTION</h2>
<p>Here is a summary of the key points about extraction from the chapter:</p>
<ul>
<li>
<p>Extraction involves pulling out and marking material to make into notes. There are intentional vs exploratory strategies.</p>
</li>
<li>
<p>Extraction methods include:</p>
</li>
</ul>
<ol>
<li>
<p>1-Step Book-to-Maincard: Stop reading to make a note on a card. Good for unfamiliar/complex books.</p>
</li>
<li>
<p>2-Step Marginalia: Mark passages in books, then extract later. Risks overselection.</p>
</li>
<li>
<p>Other Methods: Highlighting, headings, summaries. Help comprehension.</p>
</li>
</ol>
<ul>
<li>
<p>The 2-Step Luhmannian Bibcard Method is best:</p>
</li>
<li>
<p>Front of bibcard has source details, reading goal, overview.<br>
资料卡正面有资料来源详情、阅读目标和概述。</p>
</li>
<li>
<p>Back has bibnotes - brief notes/keyterms from reading.<br>
背面有书签--阅读时的简要注释/关键词。</p>
</li>
<li>
<p>Later convert bibnotes into maincards or ExRefs.<br>
之后再将 bibnotes 转换为主卡或 ExRefs。</p>
</li>
<li>
<p>Bibnotes link ideas to page numbers for selective reading. They prime neuro-associative recall.<br>
参考文献注释将观点与页码联系起来，便于选择性阅读。它们为神经联想记忆提供了条件。</p>
</li>
<li>
<p>Reading differently with an Antinet - faster, more selective. Still read slowly for foundational books.<br>
使用 Antinet 阅读方式不同--速度更快，选择性更强。对于基础书籍，阅读速度仍然较慢。</p>
</li>
<li>
<p>Syntopical reading: Reading multiple books on one topic together.<br>
综合阅读：同时阅读多个主题的书籍。</p>
</li>
<li>
<p>Good extraction focuses only on irresistible ideas aligned to your goals.<br>
好的提取只关注与你的目标相一致的不可抗拒的想法。</p>
</li>
</ul>
<h2 id="chapter-fifteen-第十五章">CHAPTER FIFTEEN 第十五章</h2>
<h2 id="creation-创建">CREATION 创建</h2>
<p>Here is a summary of the key points about note creation from the chapter:<br>
以下是本章有关创建注释的要点摘要：</p>
<ul>
<li>
<p>Notes are thought containers that capture ideas and develop thinking over time.<br>
笔记是思想的容器，可以捕捉想法，并随着时间的推移发展思维。</p>
</li>
<li>
<p>The four main types of notes are:<br>
纸币主要有四种类型：</p>
</li>
</ul>
<ol>
<li>
<p>Observation notes - brief notes made while reading sources<br>
观察笔记--阅读资料时所作的简要笔记</p>
</li>
<li>
<p>Excerpt notes - direct quotes copied from sources<br>
摘录说明--直接引自资料来源</p>
</li>
<li>
<p>Reformulation notes - summarizing ideas in your own words<br>
改写笔记--用自己的话概括观点</p>
</li>
<li>
<p>Reflection notes - applying meaning and relating ideas to projects<br>
反思笔记--应用意义并将想法与项目联系起来</p>
</li>
</ol>
<ul>
<li>
<p>Note creation is a means to an end, not the end goal itself. Focus on the process, not perfection.<br>
音符创作是达到目的的手段，而不是最终目标本身。注重过程，而非完美。</p>
</li>
<li>
<p>Review your Antinet before writing a note to avoid duplicates. Not every idea needs a main note.<br>
在撰写注释之前，先查看一下您的 Antinet，以避免重复。并非每个想法都需要主注释。</p>
</li>
<li>
<p>When possible, write reflections as if teaching an audience to gain deeper understanding.<br>
在可能的情况下，写反思时要像教听众一样，以加深理解。</p>
</li>
<li>
<p>Reformulations aim for comprehension, reflections aim for understanding by relating ideas to experience.<br>
重述的目的是理解，反思的目的是通过将观点与经验联系起来来理解。</p>
</li>
<li>
<p>Other notes include collectives (links or references grouped by topic), hoplinks (brief cross-references), and keyterm indexcards.<br>
其他注释包括集合（按主题分组的链接或参考文献）、跳转链接（简短的交叉引用）和关键词索引卡。</p>
</li>
<li>
<p>Add your own flair and creativity. No one style is best. Focus on starting and building your notes over time.<br>
加入自己的风格和创意。没有一种风格是最好的。集中精力开始并逐步建立自己的笔记。</p>
</li>
</ul>
<h2 id="chapter-sixteen-第十六章">CHAPTER SIXTEEN 第十六章</h2>
<h2 id="installation-安装">INSTALLATION 安装</h2>
<p>Here is a summary of the key points about installing notes from the chapter:<br>
以下是本章关于安装笔记的要点总结：</p>
<ul>
<li>
<p>Installation refers to determining where to place a new note in your Antinet system.<br>
安装是指确定新音符在 Antinet 系统中的位置。</p>
</li>
<li>
<p>Review your Antinet before writing a new note to find the best place to install it. This prevents duplicates and allows you to build on previous thinking.<br>
在撰写新注释之前，先查看您的 Antinet，以找到最佳安装位置。这样做可以防止重复，并让您在以前的基础上更上一层楼。</p>
</li>
<li>
<p>Install notes under or behind the most similar existing note or branch. Use your index to find related keyterms and cardlinks.<br>
在最相似的现有注释或分支下或后面安装注释。使用索引查找相关的关键词和卡片链接。</p>
</li>
<li>
<p>If a topic doesn't exist yet, create a new stem or branch for it. Add an index entry pointing to the new section.<br>
如果主题还不存在，则为其创建一个新的主干或分支。添加指向新章节的索引条目。</p>
</li>
<li>
<p>Don't overdo indexing, especially early on. Only add keyterms when needed to find a note again. Index fatigue is real.<br>
不要过度编制索引，尤其是在初期。只有在需要再次查找注释时才添加关键词。索引疲劳是真实存在的。</p>
</li>
<li>
<p>The name of the game is similarity. Install notes among their most similar neighbors in your Antinet's tree structure.<br>
游戏的关键在于相似性。在 Antinet 的树形结构中，将音符安装在最相似的邻居中。</p>
</li>
<li>
<p>Following the creation guidelines makes installation smooth. Determine placement first, then write the note to match that context.<br>
遵循创建指南可使安装工作顺利进行。首先确定位置，然后根据背景编写注释。</p>
</li>
<li>
<p>Keeping installation simple allows you to focus energy on writing great notes. Don't let organization become a burden.<br>
保持安装简单，可以让你集中精力写好笔记。不要让组织工作成为负担。</p>
</li>
</ul>
<h1 id="part-4-the-nature-of-the-antinet">PART 4: THE NATURE OF THE ANTINET</h1>
<p>第 4 部分：反内阁的性质</p>
<h2 id="chapter-seventeen-第十七章">CHAPTER SEVENTEEN 第十七章</h2>
<h2 id="mindset-心态">MINDSET 心态</h2>
<p>Here is a summary of the key points about Antinet mindset and workflow from the chapter:<br>
以下是本章中有关 Antinet 思维方式和工作流程的要点摘要：</p>
<ul>
<li>There are three main working states:<br>
主要有三种工作状态：</li>
</ul>
<ol>
<li>
<p>Emergence - Exploratory research to discover new ideas<br>
新兴 - 探索性研究，发现新思路</p>
</li>
<li>
<p>Evolutionary - Find supporting info for emerged ideas<br>
进化论 - 为新出现的观点寻找支持信息</p>
</li>
<li>
<p>Producing - Creating output like writing using your notes<br>
制作 - 利用笔记创建输出，如写作</p>
</li>
</ol>
<ul>
<li>
<p>Work consistently each day, even if just 2 hours. Long-term consistency matters over intensity.<br>
每天坚持工作，哪怕只有 2 个小时。长期坚持比强度更重要。</p>
</li>
<li>
<p>Make your workspace analog to minimize digital distraction. Dedicate set time to deep focus.<br>
让你的工作空间成为模拟的，以尽量减少数字干扰。为深度专注留出固定时间。</p>
</li>
<li>
<p>Luhmann worked long hours daily, but viewed it as fun vacation-like work. Make using your Antinet an enjoyable experience.<br>
Luhmann 每天工作很长时间，但他认为这是像度假一样有趣的工作。让使用 Antinet 成为一种愉快的体验。</p>
</li>
<li>
<p>Be willing to put in effort upfront in creating notes and indexing. It gets easier over time. Focus on the long game.<br>
愿意在创建注释和索引方面付出前期努力。随着时间的推移会越来越容易。着眼长远。</p>
</li>
<li>
<p>Don't get bogged down importing old notes. Focus energy on developing new knowledge.<br>
不要陷入导入旧笔记的困境。集中精力开发新知识。</p>
</li>
<li>
<p>Adopt a contribution mindset, using your notes to create works for your audience. This fuels motivation.<br>
采用贡献的心态，利用笔记为受众创作作品。这会激发你的动力。</p>
</li>
<li>
<p>Trust the process and give it time. The benefits compound and emerge in their own way down the road.<br>
相信这个过程，给它时间。好处会不断累积，并以自己的方式显现出来。</p>
</li>
</ul>
<h2 id="chapter-eighteen-第十八章">CHAPTER EIGHTEEN 第十八章</h2>
<h2 id="communication-with-your-second-mind">COMMUNICATION WITH YOUR SECOND MIND</h2>
<p>与你的第二心灵沟通</p>
<p>Here is a summary of the key points about communication with the Antinet's second mind:<br>
以下是与安蒂内特第二心灵交流的要点摘要：</p>
<ul>
<li>
<p>The Antinet becomes a second mind, not just a second brain. It is an active thinking partner.<br>
Antinet 成为第二个头脑，而不仅仅是第二个大脑。它是一个积极的思维伙伴。</p>
</li>
<li>
<p>Communication emerges between you and your past self captured in the Antinet's notes. It's an intrapersonal dialogue.<br>
你与安蒂内特笔记中记录的过去的自己之间会产生交流。这是一种人与人之间的对话。</p>
</li>
<li>
<p>Communication, especially being surprised, helps the Antinet generate insights. Selective relations enable this.<br>
交流，尤其是惊喜，有助于 Antinet 产生洞察力。选择性关系可以实现这一点。</p>
</li>
<li>
<p>The Antinet develops its own unique personality through your handwriting, keywords, and structure.<br>
通过您的笔迹、关键词和结构，Antinet 会形成自己独特的个性。</p>
</li>
<li>
<p>It takes time to reach a threshold and transition into a second mind. But then you can collaborate with this metaphysical entity.<br>
达到一个临界点并过渡到第二心灵需要时间。但这样你就可以与这个形而上的实体合作了。</p>
</li>
<li>
<p>The constraints of analog notes promote under-communication, triggering your mind's internal dialogue.<br>
模拟笔记的限制会促进沟通不足，引发你的内心对话。</p>
</li>
<li>
<p>Viewing your thoughts makes the Antinet feel like a ghostly presence of your past self. It becomes an alter ego.<br>
查看自己的想法会让 Antinet 感觉像是自己过去的幽灵。它变成了另一个自我。</p>
</li>
<li>
<p>Trust in the emergence of this hard-to-describe phenomenon. With practice, the second mind develops its own antifragile nature.<br>
相信这种难以描述的现象的出现。通过练习，&quot;第二心灵 &quot;会发展出自己的反脆弱特性。</p>
</li>
<li>
<p>The second mind concept originated long before Luhmann, but his Antinet principles unlock its benefits.<br>
第二心灵的概念早在卢曼之前就已提出，但他的安蒂内原则释放了这一概念的优势。</p>
</li>
<li>
<p>In the end, it's about communicating with an expression of your own consciousness to think better.<br>
归根结底，这是与自己的意识表达进行交流，从而更好地思考。</p>
</li>
</ul>
<h2 id="chapter-nineteen-第十九章">CHAPTER NINETEEN 第十九章</h2>
<h2 id="human-memory-and-the-antinet">HUMAN MEMORY AND THE ANTINET</h2>
<p>人类记忆与反记忆</p>
<p>Here is a summary of the key points about human memory and the Antinet from the chapter:<br>
以下是本章中有关人类记忆和 Antinet 的要点摘要：</p>
<ul>
<li>
<p>The Antinet's structure mirrors how human memory works, not digital storage. Luhmann modeled it after memory science.<br>
Antinet 的结构反映了人类记忆的工作原理，而不是数字存储。卢曼以记忆科学为蓝本。</p>
</li>
<li>
<p>Notes are like neurons, cardlinks like neural connections. The Antinet forms a haptic neural network.<br>
音符就像神经元，卡片链接就像神经连接。Antinet 构成了一个触觉神经网络。</p>
</li>
<li>
<p>Context is critical - branches provide internal context for developing ideas. Context evolves based on content.<br>
情境至关重要--分支机构提供内部情境来发展创意。内涵根据内容不断演变。</p>
</li>
<li>
<p>Physical notes capture internal and external context better than digital. This transports your mind back in time.<br>
实物笔记比数字笔记更能捕捉内部和外部环境。这让你的思绪回到过去。</p>
</li>
<li>
<p>Positional coding - knowing a note's placement relies on spatial memory. This mimics the method of loci.<br>
位置编码--了解音符的位置依赖于空间记忆。这模仿了定位的方法。</p>
</li>
<li>
<p>Cardlinks enable associations like those in memory - local (stemlinks) and remote (remotelinks).<br>
卡片链接可实现类似内存中的关联--本地链接（stemlinks）和远程链接（remotelinks）。</p>
</li>
<li>
<p>The Antinet relies on distributed representations, not discrete storage locations. Thoughts connect.<br>
Antinet 依靠的是分布式表示法，而不是独立的存储位置。思维连接。</p>
</li>
<li>
<p>Noise and decay exist, just like in human memory. The system evolves organically over time.<br>
噪音和衰减是存在的，就像人类的记忆一样。随着时间的推移，系统会有机地演变。</p>
</li>
<li>
<p>The explicit design mirrors memory science. This enables the Antinet to become a second mind, exceeding digital tools.<br>
明确的设计反映了记忆科学。这使得 Antinet 成为超越数字工具的第二大脑。</p>
</li>
<li>
<p>Understanding these principles lets you appreciate the system's genius. But empirical testing is still key for full comprehension.<br>
了解了这些原理，你就能欣赏到这一系统的天才之处。但要完全理解，经验测试仍然是关键。</p>
</li>
</ul>
<h2 id="chapter-twenty-第二十章">CHAPTER TWENTY 第二十章</h2>
<h2 id="evolution-perception-perspective-and-ruminants">EVOLUTION, PERCEPTION, PERSPECTIVE AND RUMINANTS</h2>
<p>进化、认知、视角和反刍动物</p>
<p>Here is a summary of the key points about evolution, perception, perspective, and rumination from the chapter:<br>
以下是本章关于进化、感知、视角和反刍的要点总结：</p>
<ul>
<li>
<p>The Antinet's structure enables long-term evolution of ideas. You can see your mental history unfold over time.<br>
Antinet 的结构可以实现思想的长期演变。您可以看到自己的思想史随着时间的推移而不断发展。</p>
</li>
<li>
<p>Reviewing your Antinet helps avoid repeating what you already know. You also see your perspectives shift.<br>
回顾你的 Antinet 可以避免重复你已经知道的东西。您还会发现自己的视角发生了变化。</p>
</li>
<li>
<p>Simple ideas compound over time into complex, interconnected pathways of knowledge. This takes effort but pays off.<br>
随着时间的推移，简单的想法会复合成复杂、相互关联的知识路径。这需要付出努力，但会有回报。</p>
</li>
<li>
<p>Cards capture your perception (interpretation) and perspective (point of view) when created. This gets locked in time.<br>
卡片在制作时会捕捉您的感知（解释）和视角（观点）。这会被时间锁定。</p>
</li>
<li>
<p>Reviewing old cards creates an internal dialogue between past and present perceptions and perspectives.<br>
回顾旧卡可以在过去和现在的看法和观点之间建立内部对话。</p>
</li>
<li>
<p>The Antinet is like a ruminant - it lets you slowly digest and ferment ideas over time before developing them.<br>
Antinet 就像反刍动物，让你慢慢消化和发酵，然后再提出想法。</p>
</li>
<li>
<p>Reverberation of ideas leads to rumination when captured over the long term in an Antinet.<br>
在 Antinet 中长期捕捉到的思想回响会导致反刍。</p>
</li>
<li>
<p>Read analytically, digesting books deeply. The Antinet stores these insights to compound and collide over time.<br>
分析性阅读，深入消化书籍。Antinet 会将这些见解储存起来，随着时间的推移不断复合和碰撞。</p>
</li>
<li>
<p>Trust in the organic, antifragile evolution of your ideas over the long haul. The results will surprise you.<br>
相信你的想法会长期有机地、反脆弱地发展。结果会让你大吃一惊。</p>
</li>
</ul>
<h2 id="chapter-twenty-one-第二十一章">CHAPTER TWENTY-ONE 第二十一章</h2>
<h2 id="randomness-surprisesand-accidents">RANDOMNESS, SURPRISESAND ACCIDENTS</h2>
<p>随机、惊喜和意外</p>
<p>Here is a summary of the key points about randomness, surprises, and accidents from the chapter:<br>
以下是本章关于随机性、惊喜和意外的要点总结：</p>
<ul>
<li>
<p>Randomness, surprises, and accidents are features, not bugs, of the Antinet's organic structure.<br>
随机性、惊喜和意外是 Antinet 有机结构的特点，而不是缺陷。</p>
</li>
<li>
<p>The tree structure and hard-to-create cardlinks generate useful surprises - insights you didn't intentionally design.<br>
树形结构和难以创建的卡片链接会带来有用的惊喜--你并非有意设计的洞察力。</p>
</li>
<li>
<p>Heterogeneous relations between disparate ideas create bisociations and new understandings.<br>
不同思想之间的异质关系产生了二元对立和新的理解。</p>
</li>
<li>
<p>Proximity of ideas in branches can create holistic entities greater than their parts.<br>
各分支机构的理念相近，可以创造出大于其组成部分的整体实体。</p>
</li>
<li>
<p>Accidents emerge from shuffling physical cards and prowling the stacks, not just focused searching.<br>
在洗牌和徘徊牌堆的过程中会出现意外，而不仅仅是集中搜索。</p>
</li>
<li>
<p>Movement creates more possibilities for useful accidents versus just meditation alone.<br>
与单纯的冥想相比，运动为有用的意外创造了更多的可能性。</p>
</li>
<li>
<p>Adopt a playful, curious spirit like John Venn instead of rigid overwork. This unlocks breakthroughs.<br>
像约翰-文一样，以玩乐、好奇的精神代替刻板的过度工作。这样才能实现突破。</p>
</li>
<li>
<p>Trust in the randomness. Don't fear the mess in your Antinet. Embrace odd structures along the way.<br>
相信随机性。不要惧怕安提内特的混乱。拥抱一路上的奇特结构。</p>
</li>
<li>
<p>Surprises demonstrate the magic of communicating with your past self captured in the second mind.<br>
惊喜展示了与第二心灵中的过去的自己交流的魔力。</p>
</li>
<li>
<p>The story about John Venn emerged as its own surprise thanks to the Antinet. Fittingly, it underscores the power of randomness.<br>
由于 Antinet 的出现，关于约翰-文的故事成为了一个惊喜。恰如其分地强调了随机性的力量。</p>
</li>
</ul>
<h1 id="afterword-后记">AFTERWORD 后记</h1>
<h1 id="appendix-a-luhmannian-tree-structure-zettelkasten-i">APPENDIX A: LUHMANNIAN TREE STRUCTURE (ZETTELKASTEN I)</h1>
<p>附录 A：卢曼尼亚树结构（Zettelkasten I）</p>
<h1 id="appendix-b-luhmannian-tree-structure-zettelkasten-ii">APPENDIX B: LUHMANNIAN TREE STRUCTURE (ZETTELKASTEN II)</h1>
<p>附录 B：卢曼尼亚树结构（II 号聚落柜）</p>
<h1 id="appendix-c-digital-antinets">APPENDIX C: DIGITAL ANTINETS</h1>
<p>附录 C：数字安提网</p>
<h1 id="glossary-术语表">GLOSSARY 术语表</h1>
<h1 id="acknowledgments-致谢">ACKNOWLEDGMENTS 致谢</h1>
<h1 id="about-the-author-关于作者">ABOUT THE AUTHOR 关于作者</h1>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[ANTINET summary（Claude2）]]></title>
        <id>https://temberature.github.io/post/tYf0mPvCO/</id>
        <link href="https://temberature.github.io/post/tYf0mPvCO/">
        </link>
        <updated>2023-11-20T01:12:23.000Z</updated>
        <content type="html"><![CDATA[<p>Here is a high-level summary of the key points from the document:</p>
<p>The book is about an analog note-taking system called the &quot;Antinet&quot; which is inspired by Niklas Luhmann's Zettelkasten.</p>
<p>The Antinet has 4 key principles:</p>
<ul>
<li>Analog (handwritten notes on paper, not digital)</li>
<li>Numeric-Alpha addresses (unique IDs for each note)</li>
<li>Tree structure (notes form an evolving, organic tree of ideas)</li>
<li>Index (keyterms provide entry points into the notes)</li>
</ul>
<p>Together these principles enable deep thinking, linking of concepts, creativity, and evolution of knowledge over decades. The Antinet becomes a &quot;second mind&quot; that you communicate with.</p>
<p>The book covers the background of Niklas Luhmann and his views. It aims to clear up misconceptions about the Zettelkasten online. It provides practical guidance on building an Antinet from scratch.</p>
<p>There are 4 main phases of knowledge development:</p>
<ul>
<li>Selection (choosing sources and ideas)</li>
<li>Extraction (pulling out ideas while reading)</li>
<li>Creation (making different types of notes)</li>
<li>Installation (filing notes in the system)</li>
</ul>
<p>Key benefits highlighted include:</p>
<ul>
<li>Developing genius-level work</li>
<li>Enabling long-term projects spanning decades</li>
<li>Creating surprises and insights from linking ideas</li>
<li>Strengthening memory and mitigating cognitive biases</li>
</ul>
<p>The book argues the analog Antinet is far superior to digital notes for deep thinking and creativity. But it requires long-term effort and consistency to realize the benefits.</p>
<h1 id="authors-note">AUTHOR’S NOTE</h1>
<h1 id="preface-do-not-skip">PREFACE (DO NOT SKIP)</h1>
<p>Here is a summary of the key points from the document:</p>
<p>The Antinet is a knowledge development system created using notecards. It was evolved over time by many great thinkers, but is often attributed to Niklas Luhmann.</p>
<p>The Antinet has several meanings:</p>
<ul>
<li>
<p>It's a tongue-in-cheek reference to the over-reliance on digital tools for thinking and knowledge development. The author believes analog tools are better for deep, deliberate thinking.</p>
</li>
<li>
<p>It's an acronym that refers to the 4 principles of the system, which were used by Luhmann.</p>
</li>
<li>
<p>It's a reference to Antonin Sertillanges, a Catholic intellectual who used a similar system.</p>
</li>
</ul>
<p>The book aims to uncover the &quot;true magic&quot; of the analog Antinet/Zettelkasten system. It focuses on how it can turn you into a prolific researcher, reader and writer.</p>
<p>The book touches on the theoretical and practical aspects of the system, its history, and provides actionable techniques. It may need to be re-read at different stages as you build your own Antinet.</p>
<p>Key advice includes:</p>
<ul>
<li>Read Ch. 11 first to build a starter Antinet</li>
<li>Use the 2-step Luhmannian bibcard method to take notes while reading</li>
<li>Don't get bogged down by footnotes on a first read</li>
<li>Be prepared to actively apply the techniques</li>
</ul>
<p>The book aims to help committed learners create genius-level work using an analog system of pen, paper and notecards.</p>
<h1 id="part-i-the-story-behind-the-story">PART I: THE STORY BEHIND THE STORY</h1>
<h2 id="chapter-one">CHAPTER ONE</h2>
<h2 id="the-journey-that-led-me-to-publish-a-book-on-the-antinet">THE JOURNEY THAT LED ME TO PUBLISH A BOOK ON THE ANTINET</h2>
<p>Here is a summary of the key points from Chapter 1:</p>
<ul>
<li>
<p>The author had previously co-founded a successful cryptocurrency company but left due to disillusionment and burnout.</p>
</li>
<li>
<p>He spent time trying to figure out his next steps, reading books on his patio and taking notes ineffectively with a commonplace book.</p>
</li>
<li>
<p>He discovered the digital note-taking apps Foam and Obsidian and became enthused by their note-linking capabilities. However, this resulted in a messy over-linked network of digital notes.</p>
</li>
<li>
<p>He learned about the Zettelkasten system in the book &quot;How to Take Smart Notes&quot; by Sönke Ahrens. This described an analog paper-based note system used by Niklas Luhmann.</p>
</li>
<li>
<p>Intrigued, the author tried using a real analog Zettelkasten and found it transformed his note-taking and writing. His thoughts flowed much better compared to digital apps.</p>
</li>
<li>
<p>By studying Luhmann's archived Zettelkasten online, the author pieced together how the analog system worked in practice. He coined his version the &quot;Antinet&quot;.</p>
</li>
<li>
<p>The Antinet helped the author make progress on a project about marketing and cryptocurrency. However, he felt compelled to write this book to share the power of the analog system with others.</p>
</li>
<li>
<p>The author wants to help committed people create long-lasting work, even though focusing on the antiquated analog Zettelkasten seems absurd. He chose this path to genuinely help people rather than chase money.</p>
</li>
</ul>
<h2 id="chapter-two">CHAPTER TWO</h2>
<h2 id="the-who-and-why-of-the-antinet">THE WHO AND WHY OF THE ANTINET</h2>
<p>Here is a summary of the key points from Chapter 2:</p>
<ul>
<li>
<p>The author clarifies who should and should not bother reading this book about the Antinet system.</p>
</li>
<li>
<p>It is best suited for serious writers, researchers, academics, and lifelong learners who wish to develop deep knowledge and creative insights.</p>
</li>
<li>
<p>However, it requires a long-term time commitment of decades to fully realize the benefits. It is not for those with tight deadlines or limited time.</p>
</li>
<li>
<p>The Antinet excels at developing unconventional interactions between ideas that lead to creative insights and genius-level work. This emerges from its analog tree structure.</p>
</li>
<li>
<p>It shines for long-term multi-year projects and enabling knowledge to compound over decades. This cannot occur in siloed, categorized systems.</p>
</li>
<li>
<p>The Antinet reveals structured accidents - surprising connections that emerge through browsing nearby tree branches. This cannot be replicated digitally.</p>
</li>
<li>
<p>Niklas Luhmann created the Zettelkasten for a 30-year theory of everything project. However, his books were often poorly written and impenetrable due to his trollish nature.</p>
</li>
<li>
<p>The Antinet should not be expected to magically produce perfect writings without hard work. But it develops deeper ideas than other systems.</p>
</li>
<li>
<p>In summary, the Antinet is best for serious thinkers aiming to produce unconventional, creative and long-lasting work over decades, not those seeking easy solutions.</p>
</li>
</ul>
<h2 id="chapter-three">CHAPTER THREE</h2>
<h2 id="the-current-zettelkasten-landscape">THE CURRENT ZETTELKASTEN LANDSCAPE</h2>
<p>Here is a summary of the key points from Chapter 3:</p>
<ul>
<li>
<p>The current landscape of information on Zettelkasten online and in books is riddled with inaccuracies.</p>
</li>
<li>
<p>Popular sources like Wikipedia and zettelkasten.de get important aspects wrong, like describing it as hierarchical or advocating for digital notes.</p>
</li>
<li>
<p>Sönke Ahrens' book introduced concepts like fleeting notes and literature notes that are not part of Luhmann's original Zettelkasten.</p>
</li>
<li>
<p>A new wave of &quot;Ahrensians&quot; have created more layers of complexity and contradictions trying to adapt the system to digital tools.</p>
</li>
<li>
<p>For example, some advocates undermine Luhmann's numeric-alpha note IDs or promote digital search over analog serendipity.</p>
</li>
<li>
<p>The analog system's essence is lost in digital knockoffs. Luhmann saw it as a thinking tool and communication partner.</p>
</li>
<li>
<p>The author wants to share insights from studying Luhmann's archive to help committed learners avoid wasting time on inaccurate methods.</p>
</li>
<li>
<p>He cares about this niche group and wants to serve them, unlike his past work in cryptocurrency catering to speculators.</p>
</li>
<li>
<p>In summary, the current landscape spreads misconceptions about Zettelkasten, but the author aims to uncover its true analog nature.</p>
</li>
</ul>
<h2 id="chapter-four">CHAPTER FOUR</h2>
<h2 id="niklas-luhmann-the-man">NIKLAS LUHMANN, THE MAN</h2>
<p>Here is a summary of the key points about Niklas Luhmann from Chapter 4:</p>
<ul>
<li>
<p>Understanding Luhmann's background, theories, views, and personality provides context for the nature of the Antinet system he created.</p>
</li>
<li>
<p>Luhmann was born in 1927 in Germany. His passion was reading, thinking and writing. He created his Zettelkasten system to aid this.</p>
</li>
<li>
<p>He was not interested in drinking or socializing. He prioritized expanding his mind over advancing his early career.</p>
</li>
<li>
<p>His political views trended libertarian. He aimed to remain detached and avoid moralizing issues.</p>
</li>
<li>
<p>Core concepts in Luhmann's work were communication, systems theory, complexity, and autopoiesis.</p>
</li>
<li>
<p>He took an anti-humanist, anti-regionalist approach to sociology, applying biological concepts to social systems.</p>
</li>
<li>
<p>Luhmann had an ironic, absurdist, and carnivalesque attitude. He was a polite troll who provoked with his theories.</p>
</li>
<li>
<p>He was dedicated to his intellectual pursuits, desiring more time for reading, writing and thinking.</p>
</li>
<li>
<p>Luhmann produced an enormous volume of writing and books with the aid of his Zettelkasten system.</p>
</li>
<li>
<p>In summary, understanding Luhmann's unconventional mindset helps appreciate the nature of the Antinet system he devised.</p>
</li>
</ul>
<h1 id="part-2-the-antinet">PART 2: THE ANTINET</h1>
<h2 id="chapter-five">CHAPTER FIVE</h2>
<h2 id="what-is-an-antinet">WHAT IS AN ANTINET?</h2>
<p>Here is a summary of the key points from Chapter 5:</p>
<ul>
<li>
<p>The term &quot;Antinet&quot; refers to the four principles of Niklas Luhmann's Zettelkasten system: Analog, Numeric-alpha addresses, Tree structure, and Index.</p>
</li>
<li>
<p>Luhmann created his system to challenge simplistic views of good vs evil. A childhood experience of being abused by American soldiers showed him the world's complexity.</p>
</li>
<li>
<p>The Antinet functions like an adaptive optics system, transforming distorted thoughts into clear ideas. It exercises your neuro-associative recall ability.</p>
</li>
<li>
<p>An Antinet is not just analog storage. It's a thinking and thought development system that becomes a second mind over time.</p>
</li>
<li>
<p>The second mind emerges through neuroimprinting, internal dialogue, and communicating with your past self's handwriting. It has its own personality.</p>
</li>
<li>
<p>The four principles transform the raw notecards into a whole greater than the parts. This cannot be replicated digitally.</p>
</li>
<li>
<p>Antinets excel at developing unconventional insights, evolving ideas over decades, and revealing &quot;structured accidents.&quot;</p>
</li>
<li>
<p>An Antinet is not a memory aid, but a thinking system. It strengthens memory faculties and mitigates cognitive biases.</p>
</li>
<li>
<p>Simply linking digital notes misses the essence of Luhmann's system. His analog principles imprint thoughts and create dialogue.</p>
</li>
<li>
<p>In summary, &quot;Antinet&quot; refers to the unique analog system Luhmann devised to develop complex, deep knowledge over time.</p>
</li>
</ul>
<h2 id="chapter-six">CHAPTER SIX</h2>
<h2 id="analog">ANALOG</h2>
<p>Here is a summary of the key points from the chapter:</p>
<p>The Analog Pros and Cons</p>
<ul>
<li>Analog Pros:</li>
</ul>
<ol>
<li>Creates a better communication partner than digital</li>
<li>Captures one's consciousness and past self better</li>
<li>Transforms the Zettelkasten into a thinking tool for short and long-term development</li>
<li>Forces unlimited combinations of thought due to notecards' limited space</li>
<li>Prevents hyper-selection of irrelevant material while reading</li>
<li>Enables better familiarity with knowledge through constant review</li>
<li>Exposes mistakes and self-deceptions effectively</li>
</ol>
<ul>
<li>Analog Cons:</li>
</ul>
<ol>
<li>Risk of destruction from fire, flood, etc.</li>
<li>Harder than digital in terms of effort required</li>
<li>Less mobile than digital</li>
</ol>
<p>Comparison to Digital</p>
<ul>
<li>Digital can aid in productivity but lacks the communication component of analog</li>
<li>Digital is more distracting and leads to less happiness and poorer health outcomes</li>
<li>Luhmann likely would have stuck with analog even if he had access to digital tools</li>
</ul>
<p>The Power of Writing by Hand</p>
<ul>
<li>Writing by hand disentangles thoughts, enhances memory and neuro-associative recall, improves learning, and leads to better mood</li>
<li>Both scientific research and biblical verses support the power of writing by hand over typing</li>
<li>Many great thinkers and writers use analog tools and write by hand</li>
</ul>
<p>Overall, the chapter covers the benefits and drawbacks of analog Zettelkasten systems compared to digital. It makes a strong case for the power of writing by hand and using physical note cards to develop deep thinking and creativity.</p>
<h2 id="chapter-seven">CHAPTER SEVEN</h2>
<h2 id="numeric-alpha">NUMERIC-ALPHA</h2>
<p>Here is a summary of the key points from the chapter:</p>
<p>Numeric-Alpha Addresses</p>
<ul>
<li>
<p>Numeric-alpha addresses are a critical component of the Antinet system. They give each note a unique identifier and location.</p>
</li>
<li>
<p>The addresses provide structure and order, allowing notes to be easily linked and retrieved.</p>
</li>
<li>
<p>Numeric-alpha addresses have a long history, used in systems dating back to the 1700s. Luhmann likely adapted them from his work in the legal system.</p>
</li>
<li>
<p>The addresses make the Antinet self-referential, allowing it to function as a communication partner.</p>
</li>
<li>
<p>In memory science, numeric-alpha addresses resemble auto-associative networks in the brain.</p>
</li>
</ul>
<p>Links</p>
<ul>
<li>
<p>There are two main types of links: internal (within the Antinet) and external (to outside sources).</p>
</li>
<li>
<p>Internal links include stemlinks, branchlinks, remotelinks, and keyterm links. They connect related ideas.</p>
</li>
<li>
<p>External links reference outside sources like books, articles, videos, etc.</p>
</li>
<li>
<p>Links enable associations, which are critical for learning and insight. The Antinet's structure mirrorsassociative networks in memory.</p>
</li>
<li>
<p>Digital tools don't optimize associations like the Antinet does through numeric-alpha addresses.</p>
</li>
</ul>
<p>In summary, this chapter covered the importance of the Antinet's numeric-alpha address structure and linking system. Together they enable enhanced learning, creativity, and communication compared to digital notes.</p>
<h2 id="chapter-eight">CHAPTER EIGHT</h2>
<h2 id="tree">TREE</h2>
<p>Here is a summary of the key points from the chapter:</p>
<p>Tree Structure of the Antinet</p>
<ul>
<li>
<p>The structure of the Antinet is best represented as a tree, with branches, stems, leaves, and vines.</p>
</li>
<li>
<p>This tree structure allows for internal branching and evolution of thoughts over time.</p>
</li>
<li>
<p>It provides order while still embracing some chaos and roughness.</p>
</li>
<li>
<p>Notes are positioned based on location, not rank. There is no hierarchy.</p>
</li>
<li>
<p>The structure mirrors associative networks in human memory.</p>
</li>
<li>
<p>It enables reverberation of linked concepts and surprising discoveries.</p>
</li>
</ul>
<p>Classification Systems</p>
<ul>
<li>
<p>Different classification systems can provide starting branches, like Luhmann's or academic disciplines.</p>
</li>
<li>
<p>But fuzzy categories and internal growth are more important than rigid taxonomy.</p>
</li>
<li>
<p>The index supplements classification limitations. The structure evolves based on use.</p>
</li>
</ul>
<p>Metaphysics of Trees</p>
<ul>
<li>
<p>Trees play a central role in myths, stories, and belief systems throughout history.</p>
</li>
<li>
<p>They represent life, knowledge, enlightenment, and the creative force.</p>
</li>
<li>
<p>Understanding the metaphysics reinforces the power of tree structures for knowledge.</p>
</li>
</ul>
<p>In summary, this chapter covered the Antinet's rough tree structure, classification systems, and the metaphysical symbolism of trees. Together they provide a framework optimized for evolving thoughts and insights.</p>
<h2 id="chapter-nine">CHAPTER NINE</h2>
<h2 id="index">INDEX</h2>
<p>Here is a summary of the key points from the chapter:</p>
<p>The Index</p>
<ul>
<li>
<p>The index is a critical component for navigating the Antinet. It serves as a second map.</p>
</li>
<li>
<p>It contains keyterms that act as cues to access areas of knowledge.</p>
</li>
<li>
<p>Keyterms point to locations in the Antinet via numeric-alpha addresses.</p>
</li>
<li>
<p>There are two types of index cards: list cards and dedicated keyterm cards.</p>
</li>
<li>
<p>The index provides flexible access without rigid taxonomy limitations.</p>
</li>
<li>
<p>It enables cued recall and neuro-associative processing.</p>
</li>
</ul>
<p>Against Digital Search</p>
<ul>
<li>
<p>Search is actually a bug, not an inherently desirable feature.</p>
</li>
<li>
<p>Digital search yields too many low relevance results, creating noise.</p>
</li>
<li>
<p>It eliminates the structured exploration of associations and serendipity.</p>
</li>
<li>
<p>Search prevents maintenance rehearsal learning and evolving unique structures.</p>
</li>
<li>
<p>It fails to improve mood and cognition like associative processing does.</p>
</li>
</ul>
<p>In summary, the index transforms the Antinet into an explorable knowledge network. Avoiding digital search forces more valuable practices for developing insights.</p>
<h2 id="chapter-ten">CHAPTER TEN</h2>
<h2 id="network">NETWORK</h2>
<p>Here is a summary of the key points from the chapter:</p>
<p>The Antinet as a Cybernetic Network</p>
<ul>
<li>
<p>The Antinet is a cybernetic system, aimed at communication and control through feedback.</p>
</li>
<li>
<p>Cybernetics involves achieving a goal by steering in the right direction.</p>
</li>
<li>
<p>The Antinet's network structure resembles associationism and neural networks.</p>
</li>
<li>
<p>Associations are built on contiguity (continuous flow of thought) and similarity.</p>
</li>
<li>
<p>Numeric-alpha addresses create a self-referential, closed loop system.</p>
</li>
<li>
<p>This closure enables feedback signals when searching for ideas.</p>
</li>
<li>
<p>Feedback prompts course-correction and new insights along the way.</p>
</li>
<li>
<p>Digital notes lack the rich feedback loops of the Antinet's cybernetic network.</p>
</li>
</ul>
<p>In summary, this chapter explains how the Antinet functions as a cybernetic system optimized for communication between past and present thoughts. The network structure reinforced by numeric addresses generates valuable feedback and insights. This cybernetic nature is a key advantage over digital notes.</p>
<h2 id="chapter-eleven">CHAPTER ELEVEN</h2>
<h2 id="the-hitchhikers-guide-to-the-antinet">THE HITCHHIKER’S GUIDE TO THE ANTINET</h2>
<p>Here is a summary of the key points from the chapter:</p>
<p>Obstacles and Mindset</p>
<ul>
<li>
<p>Avoid perfectionism - the system evolves over time. Mistakes and imperfections have value.</p>
</li>
<li>
<p>Have faith in the power of analog tools for thinking. Don't get distracted by digital myths.</p>
</li>
<li>
<p>Adopt a growth vs contribution mindset. Strive to create work to teach others.</p>
</li>
<li>
<p>Have some goal or focus area in mind before starting.</p>
</li>
</ul>
<p>Building the Antinet</p>
<ul>
<li>
<p>The core components are the main box, index box, and bib box.</p>
</li>
<li>
<p>Main box stores developed thoughts, index provides entry points.</p>
</li>
<li>
<p>Academic disciplines provide a robust classification system.</p>
</li>
<li>
<p>Numeric-alpha addresses identify note locations.</p>
</li>
<li>
<p>Index keyterms serve as cues to find ideas.</p>
</li>
<li>
<p>Add sources to notes via ExRefs.</p>
</li>
<li>
<p>It's simple but requires deliberate effort over time.</p>
</li>
</ul>
<p>In summary, this chapter provided guidance on the mindset and practical steps for building an Antinet from scratch. With the foundation established, one can now begin developing knowledge through reading and note-taking.</p>
<h1 id="part-3-knowledge-development">PART 3: KNOWLEDGE DEVELOPMENT</h1>
<h2 id="chapter-twelve">CHAPTER TWELVE</h2>
<h2 id="knowledge-development">KNOWLEDGE DEVELOPMENT</h2>
<p>Here is a summary of the key points from the chapter:</p>
<ul>
<li>
<p>Knowledge development involves evolving thoughts and thinking over time.</p>
</li>
<li>
<p>The DIKW pyramid defines data, information, knowledge, and wisdom.</p>
</li>
<li>
<p>Knowledge = meaningful, structured information that can be taught.</p>
</li>
<li>
<p>Analog tools develop knowledge better than digital tools.</p>
</li>
<li>
<p>Knowledge development has 4 main phases:</p>
</li>
</ul>
<ol>
<li>
<p>Selection - Choose irresistible information from sources.</p>
</li>
<li>
<p>Extraction - Write down selections from reading/listening.</p>
</li>
<li>
<p>Creation - Make notes: excerpts, reformulations, reflections.</p>
</li>
<li>
<p>Installation - File notes and index key ideas.</p>
</li>
</ol>
<ul>
<li>
<p>Knowledge development simplifies complexity (sources), extracts meaning, and builds new complexity (in notes).</p>
</li>
<li>
<p>The goal is creating shareable knowledge, not just collecting information.</p>
</li>
</ul>
<p>In summary, this chapter explains the nature of knowledge and how the Antinet develops it through deliberate reading, note-taking, and evolution of ideas over time. This process transforms information into meaningful, structured knowledge.</p>
<h2 id="chapter-thirteen">CHAPTER THIRTEEN</h2>
<h2 id="selection">SELECTION</h2>
<p>Here is a summary of the key points from the chapter:</p>
<ul>
<li>
<p>Selection is critical when working with an Antinet. It involves selecting what sources to read, what ideas to extract, and where to link ideas in your Antinet.</p>
</li>
<li>
<p>Selection underlies communication. Luhmann viewed communication as founded on three selections: selection of information, selection of message, and selective interpretation.</p>
</li>
<li>
<p>Knowledge selection is like natural selection. You select &quot;mate&quot; sources and extract &quot;genetic&quot; ideas from them to create new knowledge. The knowledge best adapted to your environment (audience) will spread.</p>
</li>
<li>
<p>There are three levels of selection: source selection, link selection, and material selection. Be selective in what you read, what you link cards to, and what ideas you extract.</p>
</li>
<li>
<p>Avoid overselection. Digital tools make it too easy to capture too much. Analog forces you to be selective. Hard links are superior to hyperlinks.</p>
</li>
<li>
<p>For material selection, focus only on irresistible ideas - the most important and applicable ideas to you. Ignore bad, good, even excellent ideas.</p>
</li>
<li>
<p>Priming before reading involves previewing the source and setting a reading goal. This focuses your selection.</p>
</li>
<li>
<p>Developing good selection skills requires practice and feedback. Publishing your work provides feedback on your selection abilities.</p>
</li>
</ul>
<h2 id="chapter-fourteen">CHAPTER FOURTEEN</h2>
<h2 id="extraction">EXTRACTION</h2>
<p>Here is a summary of the key points about extraction from the chapter:</p>
<ul>
<li>
<p>Extraction involves pulling out and marking material to make into notes. There are intentional vs exploratory strategies.</p>
</li>
<li>
<p>Extraction methods include:</p>
</li>
</ul>
<ol>
<li>
<p>1-Step Book-to-Maincard: Stop reading to make a note on a card. Good for unfamiliar/complex books.</p>
</li>
<li>
<p>2-Step Marginalia: Mark passages in books, then extract later. Risks overselection.</p>
</li>
<li>
<p>Other Methods: Highlighting, headings, summaries. Help comprehension.</p>
</li>
</ol>
<ul>
<li>
<p>The 2-Step Luhmannian Bibcard Method is best:</p>
</li>
<li>
<p>Front of bibcard has source details, reading goal, overview.</p>
</li>
<li>
<p>Back has bibnotes - brief notes/keyterms from reading.</p>
</li>
<li>
<p>Later convert bibnotes into maincards or ExRefs.</p>
</li>
<li>
<p>Bibnotes link ideas to page numbers for selective reading. They prime neuro-associative recall.</p>
</li>
<li>
<p>Reading differently with an Antinet - faster, more selective. Still read slowly for foundational books.</p>
</li>
<li>
<p>Syntopical reading: Reading multiple books on one topic together.</p>
</li>
<li>
<p>Good extraction focuses only on irresistible ideas aligned to your goals.</p>
</li>
</ul>
<h2 id="chapter-fifteen">CHAPTER FIFTEEN</h2>
<h2 id="creation">CREATION</h2>
<p>Here is a summary of the key points about note creation from the chapter:</p>
<ul>
<li>
<p>Notes are thought containers that capture ideas and develop thinking over time.</p>
</li>
<li>
<p>The four main types of notes are:</p>
</li>
</ul>
<ol>
<li>
<p>Observation notes - brief notes made while reading sources</p>
</li>
<li>
<p>Excerpt notes - direct quotes copied from sources</p>
</li>
<li>
<p>Reformulation notes - summarizing ideas in your own words</p>
</li>
<li>
<p>Reflection notes - applying meaning and relating ideas to projects</p>
</li>
</ol>
<ul>
<li>
<p>Note creation is a means to an end, not the end goal itself. Focus on the process, not perfection.</p>
</li>
<li>
<p>Review your Antinet before writing a note to avoid duplicates. Not every idea needs a main note.</p>
</li>
<li>
<p>When possible, write reflections as if teaching an audience to gain deeper understanding.</p>
</li>
<li>
<p>Reformulations aim for comprehension, reflections aim for understanding by relating ideas to experience.</p>
</li>
<li>
<p>Other notes include collectives (links or references grouped by topic), hoplinks (brief cross-references), and keyterm indexcards.</p>
</li>
<li>
<p>Add your own flair and creativity. No one style is best. Focus on starting and building your notes over time.</p>
</li>
</ul>
<h2 id="chapter-sixteen">CHAPTER SIXTEEN</h2>
<h2 id="installation">INSTALLATION</h2>
<p>Here is a summary of the key points about installing notes from the chapter:</p>
<ul>
<li>
<p>Installation refers to determining where to place a new note in your Antinet system.</p>
</li>
<li>
<p>Review your Antinet before writing a new note to find the best place to install it. This prevents duplicates and allows you to build on previous thinking.</p>
</li>
<li>
<p>Install notes under or behind the most similar existing note or branch. Use your index to find related keyterms and cardlinks.</p>
</li>
<li>
<p>If a topic doesn't exist yet, create a new stem or branch for it. Add an index entry pointing to the new section.</p>
</li>
<li>
<p>Don't overdo indexing, especially early on. Only add keyterms when needed to find a note again. Index fatigue is real.</p>
</li>
<li>
<p>The name of the game is similarity. Install notes among their most similar neighbors in your Antinet's tree structure.</p>
</li>
<li>
<p>Following the creation guidelines makes installation smooth. Determine placement first, then write the note to match that context.</p>
</li>
<li>
<p>Keeping installation simple allows you to focus energy on writing great notes. Don't let organization become a burden.</p>
</li>
</ul>
<h1 id="part-4-the-nature-of-the-antinet">PART 4: THE NATURE OF THE ANTINET</h1>
<h2 id="chapter-seventeen">CHAPTER SEVENTEEN</h2>
<h2 id="mindset">MINDSET</h2>
<p>Here is a summary of the key points about Antinet mindset and workflow from the chapter:</p>
<ul>
<li>There are three main working states:</li>
</ul>
<ol>
<li>
<p>Emergence - Exploratory research to discover new ideas</p>
</li>
<li>
<p>Evolutionary - Find supporting info for emerged ideas</p>
</li>
<li>
<p>Producing - Creating output like writing using your notes</p>
</li>
</ol>
<ul>
<li>
<p>Work consistently each day, even if just 2 hours. Long-term consistency matters over intensity.</p>
</li>
<li>
<p>Make your workspace analog to minimize digital distraction. Dedicate set time to deep focus.</p>
</li>
<li>
<p>Luhmann worked long hours daily, but viewed it as fun vacation-like work. Make using your Antinet an enjoyable experience.</p>
</li>
<li>
<p>Be willing to put in effort upfront in creating notes and indexing. It gets easier over time. Focus on the long game.</p>
</li>
<li>
<p>Don't get bogged down importing old notes. Focus energy on developing new knowledge.</p>
</li>
<li>
<p>Adopt a contribution mindset, using your notes to create works for your audience. This fuels motivation.</p>
</li>
<li>
<p>Trust the process and give it time. The benefits compound and emerge in their own way down the road.</p>
</li>
</ul>
<h2 id="chapter-eighteen">CHAPTER EIGHTEEN</h2>
<h2 id="communication-with-your-second-mind">COMMUNICATION WITH YOUR SECOND MIND</h2>
<p>Here is a summary of the key points about communication with the Antinet's second mind:</p>
<ul>
<li>
<p>The Antinet becomes a second mind, not just a second brain. It is an active thinking partner.</p>
</li>
<li>
<p>Communication emerges between you and your past self captured in the Antinet's notes. It's an intrapersonal dialogue.</p>
</li>
<li>
<p>Communication, especially being surprised, helps the Antinet generate insights. Selective relations enable this.</p>
</li>
<li>
<p>The Antinet develops its own unique personality through your handwriting, keywords, and structure.</p>
</li>
<li>
<p>It takes time to reach a threshold and transition into a second mind. But then you can collaborate with this metaphysical entity.</p>
</li>
<li>
<p>The constraints of analog notes promote under-communication, triggering your mind's internal dialogue.</p>
</li>
<li>
<p>Viewing your thoughts makes the Antinet feel like a ghostly presence of your past self. It becomes an alter ego.</p>
</li>
<li>
<p>Trust in the emergence of this hard-to-describe phenomenon. With practice, the second mind develops its own antifragile nature.</p>
</li>
<li>
<p>The second mind concept originated long before Luhmann, but his Antinet principles unlock its benefits.</p>
</li>
<li>
<p>In the end, it's about communicating with an expression of your own consciousness to think better.</p>
</li>
</ul>
<h2 id="chapter-nineteen">CHAPTER NINETEEN</h2>
<h2 id="human-memory-and-the-antinet">HUMAN MEMORY AND THE ANTINET</h2>
<p>Here is a summary of the key points about human memory and the Antinet from the chapter:</p>
<ul>
<li>
<p>The Antinet's structure mirrors how human memory works, not digital storage. Luhmann modeled it after memory science.</p>
</li>
<li>
<p>Notes are like neurons, cardlinks like neural connections. The Antinet forms a haptic neural network.</p>
</li>
<li>
<p>Context is critical - branches provide internal context for developing ideas. Context evolves based on content.</p>
</li>
<li>
<p>Physical notes capture internal and external context better than digital. This transports your mind back in time.</p>
</li>
<li>
<p>Positional coding - knowing a note's placement relies on spatial memory. This mimics the method of loci.</p>
</li>
<li>
<p>Cardlinks enable associations like those in memory - local (stemlinks) and remote (remotelinks).</p>
</li>
<li>
<p>The Antinet relies on distributed representations, not discrete storage locations. Thoughts connect.</p>
</li>
<li>
<p>Noise and decay exist, just like in human memory. The system evolves organically over time.</p>
</li>
<li>
<p>The explicit design mirrors memory science. This enables the Antinet to become a second mind, exceeding digital tools.</p>
</li>
<li>
<p>Understanding these principles lets you appreciate the system's genius. But empirical testing is still key for full comprehension.</p>
</li>
</ul>
<h2 id="chapter-twenty">CHAPTER TWENTY</h2>
<h2 id="evolution-perception-perspective-and-ruminants">EVOLUTION, PERCEPTION, PERSPECTIVE AND RUMINANTS</h2>
<p>Here is a summary of the key points about evolution, perception, perspective, and rumination from the chapter:</p>
<ul>
<li>
<p>The Antinet's structure enables long-term evolution of ideas. You can see your mental history unfold over time.</p>
</li>
<li>
<p>Reviewing your Antinet helps avoid repeating what you already know. You also see your perspectives shift.</p>
</li>
<li>
<p>Simple ideas compound over time into complex, interconnected pathways of knowledge. This takes effort but pays off.</p>
</li>
<li>
<p>Cards capture your perception (interpretation) and perspective (point of view) when created. This gets locked in time.</p>
</li>
<li>
<p>Reviewing old cards creates an internal dialogue between past and present perceptions and perspectives.</p>
</li>
<li>
<p>The Antinet is like a ruminant - it lets you slowly digest and ferment ideas over time before developing them.</p>
</li>
<li>
<p>Reverberation of ideas leads to rumination when captured over the long term in an Antinet.</p>
</li>
<li>
<p>Read analytically, digesting books deeply. The Antinet stores these insights to compound and collide over time.</p>
</li>
<li>
<p>Trust in the organic, antifragile evolution of your ideas over the long haul. The results will surprise you.</p>
</li>
</ul>
<h2 id="chapter-twenty-one">CHAPTER TWENTY-ONE</h2>
<h2 id="randomness-surprisesand-accidents">RANDOMNESS, SURPRISESAND ACCIDENTS</h2>
<p>Here is a summary of the key points about randomness, surprises, and accidents from the chapter:</p>
<ul>
<li>
<p>Randomness, surprises, and accidents are features, not bugs, of the Antinet's organic structure.</p>
</li>
<li>
<p>The tree structure and hard-to-create cardlinks generate useful surprises - insights you didn't intentionally design.</p>
</li>
<li>
<p>Heterogeneous relations between disparate ideas create bisociations and new understandings.</p>
</li>
<li>
<p>Proximity of ideas in branches can create holistic entities greater than their parts.</p>
</li>
<li>
<p>Accidents emerge from shuffling physical cards and prowling the stacks, not just focused searching.</p>
</li>
<li>
<p>Movement creates more possibilities for useful accidents versus just meditation alone.</p>
</li>
<li>
<p>Adopt a playful, curious spirit like John Venn instead of rigid overwork. This unlocks breakthroughs.</p>
</li>
<li>
<p>Trust in the randomness. Don't fear the mess in your Antinet. Embrace odd structures along the way.</p>
</li>
<li>
<p>Surprises demonstrate the magic of communicating with your past self captured in the second mind.</p>
</li>
<li>
<p>The story about John Venn emerged as its own surprise thanks to the Antinet. Fittingly, it underscores the power of randomness.</p>
</li>
</ul>
<h1 id="afterword">AFTERWORD</h1>
<h1 id="appendix-a-luhmannian-tree-structure-zettelkasten-i">APPENDIX A: LUHMANNIAN TREE STRUCTURE (ZETTELKASTEN I)</h1>
<h1 id="appendix-b-luhmannian-tree-structure-zettelkasten-ii">APPENDIX B: LUHMANNIAN TREE STRUCTURE (ZETTELKASTEN II)</h1>
<h1 id="appendix-c-digital-antinets">APPENDIX C: DIGITAL ANTINETS</h1>
<h1 id="glossary">GLOSSARY</h1>
<h1 id="acknowledgments">ACKNOWLEDGMENTS</h1>
<h1 id="about-the-author">ABOUT THE AUTHOR</h1>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[沉浸式翻译]]></title>
        <id>https://temberature.github.io/post/Sk9lhoklb/</id>
        <link href="https://temberature.github.io/post/Sk9lhoklb/">
        </link>
        <updated>2023-11-17T15:08:24.000Z</updated>
        <content type="html"><![CDATA[<p>沉浸式翻译是一种浏览器插件,可以实现网页和文档的双语对照翻译。它的主要特点包括:</p>
<ol>
<li>
<p>智能识别网页主要内容区域进行翻译,实现沉浸式阅读体验。不会翻译无关内容,让翻译更聚焦主题。</p>
</li>
<li>
<p>支持多种主流网站的优化翻译,如Google、Twitter等,针对这些网站进行了深度定制。</p>
</li>
<li>
<p>支持鼠标悬停实时翻译。将鼠标悬停在段落上,可以立即看到翻译。这种交互方式更便捷。</p>
</li>
<li>
<p>不仅支持网页翻译,还支持PDF、EPUB电子书、字幕文件、TXT文本等多种文档格式的翻译。</p>
</li>
<li>
<p>支持多种翻译引擎,如谷歌、微软、DeepL等,用户可以自由选择。</p>
</li>
<li>
<p>支持多平台,可在PC、手机等设备上使用,体验一致。</p>
</li>
<li>
<p>翻译质量较好,可以明显提高阅读外文网站、电子书等的效率。</p>
</li>
<li>
<p>使用免费,大大降低了外语学习的门槛。</p>
</li>
</ol>
<p>总体来说,沉浸式翻译以其独特的交互方式和多文档支持,为用户提供了更好的双语阅读体验,是一款值得推荐的翻译工具。</p>
<p>Citations:<br>
[1] https://immersivetranslate.com<br>
[2] https://chrome.google.com/webstore/detail/immersive-translate-web-p/bpoadfkcbjbfhfodiogcnhhhpibjhbnh?hl=zh-CN<br>
[3] https://github.com/immersive-translate/immersive-translate<br>
[4] https://apps.apple.com/cn/app/%E6%B2%89%E6%B5%B8%E5%BC%8F%E7%BF%BB%E8%AF%91/id6447957425</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[screen studio]]></title>
        <id>https://temberature.github.io/post/zptut3FZG/</id>
        <link href="https://temberature.github.io/post/zptut3FZG/">
        </link>
        <updated>2023-11-17T14:59:13.000Z</updated>
        <content type="html"><![CDATA[<p>Here is a comprehensive response to your question about screen studio software:</p>
<h2 id="overview-of-screen-studio">Overview of Screen Studio</h2>
<p>Screen Studio is a screen recording and video editing software designed specifically for Mac. It aims to help users create high-quality, professional-looking screen recordings with minimal effort.</p>
<p>Some of the key features of Screen Studio include:</p>
<ul>
<li>Automatic zooming and smooth cursor movement to highlight clicks and interactions</li>
<li>Cinematic motion blur added to animations</li>
<li>Ability to record full screen, specific windows, or iOS devices</li>
<li>Webcam and microphone recording</li>
<li>Intuitive video editing capabilities</li>
<li>Export videos in resolutions up to 4K</li>
</ul>
<h2 id="underlying-technology">Underlying Technology</h2>
<p>Screen Studio is built using the following core technologies:</p>
<ul>
<li>Framework: Electron - Allows building cross-platform desktop apps using web technologies</li>
<li>Programming Language: JavaScript/TypeScript - Used to code the backend logic and interactions</li>
<li>UI Library: React - Enables building modular UI components to create the frontend</li>
<li>Video Engine: FFmpeg - Handles screen recording and video processing/editing capabilities</li>
<li>Graphics: Canvas/WebGL - For rendering animations and effects like motion blur</li>
</ul>
<p>Additionally, Screen Studio utilizes other open source libraries like WebCodecs for hardware-accelerated video encoding and OpenCV for handling computer vision tasks.</p>
<h2 id="key-capabilities-and-features">Key Capabilities and Features</h2>
<p>Here are some of the standout features and capabilities of Screen Studio:</p>
<ul>
<li>
<p><strong>Automatic Zooming</strong>: Screen Studio automatically zooms in on clicks and interactions during recording to highlight important areas. The zoom level and animation speed are customizable.</p>
</li>
<li>
<p><strong>Smooth Cursor Movement</strong>: The software applies smoothing effects to cursor movements to eliminate jitter and make motions more cinematic. This helps improve watchability.</p>
</li>
<li>
<p><strong>Cinematic Motion Blur</strong>: Motion blur effects are added to all animations and transitions, making them appear more polished and professional.</p>
</li>
<li>
<p><strong>Intuitive Video Editor</strong>: The built-in editor makes it easy to trim, rearrange, and enhance videos after recording. Features like zoom timeline, volume control, and presets streamline editing.</p>
</li>
<li>
<p><strong>Webcam and Mic Recording</strong>: Record picture-in-picture webcam footage along with microphone narration for tutorials and demos. The webcam feed can be resized and positioned.</p>
</li>
<li>
<p><strong>Mobile Device Recording</strong>: Screen Studio can record iOS device screens via USB for demoing mobile apps. Android support is on the roadmap.</p>
</li>
<li>
<p><strong>Format and Resolution Options</strong>: Export videos in formats like MP4, MOV, and GIF up to 4K resolution. The UI provides preset export profiles for social media platforms.</p>
</li>
</ul>
<h2 id="use-cases">Use Cases</h2>
<p>Here are some common use cases and scenarios where Screen Studio provides value:</p>
<ul>
<li>
<p><strong>Software Demos and Tutorials</strong>: Showcase product features, workflows, and guides using engaging and professional videos.</p>
</li>
<li>
<p><strong>Marketing Content</strong>: Create promotional videos, social media stories, and ads quickly and easily.</p>
</li>
<li>
<p><strong>Customer Support</strong>: Use videos to explain solutions to common problems or provide how-to guidance.</p>
</li>
<li>
<p><strong>eLearning and Presentations</strong>: Develop engaging educational videos and animated slides.</p>
</li>
<li>
<p><strong>App Previews</strong>: Demo mobile apps and games by recording iOS device screens.</p>
</li>
<li>
<p><strong>Video Blogs and Reviews</strong>: Produce high-quality videos for YouTube channels or blogs.</p>
</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>In summary, Screen Studio is a specialized screen recorder that automates many video editing tasks like zooming and cursor smoothing to help users create professional-looking videos with minimal effort. Its straightforward editor, device recording capabilities, and export flexibility make it valuable for a wide range of use cases from software demos to eLearning content creation.</p>
<p>Citations:<br>
[1] https://www.screen.studio<br>
[2] https://www.screen.studio/help<br>
[3] https://www.techsmith.com/blog/the-ultimate-screen-recorder-comparison-guide-free-and-paid-options/<br>
[4] https://www.screen.studio/download<br>
[5] https://ninjacapture.com/what-are-the-features-of-screen-capturing-and-recording-software<br>
[6] https://en.wikipedia.org/wiki/Comparison_of_screencasting_software<br>
[7] https://www.producthunt.com/products/screen-studio<br>
[8] https://www.bitdoze.com/screen-studio-review/<br>
[9] https://efficient.app/compare/screen-studio-vs-loom<br>
[10] https://www.reddit.com/r/SideProject/comments/ykhi7h/update_i_released_screen_studio_screen_recorder/<br>
[11] https://www.ispringsolutions.com/blog/10-best-screen-recording-software-for-windows-free-and-paid<br>
[12] https://zapier.com/blog/best-screen-recording-software/<br>
[13] https://www.capterra.com/screen-recording-software/pricing-guide/<br>
[14] https://www.producthunt.com/products/screen-studio/alternatives<br>
[15] https://www.softwareadvice.com/screen-recording/<br>
[16] https://youtube.com/watch?v=Fe78Re-eVuA<br>
[17] https://www.g2.com/categories/screen-and-video-capture<br>
[18] https://efficient.app/apps/screen-studio</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[美国联邦基金利率的历史变化]]></title>
        <id>https://temberature.github.io/post/8m21ehhS9/</id>
        <link href="https://temberature.github.io/post/8m21ehhS9/">
        </link>
        <updated>2023-10-23T13:27:15.000Z</updated>
        <content type="html"><![CDATA[<p>根据搜索结果,我总结了美国联邦基金利率的历史变化如下:<br>
<img src="https://temberature.github.io/post-images/1698067723043.png" alt="" loading="lazy"></p>
<h2 id="1981-1990年沃尔克尔与通货膨胀作斗争">1981-1990年:沃尔克尔与通货膨胀作斗争</h2>
<ul>
<li>此期间联邦基金利率达到历史最高点,最高达到20%。</li>
<li>美联储主席保罗·沃尔克尔采取积极的紧缩货币政策,以遏制通货膨胀。通货膨胀率在1980年达到14.6%,为历史最高。</li>
<li>1981年利率开始大幅下降,但直到1984年11月才首次低于10%。</li>
<li>1981-1990年期间,实际联邦基金利率平均为9.97%。</li>
</ul>
<h2 id="1991-2000年格林斯潘主导经济长期扩张">1991-2000年:格林斯潘主导经济长期扩张</h2>
<ul>
<li>1990年代早期的短暂衰退后,联邦基金利率降至3%,为该十年最低点。</li>
<li>格林斯潘领导美联储进行多次“保险性”降息,即在经济未衰退时降低利率以刺激经济。</li>
<li>2000年5月,利率提高至6.5%,为该十年最高点。</li>
<li>1991-2000年期间,利率保持相对稳定。</li>
</ul>
<h2 id="2001-2010年美联储面临互联网泡沫-911恐怖袭击和2008年金融危机">2001-2010年:美联储面临互联网泡沫、911恐怖袭击和2008年金融危机</h2>
<ul>
<li>2001-2003年,联邦基金利率从6%降至1%,为应对互联网泡沫破裂和911事件导致的衰退。</li>
<li>2004-2006年,利率从1%逐步提高至5.25%。</li>
<li>2008年金融危机爆发后,利率降至接近零。</li>
<li>本·伯南克领导美联储进行大规模经济救助。</li>
</ul>
<h2 id="2011-2020年经济从大衰退中复苏后遭遇新冠疫情">2011-2020年:经济从大衰退中复苏,后遭遇新冠疫情</h2>
<ul>
<li>2015-2018年,美联储多次小幅提高利率。</li>
<li>2019年,美联储进行三次降息,类似1990年代的“保险性”降息。</li>
<li>2020年3月,新冠疫情爆发,美联储将利率降至接近零。</li>
</ul>
<h2 id="总结">总结</h2>
<ul>
<li>联邦基金利率反映了不同时期美国经济形势和美联储货币政策。</li>
<li>1980年代利率最高,用于遏制通货膨胀;2008年和2020年降至接近零,以应对危机。</li>
<li>格林斯潘和伯南克领导美联储应对重大经济事件。</li>
</ul>
<p>Citations:<br>
[1] https://tradingeconomics.com/united-states/interest-rate<br>
[2] https://fred.stlouisfed.org/series/FEDFUNDS<br>
[3] https://www.forbes.com/advisor/investing/fed-funds-rate-history/<br>
[4] https://www.macrotrends.net/2015/fed-funds-rate-historical-chart<br>
[5] https://www.bankrate.com/banking/federal-reserve/history-of-federal-funds-rate/</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[黎巴嫩真主党与以色列和哈马斯的关系]]></title>
        <id>https://temberature.github.io/post/0-8r-7oEN/</id>
        <link href="https://temberature.github.io/post/0-8r-7oEN/">
        </link>
        <updated>2023-10-13T15:58:08.000Z</updated>
        <content type="html"><![CDATA[<p>关于黎巴嫩真主党与以色列和哈马斯的关系,可以总结如下:</p>
<h2 id="真主党的背景">真主党的背景</h2>
<ul>
<li>
<p>真主党是黎巴嫩一个什叶派穆斯林政党和准军事组织,成立于1982年,其目的是抵抗以色列对黎巴嫩的占领[6]。</p>
</li>
<li>
<p>真主党得到伊朗的资助和支持,采用类似伊朗伊斯兰革命的模式[6]。</p>
</li>
</ul>
<h2 id="真主党与以色列的关系">真主党与以色列的关系</h2>
<ul>
<li>
<p>真主党与以色列是敌对关系,经常发生边境冲突。最近一次是2022年8月真主党向以色列北部发射导弹,以色列进行了报复性轰炸[1]。</p>
</li>
<li>
<p>2006年,真主党与以色列爆发大规模冲突,互有重大伤亡[6]。</p>
</li>
<li>
<p>真主党掌握大量导弹和火箭弹,对以色列安全构成重大威胁[1]。以色列非常担心真主党介入以色列与哈马斯的冲突[1]。</p>
</li>
</ul>
<h2 id="真主党与哈马斯的关系">真主党与哈马斯的关系</h2>
<ul>
<li>
<p>真主党与哈马斯都是反以组织,有着共同的意识形态基础,但真主党否认参与计划哈马斯最近的袭击行动[3]。</p>
</li>
<li>
<p>如果以色列大规模报复加沙,真主党可能会介入支持哈马斯[3]。</p>
</li>
<li>
<p>真主党的军事实力远强于哈马斯,如果参战将对以色列构成更大威胁[1]。</p>
</li>
</ul>
<p>Citations:<br>
[1] https://apnews.com/article/hezbollah-israel-hamas-lebanon-war-423f5f20d691dcd0cc8af1788f11857b<br>
[2] https://youtube.com/watch?v=5LWjiU25jLQ<br>
[3] https://apnews.com/article/lebanon-israel-palestinian-hamas-hezbollah-iran-2ccfaa49139358e6d2add89878a0cfe4<br>
[4] https://youtube.com/watch?v=3cyaJyhiEwo<br>
[5] https://www.reuters.com/world/middle-east/israel-reports-cross-border-fire-lebanon-where-residents-say-israeli-shelling-2023-10-11/<br>
[6] https://en.wikipedia.org/wiki/Hezbollah</p>
]]></content>
    </entry>
    <entry>
        <title type="html"><![CDATA[20231013 金融市场周报]]></title>
        <id>https://temberature.github.io/post/XFAaF4w7L/</id>
        <link href="https://temberature.github.io/post/XFAaF4w7L/">
        </link>
        <updated>2023-10-13T15:48:32.000Z</updated>
        <content type="html"><![CDATA[<p>这是一篇市场周报,总结过去一周金融市场的主要事件和行情。</p>
<ol>
<li>
<p>美联储官员在加息路径上存在分歧。一些官员提出可以放缓加息步伐,但最新通胀数据表明降通胀任务艰巨,年内再加息一次的预期不减。</p>
</li>
<li>
<p>巴以冲突升级,导致地缘政治风险加大。这推动国际油价和黄金价格上涨。如果冲突进一步升级,可能会严重影响中东石油供应。</p>
</li>
<li>
<p>美国强化了对俄罗斯石油的出口制裁。这增加了油价的地缘政治风险溢价。委内瑞拉原油可能重新进入市场,增加供应。</p>
</li>
<li>
<p>汇金公司继续增持四大国有银行股票。这被视为国家队对资本市场的支持。</p>
</li>
<li>
<p>券商境外业务整改在有序进行。监管层面对存量客户采取相对宽松的态度。</p>
</li>
<li>
<p>高盛建议四季度超配中国股票,预计年底前可能出现反弹。</p>
</li>
<li>
<p>多地积极发行特殊再融资债券。这有助于地方政府补充财政收入。</p>
</li>
<li>
<p>成品油价格在半年来首次下调,有利于缓解企业成本压力。</p>
</li>
</ol>
<p>总体来看,地缘政治风险、货币政策渐趋宽松为市场提供一定支持,但全球经济面临衰退风险加大,市场波动可能持续。中国经济有望在政策刺激下企稳回升。</p>
<p>一周热榜精选：涨超80美元！巴以冲突下，黄金不惧美联储加息-市场参考-金十数据<br>
https://xnews.jin10.com/details/124218</p>
]]></content>
    </entry>
</feed>